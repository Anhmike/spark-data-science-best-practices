{"cells":[{"cell_type":"markdown","source":["## Use MLflow to Experiment a Keras Network Model Binary Classification for Movie Reviews\n\nThis notebook is based on \n* Jules Damji's ([@2twitme](https://twitter.com/2twitme)) blog [How to Use MLflow to Experiment a Keras Network Model: Binary Classification for Movie Reviews](https://databricks.com/blog/2018/08/23/how-to-use-mlflow-to-experiment-a-keras-network-model-binary-classification-for-movie-reviews.html) \n* [jsd-mlflow-examples](https://github.com/dmatrix/jsd-mlflow-examples)\n* Francois Cholllet's book: [_Deep Learning with Python_](https://www.manning.com/books/deep-learning-with-python?a_aid=keras&a_bid=76564dff)\n\n\nPre-requisites:\n* Refer to [MLflow Quick Start: Model Training and Logging](https://docs.databricks.com/spark/latest/mllib/mlflow.html) to setup an MLflow tracking server on a Linux instance."],"metadata":{}},{"cell_type":"code","source":["import mlflow\n\n# Set global variable for output_dir\noutput_dir = \"\""],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">\n<span class=\"ansi-red-fg\">AttributeError</span>Traceback (most recent call last)\n<span class=\"ansi-green-fg\">&lt;command-1440947&gt;</span> in <span class=\"ansi-cyan-fg\">&lt;module&gt;</span><span class=\"ansi-blue-fg\">()</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">      3</span> \n<span class=\"ansi-green-intense-fg ansi-bold\">      4</span> <span class=\"ansi-red-fg\"># Set experiment ID</span>\n<span class=\"ansi-green-fg\">----&gt; 5</span><span class=\"ansi-red-fg\"> </span>mlflow<span class=\"ansi-blue-fg\">.</span>set_experiment_id<span class=\"ansi-blue-fg\">(</span><span class=\"ansi-cyan-fg\">11</span><span class=\"ansi-blue-fg\">)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">      6</span> \n<span class=\"ansi-green-intense-fg ansi-bold\">      7</span> <span class=\"ansi-red-fg\"># Set global variable for output_dir</span>\n\n<span class=\"ansi-red-fg\">AttributeError</span>: &#39;module&#39; object has no attribute &#39;set_experiment_id&#39;</div>"]}}],"execution_count":2},{"cell_type":"code","source":["from keras.datasets import imdb\nimport numpy as np\n\n\"\"\"\nPart of this module is derived and borrowed heavily from Francois Chollet's book Deep Learning Python. Original code\ncan be found at :https://github.com/fchollet/deep-learning-with-python-notebooks/blob/master/3.5-classifying-movie-reviews.ipynb\n\nWe'll be working with \"IMDB dataset\", a set of 50,000 highly-polarized reviews from the Internet Movie Database. They are split into \n25,000 reviews for training and 25,000 reviews for testing, each set consisting in 50% negative and 50% positive reviews.\nWhy do we have these two separate training and test sets? You should never test a machine learning model on the same data \nthat you used to train it! Just because a model performs well on its training data doesn't mean that it will perform well \non data it has never seen, and what you actually care about is your model's performance on new data (since you already \nknow the labels of your training data -- obviously you don't need your model to predict those). For instance, it is \npossible that your model could end up merely memorizing a mapping between your training samples and their targets -- \nwhich would be completely useless for the task of predicting targets for data never seen before. We will go over this \npoint in much more detail in the next chapter.\n\nJust like the MNIST dataset, the IMDB dataset comes packaged with Keras. It has already been preprocessed: the reviews \n(sequences of words) have been turned into sequences of integers, where each integer stands for a specific word in a dictionary.\n\nThe following code will load the dataset (when you run it for the first time, about 80MB of data will be downloaded to your \nmachine)\n\"\"\"\n\nclass KIMDB_Data_Utils():\n\n    def __init__(self):\n        return\n\n    def fetch_imdb_data(self, num_words=10000):\n        \"\"\"\n        :param num_words: This arguments meants that we want to keep the top 10,000 most frequently occuring words in the training data. Rare words will be discarded\n        :return: The variables train_data and test_data are lists of reviews, each review being a list of word indices (encoding a sequence of words).  train_labels and test_labels are lists of 0s and 1s, where 0 stands for \"negative\" \\\n        and 1 stands for \"positive\":\n        \"\"\"\n        (train_data, train_labels), (test_data, test_labels) = imdb.load_data(num_words=num_words)\n\n        return (train_data, train_labels), (test_data, test_labels)\n\n    def decode_review(self, train_data, index=0):\n        \"\"\"\n        Return a decoded review\n        :param index: is index into mapping of words into the integer index\n        :return: a string matching the review\n        \"\"\"\n        # word_index is a dictionary mapping words to an integer index\n        word_index = imdb.get_word_index()\n        # We reverse it, mapping integer indices to words\n        reverse_word_index = dict([(value, key) for (key, value) in word_index.items()])\n        # We decode the review; note that our indices were offset by 3\n        # because 0, 1 and 2 are reserved indices for \"padding\", \"start of sequence\", and \"unknown\".\n        decoded_review = ' '.join([reverse_word_index.get(i - 3, '?') for i in train_data[index]])\n\n        return decoded_review\n\n    def prepare_vectorized_sequences(self, sequences, dimension=10000):\n        \"\"\"\n        We cannot feed lists of integers into a neural network. We have to turn our lists into tensors. One way is to convert the sequence\n        into tensors using Numpy. Also, we are going to use one-hot-encode our lists into vectors of 0s and 1s. That is, for instance turning the sequence\n        [3, 5] into a 10,000-dimensional vector that would be all-zeros except for indices 3 and 5, which would be ones. Then we could use as first layer in our\n        network a Dense layer, capable of handling floating point vector data.\n        :param sequences: this is the sequence we want to convert\n        :param dimension: size of the sequence\n        :return: list of one-hot-encoded vector []\n        \"\"\"\n        # Create an all-zero matrix of shape (len(sequences), dimension)\n        results = np.zeros((len(sequences), dimension))\n        for i, sequence in enumerate(sequences):\n            results[i, sequence] = 1.  # set specific indices of results[i] to 1s\n\n        return results\n\n    def prepare_vectorized_labels(self, labels):\n        \"\"\"\n        labels are scalars so we can just use numpy as arrays of type float\n        :param labels: label data\n        :return: numpy array\n        \"\"\"\n        return np.asarray(labels).astype('float32')\n#\n# Test the functions\n#\nif __name__ == '__main__':\n    # create a class handle\n    kdata_cls = KIMDB_Data_Utils()\n    (train_data, train_labels), (test_data, test_labels) = kdata_cls.fetch_imdb_data(num_words=10000)\n    print(train_data[0])\n    print(len(train_data))\n    decoded = kdata_cls.decode_review(train_data)\n    print(decoded)\n    x_train = kdata_cls.prepare_vectorized_sequences(train_data)\n    x_test = kdata_cls.prepare_vectorized_sequences(test_data)\n    print(x_train[0])\n    print(x_test[0])\n    y_train = kdata_cls.prepare_vectorized_labels(train_labels)\n    y_test = kdata_cls.prepare_vectorized_labels(test_labels)\n    print(y_train)\n    print(y_test)"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">[1, 14, 22, 16, 43, 530, 973, 1622, 1385, 65, 458, 4468, 66, 3941, 4, 173, 36, 256, 5, 25, 100, 43, 838, 112, 50, 670, 2, 9, 35, 480, 284, 5, 150, 4, 172, 112, 167, 2, 336, 385, 39, 4, 172, 4536, 1111, 17, 546, 38, 13, 447, 4, 192, 50, 16, 6, 147, 2025, 19, 14, 22, 4, 1920, 4613, 469, 4, 22, 71, 87, 12, 16, 43, 530, 38, 76, 15, 13, 1247, 4, 22, 17, 515, 17, 12, 16, 626, 18, 2, 5, 62, 386, 12, 8, 316, 8, 106, 5, 4, 2223, 5244, 16, 480, 66, 3785, 33, 4, 130, 12, 16, 38, 619, 5, 25, 124, 51, 36, 135, 48, 25, 1415, 33, 6, 22, 12, 215, 28, 77, 52, 5, 14, 407, 16, 82, 2, 8, 4, 107, 117, 5952, 15, 256, 4, 2, 7, 3766, 5, 723, 36, 71, 43, 530, 476, 26, 400, 317, 46, 7, 4, 2, 1029, 13, 104, 88, 4, 381, 15, 297, 98, 32, 2071, 56, 26, 141, 6, 194, 7486, 18, 4, 226, 22, 21, 134, 476, 26, 480, 5, 144, 30, 5535, 18, 51, 36, 28, 224, 92, 25, 104, 4, 226, 65, 16, 38, 1334, 88, 12, 16, 283, 5, 16, 4472, 113, 103, 32, 15, 16, 5345, 19, 178, 32]\n25000\n? this film was just brilliant casting location scenery story direction everyone&#39;s really suited the part they played and you could just imagine being there robert ? is an amazing actor and now the same being director ? father came from the same scottish island as myself so i loved the fact there was a real connection with this film the witty remarks throughout the film were great it was just brilliant so much that i bought the film as soon as it was released for ? and would recommend it to everyone to watch and the fly fishing was amazing really cried at the end it was so sad and you know what they say if you cry at a film it must have been good and this definitely was also ? to the two little boy&#39;s that played the ? of norman and paul they were just brilliant children are often left out of the ? list i think because the stars that play them all grown up are such a big profile for the whole film but these children are amazing and should be praised for what they have done don&#39;t you think the whole story was so lovely because it was true and was someone&#39;s life after all that was shared with us all\n[0. 1. 1. ... 0. 0. 0.]\n[0. 1. 1. ... 0. 0. 0.]\n[1. 0. 0. ... 0. 1. 0.]\n[0. 1. 1. ... 0. 0. 0.]\n</div>"]}}],"execution_count":3},{"cell_type":"code","source":["from keras import models\nfrom keras import layers\n\nclass KModel():\n\n    def __init__(self):\n        return\n\n    def build_basic_model(self):\n\n        \"\"\"\n        Build the base line model with one input layer, one hidden layer, and one output layer, with\n        16, 16, and 1 output neurons. Default activation functions for input and hidden layer are relu\n        and sigmoid respectively\n        :return: a Keras network model\n        \"\"\"\n\n        base_model = models.Sequential()\n        base_model.add(layers.Dense(16, activation='relu', input_shape=(10000,)))\n        base_model.add(layers.Dense(16, activation='relu'))\n        base_model.add(layers.Dense(1, activation='sigmoid'))\n\n        return base_model\n\n    def build_experimental_model(self, hidden_layers=1, output=16, activation='relu'):\n\n        exp_model = models.Sequential()\n        # add the input layers\n        exp_model.add(layers.Dense(output, activation=activation, input_shape=(10000,)))\n        # add hidden layers\n        for i in range(0, hidden_layers):\n            exp_model.add(layers.Dense(output, activation=activation))\n        # add output layer\n        exp_model.add(layers.Dense(1, activation='sigmoid'))\n\n        return exp_model\n\nif __name__ == '__main__':\n\n    mmaker = KModel()\n    model = mmaker.build_basic_model()\n    model.summary()\n\n    custom_model = mmaker.build_experimental_model(3, 32, 'tanh')\n    custom_model.summary()"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\ndense_1 (Dense)              (None, 16)                160016    \n_________________________________________________________________\ndense_2 (Dense)              (None, 16)                272       \n_________________________________________________________________\ndense_3 (Dense)              (None, 1)                 17        \n=================================================================\nTotal params: 160,305\nTrainable params: 160,305\nNon-trainable params: 0\n_________________________________________________________________\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\ndense_4 (Dense)              (None, 32)                320032    \n_________________________________________________________________\ndense_5 (Dense)              (None, 32)                1056      \n_________________________________________________________________\ndense_6 (Dense)              (None, 32)                1056      \n_________________________________________________________________\ndense_7 (Dense)              (None, 32)                1056      \n_________________________________________________________________\ndense_8 (Dense)              (None, 1)                 33        \n=================================================================\nTotal params: 323,233\nTrainable params: 323,233\nNon-trainable params: 0\n_________________________________________________________________\n</div>"]}}],"execution_count":4},{"cell_type":"code","source":["import matplotlib.pyplot as plt\n\nclass KPlot():\n    \n    def __init__(self):\n        return\n\n    def plot_loss_graph(self,history, title):\n        \"\"\"\n        Generate a matplotlib graph for the loss and accuracy metrics\n        :param histroy:\n        :return: instance of a graph\n        \"\"\"\n\n        acc = history.history['binary_accuracy']\n        loss = history.history['loss']\n        val_loss = history.history['val_loss']\n\n        epochs = range(1, len(acc) + 1)\n\n        fig, ax = plt.subplots()\n        ax.plot(epochs, loss, 'bo')\n\n        # \"bo\" is for \"blue dot\"\n        plt.plot(epochs, loss, 'bo', label='Training loss')\n        # b is for \"solid blue line\"\n        plt.plot(epochs, val_loss, 'b', label='Validation loss')\n        plt.title(title)\n        plt.xlabel('Epochs')\n        plt.ylabel('Loss')\n        plt.legend()\n\n        return fig\n\n    def plot_accuracy_graph(elf, history, title):\n\n        plt.clf()\n        acc = history.history['binary_accuracy']\n        val_acc = history.history['val_binary_accuracy']\n\n        epochs = range(1, len(acc) + 1)\n\n        fig, ax = plt.subplots()\n        ax.plot(epochs, acc, 'bo')\n\n        plt.plot(epochs, acc, 'bo', label='Training acc')\n        plt.plot(epochs, val_acc, 'b', label='Validation acc')\n        plt.title(title)\n        plt.xlabel('Epochs')\n        plt.ylabel('Loss')\n        plt.legend()\n\n        return fig"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":5},{"cell_type":"code","source":["# Create Params dictionary\nclass Params(object):\n\tdef __init__(self, hidden_layers, epochs, output, loss):\n\t\tself.hidden_layers = hidden_layers\n\t\tself.epochs = epochs\n\t\tself.output = output\n\t\tself.loss = loss\n\n# Configure args\n#args = Params(1, 20, 16, \"binary_crossentropy\")\n#args = Params(3, 30, 16, \"binary_crossentropy\")\n#args = Params(3, 20, 32, \"mse\")"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":6},{"cell_type":"code","source":["import os\nimport sys\nimport mlflow\nimport mlflow.keras\nimport tensorflow as tf\nimport tempfile\n\nfrom keras import optimizers\nfrom keras import metrics\n\nclass KTrain():\n\n    def __init__(self):\n        return\n\n    def compile_and_fit_model(self, model, x_train, y_train, epochs=20, batch_size=512, loss='binary_crossentropy',\n                              optimizer='rmsprop', lr=0.0001, metrics=metrics.binary_accuracy,\n                              verbose=1, save_model=0):\n        #\n        # generate validation data and training data\n        #\n        x_val = x_train[:10000]\n        partial_x_train = x_train[10000:]\n\n        y_val = y_train[:10000]\n        partail_y_train = y_train[10000:]\n\n        if optimizer == 'rmsprop':\n            opt = optimizers.RMSprop(lr=lr)\n        model.compile(optimizer=opt,\n                      loss=loss,\n                      metrics=[metrics])\n        #\n        # fit the model: use part of the training data and use validation for unseen data\n        #\n        history = model.fit(partial_x_train,\n                            partail_y_train,\n                            epochs=epochs,\n                            batch_size=batch_size,\n                            verbose=verbose,\n                            validation_data=(x_val, y_val))\n\n        if save_model:\n            pathdir = \"keras_models/\" + run_uuid\n            model_dir = self.get_directory_path(pathdir)\n            self.keras_save_model(model, model_dir)\n\n        return history\n\n    def keras_save_model(self, model, model_dir='/tmp'):\n        \"\"\"\n        Convert Keras estimator to TensorFlow\n        :type model_dir: object\n        \"\"\"\n        print(\"Keras model saved locally at %s\" % model_dir)\n        mlflow.keras.save_model(model, model_dir)\n\n    def evaulate_model(self,model, x_test, y_test):\n        \"\"\"\n        Evaulate the model with unseen and untrained data\n        :param model:\n        :return: results of probability\n        \"\"\"\n\n        return model.evaluate(x_test, y_test)\n\n    def get_binary_loss(self, hist):\n        loss = hist.history['loss']\n        loss_val = loss[len(loss) - 1]\n        return loss_val\n\n    def get_binary_acc(self, hist):\n        acc = hist.history['binary_accuracy']\n        acc_value = acc[len(acc) - 1]\n\n        return acc_value\n\n    def get_validation_loss(self, hist):\n        val_loss = hist.history['val_loss']\n        val_loss_value = val_loss[len(val_loss) - 1]\n\n        return val_loss_value\n\n    def get_validation_acc(self, hist):\n        val_acc = hist.history['val_binary_accuracy']\n        val_acc_value = val_acc[len(val_acc) - 1]\n\n        return val_acc_value\n\n\n    def print_metrics(self, hist):\n\n        acc_value = self.get_binary_acc(hist)\n        loss_value = self.get_binary_loss(hist)\n\n        val_acc_value = self.get_validation_acc(hist)\n\n        val_loss_value = self.get_validation_loss(hist)\n\n        print(\"Final metrics: binary_loss:%6.4f\" % loss_value)\n        print(\"Final metrics: binary_accuracy=%6.4f\" % acc_value)\n        print(\"Final metrics: validation_binary_loss:%6.4f\" % val_loss_value)\n        print(\"Final metrics: validation_binary_accuracy:%6.4f\" % val_acc_value)\n\n    def get_directory_path(self, dir_name, create_dir=True):\n\n        cwd = os.getcwd()\n\n        dir = os.path.join(cwd, dir_name)\n        if create_dir:\n          if not os.path.exists(dir):\n             os.mkdir(dir)\n\n        return dir\n\n    def train_models(self, args, base_line=True):\n        \"\"\"\n        Train the model and log all the MLflow Metrics\n        :param args: command line arguments. If no arguments then use default\n        :param base_line: Default flag. Create Baseline model\n        \"\"\"\n        with mlflow.start_run(experiment_id=11):\n            # Create TensorFlow Session\n            sess = tf.InteractiveSession()\n\n\n            #\n            # initialize some classes\n            #\n            kdata_cls = KIMDB_Data_Utils()\n            ktrain_cls = KTrain()\n            kplot_cls = KPlot()\n\n            #\n            # get IMDB Data\n            #\n            (train_data, train_labels), (test_data, test_labels) = kdata_cls.fetch_imdb_data()\n\n            #\n            # prepare and vectorize data\n            #\n            x_train = kdata_cls.prepare_vectorized_sequences(train_data)\n            x_test = kdata_cls.prepare_vectorized_sequences(test_data)\n\n            y_train = kdata_cls.prepare_vectorized_labels(train_labels)\n            y_test = kdata_cls.prepare_vectorized_labels(test_labels)\n\n            image_dir = ktrain_cls.get_directory_path(\"images\")\n            model_dir = ktrain_cls.get_directory_path(\"models\")\n\n            graph_label_loss = 'Baseline Model: Training and Validation Loss'\n            graph_label_acc = 'Baseline Model: Training and Validation Accuracy'\n            graph_image_loss_png = os.path.join(image_dir,'baseline_loss.png')\n            graph_image_acc_png = os.path.join(image_dir, 'baseline_accuracy.png')\n\n            if not base_line:\n                graph_label_loss = 'Experimental: Training and Validation Loss'\n                graph_label_acc = 'Experimental Model: Training and Validation Accuracy'\n                graph_image_loss_png = os.path.join(image_dir, 'experimental_loss.png')\n                graph_image_acc_png = os.path.join(image_dir,'experimental_accuracy.png')\n\n            kmodel = KModel()\n            if base_line:\n                print(\"Baseline Model:\")\n                model = kmodel.build_basic_model()\n            else:\n                print(\"Experiment Model:\")\n                model = kmodel.build_experimental_model(args.hidden_layers, args.output)\n\n            history = ktrain_cls.compile_and_fit_model(model, x_train, y_train, epochs=args.epochs, loss=args.loss)\n            model.summary()\n            ktrain_cls.print_metrics(history)\n\n            figure_loss = kplot_cls.plot_loss_graph(history, graph_label_loss)\n            figure_loss.savefig(graph_image_loss_png )\n\n            figure_acc = kplot_cls.plot_accuracy_graph(history, graph_label_acc)\n            figure_acc.savefig(graph_image_acc_png)\n\n            results = ktrain_cls.evaulate_model(model, x_test, y_test)\n\n            print(\"Average Probability Results:\")\n            print(results)\n\n            print()\n            print(\"Predictions Results:\")\n            predictions = model.predict(x_test)\n            print(predictions)\n\n            # print out current run_uuid\n            run_uuid = mlflow.active_run().info.run_uuid\n            print(\"MLflow Run ID: %s\" % run_uuid)\n            \n            # log parameters\n            mlflow.log_param(\"hidden_layers\", args.hidden_layers)\n            mlflow.log_param(\"output\", args.output)\n            mlflow.log_param(\"epochs\", args.epochs)\n            mlflow.log_param(\"loss_function\", args.loss)\n            \n            # log metrics\n            mlflow.log_metric(\"binary_loss\", ktrain_cls.get_binary_loss(history))\n            mlflow.log_metric(\"binary_acc\",  ktrain_cls.get_binary_acc(history))\n            mlflow.log_metric(\"validation_loss\", ktrain_cls.get_binary_loss(history))\n            mlflow.log_metric(\"validation_acc\", ktrain_cls.get_validation_acc(history))\n            mlflow.log_metric(\"average_loss\", results[0])\n            mlflow.log_metric(\"average_acc\", results[1])\n            \n            # log artifacts\n            mlflow.log_artifacts(image_dir, \"images\")\n                        \n            # log model\n            mlflow.keras.log_model(model, \"models\")\n\n            # save model locally\n            pathdir = \"keras_models/\" + run_uuid\n            model_dir = self.get_directory_path(pathdir, False)\n            ktrain_cls.keras_save_model(model, model_dir)\n\n            # Write out tensorflow graph\n            output_dir = tempfile.mkdtemp()\n            print(\"Writing TensorFlow events locally to %s\\n\" % output_dir)\n            writer = tf.summary.FileWriter(output_dir, graph=sess.graph)\n            print(\"Uploading TensorFlow events as a run artifact.\")\n            mlflow.log_artifacts(output_dir, artifact_path=\"events\")\n\n        print(\"loss function use\", args.loss)\n\n        # Close TensorFlow Session\n        sess.close()\n\n  \ndef runReviews(args, flag):\n    \n    if flag:\n        print(\"Using Default Baseline parameters\")\n    else:\n        print(\"Using Experimental parameters\")\n\n    print(\"hidden_layers:\", args.hidden_layers)\n    print(\"output:\", args.output)\n    print(\"epochs:\", args.epochs)\n    print(\"loss:\", args.loss)\n\n    train_models_cls = KTrain().train_models(args, flag)"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":7},{"cell_type":"code","source":["args = Params(1, 20, 16, \"binary_crossentropy\")\nrunReviews(args, True)"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Using Default Baseline parameters\n(&#39;hidden_layers:&#39;, 1)\n(&#39;output:&#39;, 16)\n(&#39;epochs:&#39;, 20)\n(&#39;loss:&#39;, &#39;binary_crossentropy&#39;)\nBaseline Model:\nTrain on 15000 samples, validate on 10000 samples\nEpoch 1/20\n\n  512/15000 [&gt;.............................] - ETA: 8s - loss: 0.6939 - binary_accuracy: 0.5020\n 1024/15000 [=&gt;............................] - ETA: 5s - loss: 0.6930 - binary_accuracy: 0.5107\n 1536/15000 [==&gt;...........................] - ETA: 4s - loss: 0.6933 - binary_accuracy: 0.5046\n 2048/15000 [===&gt;..........................] - ETA: 4s - loss: 0.6935 - binary_accuracy: 0.4956\n 2560/15000 [====&gt;.........................] - ETA: 3s - loss: 0.6927 - binary_accuracy: 0.5043\n 3072/15000 [=====&gt;........................] - ETA: 3s - loss: 0.6928 - binary_accuracy: 0.5085\n 3584/15000 [======&gt;.......................] - ETA: 3s - loss: 0.6926 - binary_accuracy: 0.5112\n 4096/15000 [=======&gt;......................] - ETA: 2s - loss: 0.6923 - binary_accuracy: 0.5134\n 4608/15000 [========&gt;.....................] - ETA: 2s - loss: 0.6919 - binary_accuracy: 0.5197\n 5120/15000 [=========&gt;....................] - ETA: 2s - loss: 0.6915 - binary_accuracy: 0.5281\n 5632/15000 [==========&gt;...................] - ETA: 2s - loss: 0.6912 - binary_accuracy: 0.5293\n 6144/15000 [===========&gt;..................] - ETA: 2s - loss: 0.6911 - binary_accuracy: 0.5308\n 6656/15000 [============&gt;.................] - ETA: 2s - loss: 0.6907 - binary_accuracy: 0.5328\n 7168/15000 [=============&gt;................] - ETA: 1s - loss: 0.6902 - binary_accuracy: 0.5340\n 7680/15000 [==============&gt;...............] - ETA: 1s - loss: 0.6895 - binary_accuracy: 0.5401\n 8192/15000 [===============&gt;..............] - ETA: 1s - loss: 0.6889 - binary_accuracy: 0.5446\n 8704/15000 [================&gt;.............] - ETA: 1s - loss: 0.6886 - binary_accuracy: 0.5465\n 9216/15000 [=================&gt;............] - ETA: 1s - loss: 0.6883 - binary_accuracy: 0.5492\n 9728/15000 [==================&gt;...........] - ETA: 1s - loss: 0.6880 - binary_accuracy: 0.5514\n10240/15000 [===================&gt;..........] - ETA: 1s - loss: 0.6875 - binary_accuracy: 0.5552\n10752/15000 [====================&gt;.........] - ETA: 0s - loss: 0.6873 - binary_accuracy: 0.5573\n11264/15000 [=====================&gt;........] - ETA: 0s - loss: 0.6866 - binary_accuracy: 0.5611\n11776/15000 [======================&gt;.......] - ETA: 0s - loss: 0.6859 - binary_accuracy: 0.5639\n12288/15000 [=======================&gt;......] - ETA: 0s - loss: 0.6853 - binary_accuracy: 0.5671\n12800/15000 [========================&gt;.....] - ETA: 0s - loss: 0.6847 - binary_accuracy: 0.5695\n13312/15000 [=========================&gt;....] - ETA: 0s - loss: 0.6841 - binary_accuracy: 0.5720\n13824/15000 [==========================&gt;...] - ETA: 0s - loss: 0.6837 - binary_accuracy: 0.5734\n14336/15000 [===========================&gt;..] - ETA: 0s - loss: 0.6832 - binary_accuracy: 0.5756\n14848/15000 [============================&gt;.] - ETA: 0s - loss: 0.6828 - binary_accuracy: 0.5768\n15000/15000 [==============================] - 5s 345us/step - loss: 0.6826 - binary_accuracy: 0.5781 - val_loss: 0.6665 - val_binary_accuracy: 0.6507\nEpoch 2/20\n\n  512/15000 [&gt;.............................] - ETA: 3s - loss: 0.6602 - binary_accuracy: 0.6953\n 1024/15000 [=&gt;............................] - ETA: 3s - loss: 0.6593 - binary_accuracy: 0.6875\n 1536/15000 [==&gt;...........................] - ETA: 3s - loss: 0.6586 - binary_accuracy: 0.6895\n 2048/15000 [===&gt;..........................] - ETA: 2s - loss: 0.6582 - binary_accuracy: 0.6904\n 2560/15000 [====&gt;.........................] - ETA: 2s - loss: 0.6582 - binary_accuracy: 0.6887\n 3072/15000 [=====&gt;........................] - ETA: 2s - loss: 0.6573 - binary_accuracy: 0.6895\n 3584/15000 [======&gt;.......................] - ETA: 2s - loss: 0.6577 - binary_accuracy: 0.6855\n 4096/15000 [=======&gt;......................] - ETA: 2s - loss: 0.6568 - binary_accuracy: 0.6919\n 4608/15000 [========&gt;.....................] - ETA: 2s - loss: 0.6556 - binary_accuracy: 0.6927\n 5120/15000 [=========&gt;....................] - ETA: 2s - loss: 0.6546 - binary_accuracy: 0.6977\n 5632/15000 [==========&gt;...................] - ETA: 2s - loss: 0.6539 - binary_accuracy: 0.7010\n 6144/15000 [===========&gt;..................] - ETA: 1s - loss: 0.6529 - binary_accuracy: 0.7025\n 6656/15000 [============&gt;.................] - ETA: 1s - loss: 0.6526 - binary_accuracy: 0.7018\n 7168/15000 [=============&gt;................] - ETA: 1s - loss: 0.6521 - binary_accuracy: 0.7010\n 7680/15000 [==============&gt;...............] - ETA: 1s - loss: 0.6513 - binary_accuracy: 0.7046\n 8192/15000 [===============&gt;..............] - ETA: 1s - loss: 0.6504 - binary_accuracy: 0.7061\n 8704/15000 [================&gt;.............] - ETA: 1s - loss: 0.6496 - binary_accuracy: 0.7086\n 9216/15000 [=================&gt;............] - ETA: 1s - loss: 0.6491 - binary_accuracy: 0.7070\n 9728/15000 [==================&gt;...........] - ETA: 1s - loss: 0.6485 - binary_accuracy: 0.7074\n10240/15000 [===================&gt;..........] - ETA: 1s - loss: 0.6483 - binary_accuracy: 0.7071\n10752/15000 [====================&gt;.........] - ETA: 0s - loss: 0.6478 - binary_accuracy: 0.7079\n11264/15000 [=====================&gt;........] - ETA: 0s - loss: 0.6473 - binary_accuracy: 0.7079\n11776/15000 [======================&gt;.......] - ETA: 0s - loss: 0.6465 - binary_accuracy: 0.7090\n12288/15000 [=======================&gt;......] - ETA: 0s - loss: 0.6458 - binary_accuracy: 0.7103\n12800/15000 [========================&gt;.....] - ETA: 0s - loss: 0.6449 - binary_accuracy: 0.7130\n13312/15000 [=========================&gt;....] - ETA: 0s - loss: 0.6445 - binary_accuracy: 0.7136\n13824/15000 [==========================&gt;...] - ETA: 0s - loss: 0.6439 - binary_accuracy: 0.7161\n14336/15000 [===========================&gt;..] - ETA: 0s - loss: 0.6434 - binary_accuracy: 0.7174\n14848/15000 [============================&gt;.] - ETA: 0s - loss: 0.6428 - binary_accuracy: 0.7183\n15000/15000 [==============================] - 5s 352us/step - loss: 0.6425 - binary_accuracy: 0.7187 - val_loss: 0.6246 - val_binary_accuracy: 0.7596\nEpoch 3/20\n\n  512/15000 [&gt;.............................] - ETA: 3s - loss: 0.6109 - binary_accuracy: 0.7930\n 1024/15000 [=&gt;............................] - ETA: 3s - loss: 0.6149 - binary_accuracy: 0.7871\n 1536/15000 [==&gt;...........................] - ETA: 3s - loss: 0.6131 - binary_accuracy: 0.7871\n 2048/15000 [===&gt;..........................] - ETA: 2s - loss: 0.6125 - binary_accuracy: 0.7852\n 2560/15000 [====&gt;.........................] - ETA: 2s - loss: 0.6113 - binary_accuracy: 0.7859\n 3072/15000 [=====&gt;........................] - ETA: 2s - loss: 0.6102 - binary_accuracy: 0.7868\n 3584/15000 [======&gt;.......................] - ETA: 2s - loss: 0.6101 - binary_accuracy: 0.7860\n 4096/15000 [=======&gt;......................] - ETA: 2s - loss: 0.6100 - binary_accuracy: 0.7856\n 4608/15000 [========&gt;.....................] - ETA: 2s - loss: 0.6095 - binary_accuracy: 0.7875\n 5120/15000 [=========&gt;....................] - ETA: 2s - loss: 0.6082 - binary_accuracy: 0.7912\n 5632/15000 [==========&gt;...................] - ETA: 2s - loss: 0.6081 - binary_accuracy: 0.7901\n 6144/15000 [===========&gt;..................] - ETA: 2s - loss: 0.6071 - binary_accuracy: 0.7920\n 6656/15000 [============&gt;.................] - ETA: 1s - loss: 0.6064 - binary_accuracy: 0.7915\n 7168/15000 [=============&gt;................] - ETA: 1s - loss: 0.6062 - binary_accuracy: 0.7903\n 7680/15000 [==============&gt;...............] - ETA: 1s - loss: 0.6049 - binary_accuracy: 0.7921\n 8192/15000 [===============&gt;..............] - ETA: 1s - loss: 0.6039 - binary_accuracy: 0.7915\n 8704/15000 [================&gt;.............] - ETA: 1s - loss: 0.6038 - binary_accuracy: 0.7898\n 9216/15000 [=================&gt;............] - ETA: 1s - loss: 0.6036 - binary_accuracy: 0.7883\n 9728/15000 [==================&gt;...........] - ETA: 1s - loss: 0.6033 - binary_accuracy: 0.7884\n10240/15000 [===================&gt;..........] - ETA: 1s - loss: 0.6022 - binary_accuracy: 0.7893\n10752/15000 [====================&gt;.........] - ETA: 0s - loss: 0.6020 - binary_accuracy: 0.7896\n11264/15000 [=====================&gt;........] - ETA: 0s - loss: 0.6013 - binary_accuracy: 0.7901\n11776/15000 [======================&gt;.......] - ETA: 0s - loss: 0.6009 - binary_accuracy: 0.7908\n12288/15000 [=======================&gt;......] - ETA: 0s - loss: 0.6001 - binary_accuracy: 0.7912\n12800/15000 [========================&gt;.....] - ETA: 0s - loss: 0.5992 - binary_accuracy: 0.7923\n13312/15000 [=========================&gt;....] - ETA: 0s - loss: 0.5987 - binary_accuracy: 0.7937\n13824/15000 [==========================&gt;...] - ETA: 0s - loss: 0.5976 - binary_accuracy: 0.7967\n14336/15000 [===========================&gt;..] - ETA: 0s - loss: 0.5972 - binary_accuracy: 0.7964\n14848/15000 [============================&gt;.] - ETA: 0s - loss: 0.5968 - binary_accuracy: 0.7973\n15000/15000 [==============================] - 5s 365us/step - loss: 0.5965 - binary_accuracy: 0.7975 - val_loss: 0.5844 - val_binary_accuracy: 0.8098\nEpoch 4/20\n\n  512/15000 [&gt;.............................] - ETA: 3s - loss: 0.5672 - binary_accuracy: 0.8496\n 1024/15000 [=&gt;............................] - ETA: 3s - loss: 0.5663 - binary_accuracy: 0.8389\n 1536/15000 [==&gt;...........................] - ETA: 3s - loss: 0.5644 - binary_accuracy: 0.8392\n 2048/15000 [===&gt;..........................] - ETA: 2s - loss: 0.5670 - binary_accuracy: 0.8315\n 2560/15000 [====&gt;.........................] - ETA: 2s - loss: 0.5669 - binary_accuracy: 0.8340\n 3072/15000 [=====&gt;........................] - ETA: 2s - loss: 0.5664 - binary_accuracy: 0.8330\n 3584/15000 [======&gt;.......................] - ETA: 2s - loss: 0.5647 - binary_accuracy: 0.8329\n 4096/15000 [=======&gt;......................] - ETA: 2s - loss: 0.5649 - binary_accuracy: 0.8308\n 4608/15000 [========&gt;.....................] - ETA: 2s - loss: 0.5639 - binary_accuracy: 0.8318\n 5120/15000 [=========&gt;....................] - ETA: 2s - loss: 0.5629 - binary_accuracy: 0.8316\n 5632/15000 [==========&gt;...................] - ETA: 2s - loss: 0.5625 - binary_accuracy: 0.8310\n 6144/15000 [===========&gt;..................] - ETA: 1s - loss: 0.5630 - binary_accuracy: 0.8304\n 6656/15000 [============&gt;.................] - ETA: 1s - loss: 0.5622 - binary_accuracy: 0.8310\n 7168/15000 [=============&gt;................] - ETA: 1s - loss: 0.5618 - binary_accuracy: 0.8315\n 7680/15000 [==============&gt;...............] - ETA: 1s - loss: 0.5613 - binary_accuracy: 0.8324\n 8192/15000 [===============&gt;..............] - ETA: 1s - loss: 0.5606 - binary_accuracy: 0.8328\n 8704/15000 [================&gt;.............] - ETA: 1s - loss: 0.5605 - binary_accuracy: 0.8319\n 9216/15000 [=================&gt;............] - ETA: 1s - loss: 0.5600 - binary_accuracy: 0.8320\n 9728/15000 [==================&gt;...........] - ETA: 1s - loss: 0.5597 - binary_accuracy: 0.8318\n10240/15000 [===================&gt;..........] - ETA: 1s - loss: 0.5592 - binary_accuracy: 0.8319\n10752/15000 [====================&gt;.........] - ETA: 0s - loss: 0.5592 - binary_accuracy: 0.8313\n11264/15000 [=====================&gt;........] - ETA: 0s - loss: 0.5586 - binary_accuracy: 0.8315\n11776/15000 [======================&gt;.......] - ETA: 0s - loss: 0.5581 - binary_accuracy: 0.8325\n12288/15000 [=======================&gt;......] - ETA: 0s - loss: 0.5579 - binary_accuracy: 0.8316\n12800/15000 [========================&gt;.....] - ETA: 0s - loss: 0.5571 - binary_accuracy: 0.8314\n13312/15000 [=========================&gt;....] - ETA: 0s - loss: 0.5562 - binary_accuracy: 0.8320\n13824/15000 [==========================&gt;...] - ETA: 0s - loss: 0.5555 - binary_accuracy: 0.8328\n14336/15000 [===========================&gt;..] - ETA: 0s - loss: 0.5551 - binary_accuracy: 0.8331\n14848/15000 [============================&gt;.] - ETA: 0s - loss: 0.5539 - binary_accuracy: 0.8346\n15000/15000 [==============================] - 5s 359us/step - loss: 0.5536 - binary_accuracy: 0.8351 - val_loss: 0.5468 - val_binary_accuracy: 0.8250\nEpoch 5/20\n\n  512/15000 [&gt;.............................] - ETA: 3s - loss: 0.5356 - binary_accuracy: 0.8320\n 1024/15000 [=&gt;............................] - ETA: 3s - loss: 0.5388 - binary_accuracy: 0.8369\n 1536/15000 [==&gt;...........................] - ETA: 3s - loss: 0.5348 - binary_accuracy: 0.8366\n 2048/15000 [===&gt;..........................] - ETA: 2s - loss: 0.5317 - binary_accuracy: 0.8359\n 2560/15000 [====&gt;.........................] - ETA: 2s - loss: 0.5312 - binary_accuracy: 0.8367\n 3072/15000 [=====&gt;........................] - ETA: 2s - loss: 0.5303 - binary_accuracy: 0.8392\n 3584/15000 [======&gt;.......................] - ETA: 2s - loss: 0.5306 - binary_accuracy: 0.8387\n 4096/15000 [=======&gt;......................] - ETA: 2s - loss: 0.5295 - binary_accuracy: 0.8438\n 4608/15000 [========&gt;.....................] - ETA: 2s - loss: 0.5297 - binary_accuracy: 0.8424\n 5120/15000 [=========&gt;....................] - ETA: 2s - loss: 0.5281 - binary_accuracy: 0.8436\n 5632/15000 [==========&gt;...................] - ETA: 2s - loss: 0.5274 - binary_accuracy: 0.8436\n 6144/15000 [===========&gt;..................] - ETA: 2s - loss: 0.5256 - binary_accuracy: 0.8459\n 6656/15000 [============&gt;.................] - ETA: 1s - loss: 0.5226 - binary_accuracy: 0.8487\n 7168/15000 [=============&gt;................] - ETA: 1s - loss: 0.5226 - binary_accuracy: 0.8484\n 7680/15000 [==============&gt;...............] - ETA: 1s - loss: 0.5220 - binary_accuracy: 0.8493\n 8192/15000 [===============&gt;..............] - ETA: 1s - loss: 0.5209 - binary_accuracy: 0.8507\n 8704/15000 [================&gt;.............] - ETA: 1s - loss: 0.5198 - binary_accuracy: 0.8517\n 9216/15000 [=================&gt;............] - ETA: 1s - loss: 0.5182 - binary_accuracy: 0.8538\n 9728/15000 [==================&gt;...........] - ETA: 1s - loss: 0.5181 - binary_accuracy: 0.8535\n10240/15000 [===================&gt;..........] - ETA: 1s - loss: 0.5168 - binary_accuracy: 0.8545\n10752/15000 [====================&gt;.........] - ETA: 0s - loss: 0.5164 - binary_accuracy: 0.8549\n11264/15000 [=====================&gt;........] - ETA: 0s - loss: 0.5163 - binary_accuracy: 0.8551\n11776/15000 [======================&gt;.......] - ETA: 0s - loss: 0.5160 - binary_accuracy: 0.8551\n12288/15000 [=======================&gt;......] - ETA: 0s - loss: 0.5153 - binary_accuracy: 0.8551\n12800/15000 [========================&gt;.....] - ETA: 0s - loss: 0.5146 - binary_accuracy: 0.8554\n13312/15000 [=========================&gt;....] - ETA: 0s - loss: 0.5140 - binary_accuracy: 0.8561\n13824/15000 [==========================&gt;...] - ETA: 0s - loss: 0.5139 - binary_accuracy: 0.8558\n14336/15000 [===========================&gt;..] - ETA: 0s - loss: 0.5139 - binary_accuracy: 0.8548\n14848/15000 [============================&gt;.] - ETA: 0s - loss: 0.5131 - binary_accuracy: 0.8557\n15000/15000 [==============================] - 5s 356us/step - loss: 0.5130 - binary_accuracy: 0.8558 - val_loss: 0.5120 - val_binary_accuracy: 0.8405\nEpoch 6/20\n\n  512/15000 [&gt;.............................] - ETA: 3s - loss: 0.4921 - binary_accuracy: 0.8672\n 1024/15000 [=&gt;............................] - ETA: 2s - loss: 0.4864 - binary_accuracy: 0.8770\n 1536/15000 [==&gt;...........................] - ETA: 2s - loss: 0.4829 - binary_accuracy: 0.8730\n 2048/15000 [===&gt;..........................] - ETA: 2s - loss: 0.4846 - binary_accuracy: 0.8726\n 2560/15000 [====&gt;.........................] - ETA: 2s - loss: 0.4842 - binary_accuracy: 0.8715\n 3072/15000 [=====&gt;........................] - ETA: 2s - loss: 0.4848 - binary_accuracy: 0.8688\n 3584/15000 [======&gt;.......................] - ETA: 2s - loss: 0.4836 - binary_accuracy: 0.8691\n 4096/15000 [=======&gt;......................] - ETA: 2s - loss: 0.4837 - binary_accuracy: 0.8687\n 4608/15000 [========&gt;.....................] - ETA: 2s - loss: 0.4852 - binary_accuracy: 0.8663\n 5120/15000 [=========&gt;....................] - ETA: 2s - loss: 0.4854 - binary_accuracy: 0.8662\n 5632/15000 [==========&gt;...................] - ETA: 1s - loss: 0.4839 - binary_accuracy: 0.8661\n 6144/15000 [===========&gt;..................] - ETA: 1s - loss: 0.4840 - binary_accuracy: 0.8678\n 6656/15000 [============&gt;.................] - ETA: 1s - loss: 0.4840 - binary_accuracy: 0.8682\n 7168/15000 [=============&gt;................] - ETA: 1s - loss: 0.4850 - binary_accuracy: 0.8661\n 7680/15000 [==============&gt;...............] - ETA: 1s - loss: 0.4841 - binary_accuracy: 0.8685\n 8192/15000 [===============&gt;..............] - ETA: 1s - loss: 0.4826 - binary_accuracy: 0.8698\n 8704/15000 [================&gt;.............] - ETA: 1s - loss: 0.4826 - binary_accuracy: 0.8704\n 9216/15000 [=================&gt;............] - ETA: 1s - loss: 0.4819 - binary_accuracy: 0.8697\n 9728/15000 [==================&gt;...........] - ETA: 1s - loss: 0.4815 - binary_accuracy: 0.8693\n10240/15000 [===================&gt;..........] - ETA: 1s - loss: 0.4807 - binary_accuracy: 0.8694\n10752/15000 [====================&gt;.........] - ETA: 0s - loss: 0.4805 - binary_accuracy: 0.8682\n11264/15000 [=====================&gt;........] - ETA: 0s - loss: 0.4797 - binary_accuracy: 0.8695\n11776/15000 [======================&gt;.......] - ETA: 0s - loss: 0.4789 - binary_accuracy: 0.8700\n12288/15000 [=======================&gt;......] - ETA: 0s - loss: 0.4788 - binary_accuracy: 0.8691\n12800/15000 [========================&gt;.....] - ETA: 0s - loss: 0.4781 - binary_accuracy: 0.8696\n13312/15000 [=========================&gt;....] - ETA: 0s - loss: 0.4779 - binary_accuracy: 0.8691\n13824/15000 [==========================&gt;...] - ETA: 0s - loss: 0.4772 - binary_accuracy: 0.8696\n14336/15000 [===========================&gt;..] - ETA: 0s - loss: 0.4766 - binary_accuracy: 0.8694\n14848/15000 [============================&gt;.] - ETA: 0s - loss: 0.4760 - binary_accuracy: 0.8696\n15000/15000 [==============================] - 5s 340us/step - loss: 0.4758 - binary_accuracy: 0.8698 - val_loss: 0.4806 - val_binary_accuracy: 0.8494\nEpoch 7/20\n\n  512/15000 [&gt;.............................] - ETA: 3s - loss: 0.4493 - binary_accuracy: 0.8789\n 1024/15000 [=&gt;............................] - ETA: 2s - loss: 0.4493 - binary_accuracy: 0.8857\n 1536/15000 [==&gt;...........................] - ETA: 2s - loss: 0.4477 - binary_accuracy: 0.8809\n 2048/15000 [===&gt;..........................] - ETA: 2s - loss: 0.4489 - binary_accuracy: 0.8789\n 2560/15000 [====&gt;.........................] - ETA: 2s - loss: 0.4504 - binary_accuracy: 0.8762\n 3072/15000 [=====&gt;........................] - ETA: 2s - loss: 0.4511 - binary_accuracy: 0.8776\n 3584/15000 [======&gt;.......................] - ETA: 2s - loss: 0.4505 - binary_accuracy: 0.8756\n 4096/15000 [=======&gt;......................] - ETA: 2s - loss: 0.4496 - binary_accuracy: 0.8755\n 4608/15000 [========&gt;.....................] - ETA: 2s - loss: 0.4497 - binary_accuracy: 0.8748\n 5120/15000 [=========&gt;....................] - ETA: 2s - loss: 0.4498 - binary_accuracy: 0.8756\n 5632/15000 [==========&gt;...................] - ETA: 2s - loss: 0.4491 - binary_accuracy: 0.8775\n 6144/15000 [===========&gt;..................] - ETA: 1s - loss: 0.4481 - binary_accuracy: 0.8774\n 6656/15000 [============&gt;.................] - ETA: 1s - loss: 0.4464 - binary_accuracy: 0.8785\n 7168/15000 [=============&gt;................] - ETA: 1s - loss: 0.4464 - binary_accuracy: 0.8785\n 7680/15000 [==============&gt;...............] - ETA: 1s - loss: 0.4463 - binary_accuracy: 0.8785\n 8192/15000 [===============&gt;..............] - ETA: 1s - loss: 0.4465 - binary_accuracy: 0.8781\n 8704/15000 [================&gt;.............] - ETA: 1s - loss: 0.4462 - binary_accuracy: 0.8782\n 9216/15000 [=================&gt;............] - ETA: 1s - loss: 0.4462 - binary_accuracy: 0.8788\n 9728/15000 [==================&gt;...........] - ETA: 1s - loss: 0.4462 - binary_accuracy: 0.8786\n10240/15000 [===================&gt;..........] - ETA: 1s - loss: 0.4459 - binary_accuracy: 0.8790\n10752/15000 [====================&gt;.........] - ETA: 0s - loss: 0.4453 - binary_accuracy: 0.8788\n11264/15000 [=====================&gt;........] - ETA: 0s - loss: 0.4442 - binary_accuracy: 0.8792\n11776/15000 [======================&gt;.......] - ETA: 0s - loss: 0.4432 - binary_accuracy: 0.8802\n12288/15000 [=======================&gt;......] - ETA: 0s - loss: 0.4427 - binary_accuracy: 0.8805\n12800/15000 [========================&gt;.....] - ETA: 0s - loss: 0.4428 - binary_accuracy: 0.8800\n13312/15000 [=========================&gt;....] - ETA: 0s - loss: 0.4425 - binary_accuracy: 0.8800\n13824/15000 [==========================&gt;...] - ETA: 0s - loss: 0.4430 - binary_accuracy: 0.8791\n14336/15000 [===========================&gt;..] - ETA: 0s - loss: 0.4426 - binary_accuracy: 0.8788\n14848/15000 [============================&gt;.] - ETA: 0s - loss: 0.4417 - binary_accuracy: 0.8793\n15000/15000 [==============================] - 5s 344us/step - loss: 0.4415 - binary_accuracy: 0.8796 - val_loss: 0.4516 - val_binary_accuracy: 0.8570\nEpoch 8/20\n\n  512/15000 [&gt;.............................] - ETA: 3s - loss: 0.4265 - binary_accuracy: 0.8965\n 1024/15000 [=&gt;............................] - ETA: 2s - loss: 0.4210 - binary_accuracy: 0.8955\n 1536/15000 [==&gt;...........................] - ETA: 2s - loss: 0.4236 - binary_accuracy: 0.8874\n 2048/15000 [===&gt;..........................] - ETA: 2s - loss: 0.4209 - binary_accuracy: 0.8867\n 2560/15000 [====&gt;.........................] - ETA: 2s - loss: 0.4189 - binary_accuracy: 0.8879\n 3072/15000 [=====&gt;........................] - ETA: 2s - loss: 0.4229 - binary_accuracy: 0.8822\n 3584/15000 [======&gt;.......................] - ETA: 2s - loss: 0.4212 - binary_accuracy: 0.8831\n 4096/15000 [=======&gt;......................] - ETA: 2s - loss: 0.4194 - binary_accuracy: 0.8865\n 4608/15000 [========&gt;.....................] - ETA: 2s - loss: 0.4189 - binary_accuracy: 0.8865\n 5120/15000 [=========&gt;....................] - ETA: 2s - loss: 0.4199 - binary_accuracy: 0.8865\n 5632/15000 [==========&gt;...................] - ETA: 2s - loss: 0.4189 - binary_accuracy: 0.8865\n 6144/15000 [===========&gt;..................] - ETA: 1s - loss: 0.4193 - binary_accuracy: 0.8859\n 6656/15000 [============&gt;.................] - ETA: 1s - loss: 0.4178 - binary_accuracy: 0.8861\n 7168/15000 [=============&gt;................] - ETA: 1s - loss: 0.4170 - binary_accuracy: 0.8869\n 7680/15000 [==============&gt;...............] - ETA: 1s - loss: 0.4151 - binary_accuracy: 0.8880\n 8192/15000 [===============&gt;..............] - ETA: 1s - loss: 0.4141 - binary_accuracy: 0.8892\n 8704/15000 [================&gt;.............] - ETA: 1s - loss: 0.4140 - binary_accuracy: 0.8887\n 9216/15000 [=================&gt;............] - ETA: 1s - loss: 0.4142 - binary_accuracy: 0.8891\n 9728/15000 [==================&gt;...........] - ETA: 1s - loss: 0.4132 - binary_accuracy: 0.8894\n10240/15000 [===================&gt;..........] - ETA: 1s - loss: 0.4133 - binary_accuracy: 0.8892\n10752/15000 [====================&gt;.........] - ETA: 0s - loss: 0.4134 - binary_accuracy: 0.8892\n11264/15000 [=====================&gt;........] - ETA: 0s - loss: 0.4130 - binary_accuracy: 0.8902\n11776/15000 [======================&gt;.......] - ETA: 0s - loss: 0.4132 - binary_accuracy: 0.8891\n12288/15000 [=======================&gt;......] - ETA: 0s - loss: 0.4127 - binary_accuracy: 0.8891\n12800/15000 [========================&gt;.....] - ETA: 0s - loss: 0.4118 - binary_accuracy: 0.8889\n13312/15000 [=========================&gt;....] - ETA: 0s - loss: 0.4110 - binary_accuracy: 0.8897\n13824/15000 [==========================&gt;...] - ETA: 0s - loss: 0.4105 - binary_accuracy: 0.8898\n14336/15000 [===========================&gt;..] - ETA: 0s - loss: 0.4107 - binary_accuracy: 0.8883\n14848/15000 [============================&gt;.] - ETA: 0s - loss: 0.4103 - binary_accuracy: 0.8887\n15000/15000 [==============================] - 5s 350us/step - loss: 0.4106 - binary_accuracy: 0.8881 - val_loss: 0.4267 - val_binary_accuracy: 0.8633\nEpoch 9/20\n\n  512/15000 [&gt;.............................] - ETA: 3s - loss: 0.3899 - binary_accuracy: 0.8945\n 1024/15000 [=&gt;............................] - ETA: 2s - loss: 0.3896 - binary_accuracy: 0.8984\n 1536/15000 [==&gt;...........................] - ETA: 2s - loss: 0.3930 - binary_accuracy: 0.8958\n 2048/15000 [===&gt;..........................] - ETA: 2s - loss: 0.3965 - binary_accuracy: 0.8926\n 2560/15000 [====&gt;.........................] - ETA: 2s - loss: 0.3978 - binary_accuracy: 0.8926\n 3072/15000 [=====&gt;........................] - ETA: 2s - loss: 0.3956 - binary_accuracy: 0.8942\n 3584/15000 [======&gt;.......................] - ETA: 2s - loss: 0.3925 - binary_accuracy: 0.8984\n 4096/15000 [=======&gt;......................] - ETA: 2s - loss: 0.3955 - binary_accuracy: 0.8965\n 4608/15000 [========&gt;.....................] - ETA: 2s - loss: 0.3964 - binary_accuracy: 0.8947\n 5120/15000 [=========&gt;....................] - ETA: 2s - loss: 0.3948 - binary_accuracy: 0.8953\n 5632/15000 [==========&gt;...................] - ETA: 2s - loss: 0.3944 - binary_accuracy: 0.8967\n 6144/15000 [===========&gt;..................] - ETA: 1s - loss: 0.3925 - binary_accuracy: 0.8983\n 6656/15000 [============&gt;.................] - ETA: 1s - loss: 0.3919 - binary_accuracy: 0.8984\n\n*** WARNING: skipped 12368 bytes of output ***\n\n10240/15000 [===================&gt;..........] - ETA: 1s - loss: 0.3026 - binary_accuracy: 0.9134\n10752/15000 [====================&gt;.........] - ETA: 0s - loss: 0.3021 - binary_accuracy: 0.9135\n11264/15000 [=====================&gt;........] - ETA: 0s - loss: 0.3025 - binary_accuracy: 0.9129\n11776/15000 [======================&gt;.......] - ETA: 0s - loss: 0.3009 - binary_accuracy: 0.9136\n12288/15000 [=======================&gt;......] - ETA: 0s - loss: 0.3010 - binary_accuracy: 0.9133\n12800/15000 [========================&gt;.....] - ETA: 0s - loss: 0.3013 - binary_accuracy: 0.9130\n13312/15000 [=========================&gt;....] - ETA: 0s - loss: 0.3007 - binary_accuracy: 0.9132\n13824/15000 [==========================&gt;...] - ETA: 0s - loss: 0.3005 - binary_accuracy: 0.9134\n14336/15000 [===========================&gt;..] - ETA: 0s - loss: 0.2999 - binary_accuracy: 0.9139\n14848/15000 [============================&gt;.] - ETA: 0s - loss: 0.2995 - binary_accuracy: 0.9144\n15000/15000 [==============================] - 5s 353us/step - loss: 0.2990 - binary_accuracy: 0.9149 - val_loss: 0.3415 - val_binary_accuracy: 0.8794\nEpoch 14/20\n\n  512/15000 [&gt;.............................] - ETA: 3s - loss: 0.2830 - binary_accuracy: 0.9277\n 1024/15000 [=&gt;............................] - ETA: 2s - loss: 0.2832 - binary_accuracy: 0.9229\n 1536/15000 [==&gt;...........................] - ETA: 2s - loss: 0.2827 - binary_accuracy: 0.9219\n 2048/15000 [===&gt;..........................] - ETA: 2s - loss: 0.2824 - binary_accuracy: 0.9229\n 2560/15000 [====&gt;.........................] - ETA: 2s - loss: 0.2805 - binary_accuracy: 0.9250\n 3072/15000 [=====&gt;........................] - ETA: 2s - loss: 0.2821 - binary_accuracy: 0.9248\n 3584/15000 [======&gt;.......................] - ETA: 2s - loss: 0.2831 - binary_accuracy: 0.9244\n 4096/15000 [=======&gt;......................] - ETA: 2s - loss: 0.2823 - binary_accuracy: 0.9253\n 4608/15000 [========&gt;.....................] - ETA: 2s - loss: 0.2817 - binary_accuracy: 0.9230\n 5120/15000 [=========&gt;....................] - ETA: 2s - loss: 0.2824 - binary_accuracy: 0.9225\n 5632/15000 [==========&gt;...................] - ETA: 2s - loss: 0.2851 - binary_accuracy: 0.9194\n 6144/15000 [===========&gt;..................] - ETA: 1s - loss: 0.2842 - binary_accuracy: 0.9214\n 6656/15000 [============&gt;.................] - ETA: 1s - loss: 0.2855 - binary_accuracy: 0.9193\n 7168/15000 [=============&gt;................] - ETA: 1s - loss: 0.2855 - binary_accuracy: 0.9191\n 7680/15000 [==============&gt;...............] - ETA: 1s - loss: 0.2837 - binary_accuracy: 0.9206\n 8192/15000 [===============&gt;..............] - ETA: 1s - loss: 0.2832 - binary_accuracy: 0.9213\n 8704/15000 [================&gt;.............] - ETA: 1s - loss: 0.2842 - binary_accuracy: 0.9198\n 9216/15000 [=================&gt;............] - ETA: 1s - loss: 0.2846 - binary_accuracy: 0.9187\n 9728/15000 [==================&gt;...........] - ETA: 1s - loss: 0.2843 - binary_accuracy: 0.9182\n10240/15000 [===================&gt;..........] - ETA: 1s - loss: 0.2842 - binary_accuracy: 0.9185\n10752/15000 [====================&gt;.........] - ETA: 0s - loss: 0.2838 - binary_accuracy: 0.9186\n11264/15000 [=====================&gt;........] - ETA: 0s - loss: 0.2830 - binary_accuracy: 0.9192\n11776/15000 [======================&gt;.......] - ETA: 0s - loss: 0.2823 - binary_accuracy: 0.9197\n12288/15000 [=======================&gt;......] - ETA: 0s - loss: 0.2828 - binary_accuracy: 0.9196\n12800/15000 [========================&gt;.....] - ETA: 0s - loss: 0.2831 - binary_accuracy: 0.9190\n13312/15000 [=========================&gt;....] - ETA: 0s - loss: 0.2828 - binary_accuracy: 0.9192\n13824/15000 [==========================&gt;...] - ETA: 0s - loss: 0.2829 - binary_accuracy: 0.9190\n14336/15000 [===========================&gt;..] - ETA: 0s - loss: 0.2835 - binary_accuracy: 0.9180\n14848/15000 [============================&gt;.] - ETA: 0s - loss: 0.2830 - binary_accuracy: 0.9183\n15000/15000 [==============================] - 5s 357us/step - loss: 0.2828 - binary_accuracy: 0.9185 - val_loss: 0.3305 - val_binary_accuracy: 0.8812\nEpoch 15/20\n\n  512/15000 [&gt;.............................] - ETA: 3s - loss: 0.2631 - binary_accuracy: 0.9219\n 1024/15000 [=&gt;............................] - ETA: 2s - loss: 0.2636 - binary_accuracy: 0.9238\n 1536/15000 [==&gt;...........................] - ETA: 2s - loss: 0.2669 - binary_accuracy: 0.9264\n 2048/15000 [===&gt;..........................] - ETA: 2s - loss: 0.2719 - binary_accuracy: 0.9248\n 2560/15000 [====&gt;.........................] - ETA: 2s - loss: 0.2706 - binary_accuracy: 0.9250\n 3072/15000 [=====&gt;........................] - ETA: 2s - loss: 0.2723 - binary_accuracy: 0.9222\n 3584/15000 [======&gt;.......................] - ETA: 2s - loss: 0.2728 - binary_accuracy: 0.9219\n 4096/15000 [=======&gt;......................] - ETA: 2s - loss: 0.2716 - binary_accuracy: 0.9229\n 4608/15000 [========&gt;.....................] - ETA: 2s - loss: 0.2717 - binary_accuracy: 0.9208\n 5120/15000 [=========&gt;....................] - ETA: 2s - loss: 0.2712 - binary_accuracy: 0.9219\n 5632/15000 [==========&gt;...................] - ETA: 2s - loss: 0.2731 - binary_accuracy: 0.9215\n 6144/15000 [===========&gt;..................] - ETA: 1s - loss: 0.2726 - binary_accuracy: 0.9211\n 6656/15000 [============&gt;.................] - ETA: 1s - loss: 0.2734 - binary_accuracy: 0.9208\n 7168/15000 [=============&gt;................] - ETA: 1s - loss: 0.2724 - binary_accuracy: 0.9216\n 7680/15000 [==============&gt;...............] - ETA: 1s - loss: 0.2709 - binary_accuracy: 0.9219\n 8192/15000 [===============&gt;..............] - ETA: 1s - loss: 0.2698 - binary_accuracy: 0.9226\n 8704/15000 [================&gt;.............] - ETA: 1s - loss: 0.2705 - binary_accuracy: 0.9230\n 9216/15000 [=================&gt;............] - ETA: 1s - loss: 0.2714 - binary_accuracy: 0.9217\n 9728/15000 [==================&gt;...........] - ETA: 1s - loss: 0.2716 - binary_accuracy: 0.9213\n10240/15000 [===================&gt;..........] - ETA: 1s - loss: 0.2711 - binary_accuracy: 0.9218\n10752/15000 [====================&gt;.........] - ETA: 0s - loss: 0.2713 - binary_accuracy: 0.9218\n11264/15000 [=====================&gt;........] - ETA: 0s - loss: 0.2698 - binary_accuracy: 0.9233\n11776/15000 [======================&gt;.......] - ETA: 0s - loss: 0.2693 - binary_accuracy: 0.9233\n12288/15000 [=======================&gt;......] - ETA: 0s - loss: 0.2692 - binary_accuracy: 0.9232\n12800/15000 [========================&gt;.....] - ETA: 0s - loss: 0.2685 - binary_accuracy: 0.9230\n13312/15000 [=========================&gt;....] - ETA: 0s - loss: 0.2681 - binary_accuracy: 0.9231\n13824/15000 [==========================&gt;...] - ETA: 0s - loss: 0.2680 - binary_accuracy: 0.9232\n14336/15000 [===========================&gt;..] - ETA: 0s - loss: 0.2682 - binary_accuracy: 0.9228\n14848/15000 [============================&gt;.] - ETA: 0s - loss: 0.2680 - binary_accuracy: 0.9227\n15000/15000 [==============================] - 5s 352us/step - loss: 0.2681 - binary_accuracy: 0.9226 - val_loss: 0.3207 - val_binary_accuracy: 0.8832\nEpoch 16/20\n\n  512/15000 [&gt;.............................] - ETA: 3s - loss: 0.2664 - binary_accuracy: 0.9199\n 1024/15000 [=&gt;............................] - ETA: 2s - loss: 0.2567 - binary_accuracy: 0.9287\n 1536/15000 [==&gt;...........................] - ETA: 2s - loss: 0.2570 - binary_accuracy: 0.9310\n 2048/15000 [===&gt;..........................] - ETA: 2s - loss: 0.2571 - binary_accuracy: 0.9277\n 2560/15000 [====&gt;.........................] - ETA: 2s - loss: 0.2562 - binary_accuracy: 0.9273\n 3072/15000 [=====&gt;........................] - ETA: 2s - loss: 0.2566 - binary_accuracy: 0.9274\n 3584/15000 [======&gt;.......................] - ETA: 2s - loss: 0.2584 - binary_accuracy: 0.9247\n 4096/15000 [=======&gt;......................] - ETA: 2s - loss: 0.2589 - binary_accuracy: 0.9231\n 4608/15000 [========&gt;.....................] - ETA: 2s - loss: 0.2570 - binary_accuracy: 0.9245\n 5120/15000 [=========&gt;....................] - ETA: 2s - loss: 0.2563 - binary_accuracy: 0.9244\n 5632/15000 [==========&gt;...................] - ETA: 2s - loss: 0.2560 - binary_accuracy: 0.9238\n 6144/15000 [===========&gt;..................] - ETA: 1s - loss: 0.2556 - binary_accuracy: 0.9246\n 6656/15000 [============&gt;.................] - ETA: 1s - loss: 0.2551 - binary_accuracy: 0.9244\n 7168/15000 [=============&gt;................] - ETA: 1s - loss: 0.2548 - binary_accuracy: 0.9238\n 7680/15000 [==============&gt;...............] - ETA: 1s - loss: 0.2543 - binary_accuracy: 0.9249\n 8192/15000 [===============&gt;..............] - ETA: 1s - loss: 0.2545 - binary_accuracy: 0.9248\n 8704/15000 [================&gt;.............] - ETA: 1s - loss: 0.2552 - binary_accuracy: 0.9250\n 9216/15000 [=================&gt;............] - ETA: 1s - loss: 0.2557 - binary_accuracy: 0.9244\n 9728/15000 [==================&gt;...........] - ETA: 1s - loss: 0.2560 - binary_accuracy: 0.9250\n10240/15000 [===================&gt;..........] - ETA: 1s - loss: 0.2559 - binary_accuracy: 0.9245\n10752/15000 [====================&gt;.........] - ETA: 0s - loss: 0.2556 - binary_accuracy: 0.9246\n11264/15000 [=====================&gt;........] - ETA: 0s - loss: 0.2559 - binary_accuracy: 0.9242\n11776/15000 [======================&gt;.......] - ETA: 0s - loss: 0.2555 - binary_accuracy: 0.9248\n12288/15000 [=======================&gt;......] - ETA: 0s - loss: 0.2548 - binary_accuracy: 0.9252\n12800/15000 [========================&gt;.....] - ETA: 0s - loss: 0.2548 - binary_accuracy: 0.9251\n13312/15000 [=========================&gt;....] - ETA: 0s - loss: 0.2544 - binary_accuracy: 0.9251\n13824/15000 [==========================&gt;...] - ETA: 0s - loss: 0.2552 - binary_accuracy: 0.9248\n14336/15000 [===========================&gt;..] - ETA: 0s - loss: 0.2544 - binary_accuracy: 0.9252\n14848/15000 [============================&gt;.] - ETA: 0s - loss: 0.2553 - binary_accuracy: 0.9249\n15000/15000 [==============================] - 5s 355us/step - loss: 0.2549 - binary_accuracy: 0.9251 - val_loss: 0.3133 - val_binary_accuracy: 0.8844\nEpoch 17/20\n\n  512/15000 [&gt;.............................] - ETA: 3s - loss: 0.2539 - binary_accuracy: 0.9219\n 1024/15000 [=&gt;............................] - ETA: 2s - loss: 0.2448 - binary_accuracy: 0.9307\n 1536/15000 [==&gt;...........................] - ETA: 2s - loss: 0.2440 - binary_accuracy: 0.9316\n 2048/15000 [===&gt;..........................] - ETA: 2s - loss: 0.2488 - binary_accuracy: 0.9292\n 2560/15000 [====&gt;.........................] - ETA: 2s - loss: 0.2461 - binary_accuracy: 0.9313\n 3072/15000 [=====&gt;........................] - ETA: 2s - loss: 0.2459 - binary_accuracy: 0.9310\n 3584/15000 [======&gt;.......................] - ETA: 2s - loss: 0.2489 - binary_accuracy: 0.9280\n 4096/15000 [=======&gt;......................] - ETA: 2s - loss: 0.2491 - binary_accuracy: 0.9275\n 4608/15000 [========&gt;.....................] - ETA: 2s - loss: 0.2494 - binary_accuracy: 0.9260\n 5120/15000 [=========&gt;....................] - ETA: 2s - loss: 0.2477 - binary_accuracy: 0.9260\n 5632/15000 [==========&gt;...................] - ETA: 2s - loss: 0.2478 - binary_accuracy: 0.9260\n 6144/15000 [===========&gt;..................] - ETA: 1s - loss: 0.2467 - binary_accuracy: 0.9276\n 6656/15000 [============&gt;.................] - ETA: 1s - loss: 0.2464 - binary_accuracy: 0.9270\n 7168/15000 [=============&gt;................] - ETA: 1s - loss: 0.2447 - binary_accuracy: 0.9290\n 7680/15000 [==============&gt;...............] - ETA: 1s - loss: 0.2448 - binary_accuracy: 0.9283\n 8192/15000 [===============&gt;..............] - ETA: 1s - loss: 0.2450 - binary_accuracy: 0.9288\n 8704/15000 [================&gt;.............] - ETA: 1s - loss: 0.2443 - binary_accuracy: 0.9296\n 9216/15000 [=================&gt;............] - ETA: 1s - loss: 0.2443 - binary_accuracy: 0.9300\n 9728/15000 [==================&gt;...........] - ETA: 1s - loss: 0.2445 - binary_accuracy: 0.9296\n10240/15000 [===================&gt;..........] - ETA: 1s - loss: 0.2452 - binary_accuracy: 0.9288\n10752/15000 [====================&gt;.........] - ETA: 0s - loss: 0.2454 - binary_accuracy: 0.9286\n11264/15000 [=====================&gt;........] - ETA: 0s - loss: 0.2449 - binary_accuracy: 0.9286\n11776/15000 [======================&gt;.......] - ETA: 0s - loss: 0.2443 - binary_accuracy: 0.9288\n12288/15000 [=======================&gt;......] - ETA: 0s - loss: 0.2443 - binary_accuracy: 0.9280\n12800/15000 [========================&gt;.....] - ETA: 0s - loss: 0.2448 - binary_accuracy: 0.9277\n13312/15000 [=========================&gt;....] - ETA: 0s - loss: 0.2445 - binary_accuracy: 0.9274\n13824/15000 [==========================&gt;...] - ETA: 0s - loss: 0.2439 - binary_accuracy: 0.9282\n14336/15000 [===========================&gt;..] - ETA: 0s - loss: 0.2433 - binary_accuracy: 0.9281\n14848/15000 [============================&gt;.] - ETA: 0s - loss: 0.2426 - binary_accuracy: 0.9283\n15000/15000 [==============================] - 5s 355us/step - loss: 0.2431 - binary_accuracy: 0.9281 - val_loss: 0.3056 - val_binary_accuracy: 0.8865\nEpoch 18/20\n\n  512/15000 [&gt;.............................] - ETA: 3s - loss: 0.2441 - binary_accuracy: 0.9336\n 1024/15000 [=&gt;............................] - ETA: 2s - loss: 0.2277 - binary_accuracy: 0.9395\n 1536/15000 [==&gt;...........................] - ETA: 2s - loss: 0.2345 - binary_accuracy: 0.9297\n 2048/15000 [===&gt;..........................] - ETA: 2s - loss: 0.2388 - binary_accuracy: 0.9272\n 2560/15000 [====&gt;.........................] - ETA: 2s - loss: 0.2361 - binary_accuracy: 0.9301\n 3072/15000 [=====&gt;........................] - ETA: 2s - loss: 0.2357 - binary_accuracy: 0.9303\n 3584/15000 [======&gt;.......................] - ETA: 2s - loss: 0.2354 - binary_accuracy: 0.9294\n 4096/15000 [=======&gt;......................] - ETA: 2s - loss: 0.2354 - binary_accuracy: 0.9290\n 4608/15000 [========&gt;.....................] - ETA: 2s - loss: 0.2346 - binary_accuracy: 0.9301\n 5120/15000 [=========&gt;....................] - ETA: 2s - loss: 0.2381 - binary_accuracy: 0.9289\n 5632/15000 [==========&gt;...................] - ETA: 2s - loss: 0.2363 - binary_accuracy: 0.9293\n 6144/15000 [===========&gt;..................] - ETA: 1s - loss: 0.2364 - binary_accuracy: 0.9285\n 6656/15000 [============&gt;.................] - ETA: 1s - loss: 0.2365 - binary_accuracy: 0.9282\n 7168/15000 [=============&gt;................] - ETA: 1s - loss: 0.2357 - binary_accuracy: 0.9294\n 7680/15000 [==============&gt;...............] - ETA: 1s - loss: 0.2345 - binary_accuracy: 0.9298\n 8192/15000 [===============&gt;..............] - ETA: 1s - loss: 0.2335 - binary_accuracy: 0.9308\n 8704/15000 [================&gt;.............] - ETA: 1s - loss: 0.2323 - binary_accuracy: 0.9315\n 9216/15000 [=================&gt;............] - ETA: 1s - loss: 0.2313 - binary_accuracy: 0.9326\n 9728/15000 [==================&gt;...........] - ETA: 1s - loss: 0.2318 - binary_accuracy: 0.9325\n10240/15000 [===================&gt;..........] - ETA: 1s - loss: 0.2320 - binary_accuracy: 0.9325\n10752/15000 [====================&gt;.........] - ETA: 0s - loss: 0.2315 - binary_accuracy: 0.9318\n11264/15000 [=====================&gt;........] - ETA: 0s - loss: 0.2315 - binary_accuracy: 0.9319\n11776/15000 [======================&gt;.......] - ETA: 0s - loss: 0.2320 - binary_accuracy: 0.9317\n12288/15000 [=======================&gt;......] - ETA: 0s - loss: 0.2311 - binary_accuracy: 0.9321\n12800/15000 [========================&gt;.....] - ETA: 0s - loss: 0.2313 - binary_accuracy: 0.9320\n13312/15000 [=========================&gt;....] - ETA: 0s - loss: 0.2316 - binary_accuracy: 0.9316\n13824/15000 [==========================&gt;...] - ETA: 0s - loss: 0.2322 - binary_accuracy: 0.9306\n14336/15000 [===========================&gt;..] - ETA: 0s - loss: 0.2321 - binary_accuracy: 0.9311\n14848/15000 [============================&gt;.] - ETA: 0s - loss: 0.2318 - binary_accuracy: 0.9310\n15000/15000 [==============================] - 5s 364us/step - loss: 0.2317 - binary_accuracy: 0.9313 - val_loss: 0.2991 - val_binary_accuracy: 0.8884\nEpoch 19/20\n\n  512/15000 [&gt;.............................] - ETA: 3s - loss: 0.2300 - binary_accuracy: 0.9258\n 1024/15000 [=&gt;............................] - ETA: 2s - loss: 0.2369 - binary_accuracy: 0.9248\n 1536/15000 [==&gt;...........................] - ETA: 2s - loss: 0.2330 - binary_accuracy: 0.9323\n 2048/15000 [===&gt;..........................] - ETA: 2s - loss: 0.2352 - binary_accuracy: 0.9302\n 2560/15000 [====&gt;.........................] - ETA: 2s - loss: 0.2310 - binary_accuracy: 0.9332\n 3072/15000 [=====&gt;........................] - ETA: 2s - loss: 0.2281 - binary_accuracy: 0.9336\n 3584/15000 [======&gt;.......................] - ETA: 2s - loss: 0.2270 - binary_accuracy: 0.9353\n 4096/15000 [=======&gt;......................] - ETA: 2s - loss: 0.2285 - binary_accuracy: 0.9336\n 4608/15000 [========&gt;.....................] - ETA: 2s - loss: 0.2298 - binary_accuracy: 0.9327\n 5120/15000 [=========&gt;....................] - ETA: 2s - loss: 0.2291 - binary_accuracy: 0.9334\n 5632/15000 [==========&gt;...................] - ETA: 2s - loss: 0.2259 - binary_accuracy: 0.9352\n 6144/15000 [===========&gt;..................] - ETA: 1s - loss: 0.2254 - binary_accuracy: 0.9349\n 6656/15000 [============&gt;.................] - ETA: 1s - loss: 0.2245 - binary_accuracy: 0.9346\n 7168/15000 [=============&gt;................] - ETA: 1s - loss: 0.2232 - binary_accuracy: 0.9355\n 7680/15000 [==============&gt;...............] - ETA: 1s - loss: 0.2225 - binary_accuracy: 0.9365\n 8192/15000 [===============&gt;..............] - ETA: 1s - loss: 0.2222 - binary_accuracy: 0.9365\n 8704/15000 [================&gt;.............] - ETA: 1s - loss: 0.2224 - binary_accuracy: 0.9354\n 9216/15000 [=================&gt;............] - ETA: 1s - loss: 0.2220 - binary_accuracy: 0.9358\n 9728/15000 [==================&gt;...........] - ETA: 1s - loss: 0.2218 - binary_accuracy: 0.9361\n10240/15000 [===================&gt;..........] - ETA: 1s - loss: 0.2207 - binary_accuracy: 0.9368\n10752/15000 [====================&gt;.........] - ETA: 0s - loss: 0.2213 - binary_accuracy: 0.9362\n11264/15000 [=====================&gt;........] - ETA: 0s - loss: 0.2205 - binary_accuracy: 0.9362\n11776/15000 [======================&gt;.......] - ETA: 0s - loss: 0.2212 - binary_accuracy: 0.9353\n12288/15000 [=======================&gt;......] - ETA: 0s - loss: 0.2218 - binary_accuracy: 0.9344\n12800/15000 [========================&gt;.....] - ETA: 0s - loss: 0.2229 - binary_accuracy: 0.9337\n13312/15000 [=========================&gt;....] - ETA: 0s - loss: 0.2226 - binary_accuracy: 0.9339\n13824/15000 [==========================&gt;...] - ETA: 0s - loss: 0.2219 - binary_accuracy: 0.9340\n14336/15000 [===========================&gt;..] - ETA: 0s - loss: 0.2219 - binary_accuracy: 0.9339\n14848/15000 [============================&gt;.] - ETA: 0s - loss: 0.2217 - binary_accuracy: 0.9336\n15000/15000 [==============================] - 5s 356us/step - loss: 0.2216 - binary_accuracy: 0.9334 - val_loss: 0.2939 - val_binary_accuracy: 0.8886\nEpoch 20/20\n\n  512/15000 [&gt;.............................] - ETA: 3s - loss: 0.2332 - binary_accuracy: 0.9238\n 1024/15000 [=&gt;............................] - ETA: 2s - loss: 0.2086 - binary_accuracy: 0.9385\n 1536/15000 [==&gt;...........................] - ETA: 2s - loss: 0.2090 - binary_accuracy: 0.9395\n 2048/15000 [===&gt;..........................] - ETA: 2s - loss: 0.2128 - binary_accuracy: 0.9375\n 2560/15000 [====&gt;.........................] - ETA: 2s - loss: 0.2166 - binary_accuracy: 0.9371\n 3072/15000 [=====&gt;........................] - ETA: 2s - loss: 0.2152 - binary_accuracy: 0.9359\n 3584/15000 [======&gt;.......................] - ETA: 2s - loss: 0.2154 - binary_accuracy: 0.9369\n 4096/15000 [=======&gt;......................] - ETA: 2s - loss: 0.2121 - binary_accuracy: 0.9390\n 4608/15000 [========&gt;.....................] - ETA: 2s - loss: 0.2151 - binary_accuracy: 0.9379\n 5120/15000 [=========&gt;....................] - ETA: 2s - loss: 0.2162 - binary_accuracy: 0.9361\n 5632/15000 [==========&gt;...................] - ETA: 2s - loss: 0.2154 - binary_accuracy: 0.9359\n 6144/15000 [===========&gt;..................] - ETA: 1s - loss: 0.2155 - binary_accuracy: 0.9351\n 6656/15000 [============&gt;.................] - ETA: 1s - loss: 0.2145 - binary_accuracy: 0.9351\n 7168/15000 [=============&gt;................] - ETA: 1s - loss: 0.2140 - binary_accuracy: 0.9348\n 7680/15000 [==============&gt;...............] - ETA: 1s - loss: 0.2138 - binary_accuracy: 0.9353\n 8192/15000 [===============&gt;..............] - ETA: 1s - loss: 0.2161 - binary_accuracy: 0.9333\n 8704/15000 [================&gt;.............] - ETA: 1s - loss: 0.2158 - binary_accuracy: 0.9339\n 9216/15000 [=================&gt;............] - ETA: 1s - loss: 0.2167 - binary_accuracy: 0.9333\n 9728/15000 [==================&gt;...........] - ETA: 1s - loss: 0.2171 - binary_accuracy: 0.9330\n10240/15000 [===================&gt;..........] - ETA: 1s - loss: 0.2171 - binary_accuracy: 0.9327\n10752/15000 [====================&gt;.........] - ETA: 0s - loss: 0.2173 - binary_accuracy: 0.9328\n11264/15000 [=====================&gt;........] - ETA: 0s - loss: 0.2165 - binary_accuracy: 0.9338\n11776/15000 [======================&gt;.......] - ETA: 0s - loss: 0.2158 - binary_accuracy: 0.9343\n12288/15000 [=======================&gt;......] - ETA: 0s - loss: 0.2154 - binary_accuracy: 0.9345\n12800/15000 [========================&gt;.....] - ETA: 0s - loss: 0.2156 - binary_accuracy: 0.9345\n13312/15000 [=========================&gt;....] - ETA: 0s - loss: 0.2145 - binary_accuracy: 0.9352\n13824/15000 [==========================&gt;...] - ETA: 0s - loss: 0.2143 - binary_accuracy: 0.9353\n14336/15000 [===========================&gt;..] - ETA: 0s - loss: 0.2125 - binary_accuracy: 0.9360\n14848/15000 [============================&gt;.] - ETA: 0s - loss: 0.2119 - binary_accuracy: 0.9366\n15000/15000 [==============================] - 5s 358us/step - loss: 0.2120 - binary_accuracy: 0.9366 - val_loss: 0.2893 - val_binary_accuracy: 0.8896\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\ndense_20 (Dense)             (None, 16)                160016    \n_________________________________________________________________\ndense_21 (Dense)             (None, 16)                272       \n_________________________________________________________________\ndense_22 (Dense)             (None, 1)                 17        \n=================================================================\nTotal params: 160,305\nTrainable params: 160,305\nNon-trainable params: 0\n_________________________________________________________________\nFinal metrics: binary_loss:0.2120\nFinal metrics: binary_accuracy=0.9366\nFinal metrics: validation_binary_loss:0.2893\nFinal metrics: validation_binary_accuracy:0.8896\n\n   32/25000 [..............................] - ETA: 2s\n  704/25000 [..............................] - ETA: 1s\n 1504/25000 [&gt;.............................] - ETA: 1s\n 2304/25000 [=&gt;............................] - ETA: 1s\n 3104/25000 [==&gt;...........................] - ETA: 1s\n 3904/25000 [===&gt;..........................] - ETA: 1s\n 4704/25000 [====&gt;.........................] - ETA: 1s\n 5472/25000 [=====&gt;........................] - ETA: 1s\n 6272/25000 [======&gt;.......................] - ETA: 1s\n 7072/25000 [=======&gt;......................] - ETA: 1s\n 7872/25000 [========&gt;.....................] - ETA: 1s\n 8640/25000 [=========&gt;....................] - ETA: 1s\n 9440/25000 [==========&gt;...................] - ETA: 1s\n10240/25000 [===========&gt;..................] - ETA: 0s\n11040/25000 [============&gt;.................] - ETA: 0s\n11808/25000 [=============&gt;................] - ETA: 0s\n12608/25000 [==============&gt;...............] - ETA: 0s\n13376/25000 [===============&gt;..............] - ETA: 0s\n14144/25000 [===============&gt;..............] - ETA: 0s\n14944/25000 [================&gt;.............] - ETA: 0s\n15744/25000 [=================&gt;............] - ETA: 0s\n16480/25000 [==================&gt;...........] - ETA: 0s\n17280/25000 [===================&gt;..........] - ETA: 0s\n18048/25000 [====================&gt;.........] - ETA: 0s\n18784/25000 [=====================&gt;........] - ETA: 0s\n19520/25000 [======================&gt;.......] - ETA: 0s\n20256/25000 [=======================&gt;......] - ETA: 0s\n20992/25000 [========================&gt;.....] - ETA: 0s\n21728/25000 [=========================&gt;....] - ETA: 0s\n22464/25000 [=========================&gt;....] - ETA: 0s\n23200/25000 [==========================&gt;...] - ETA: 0s\n23904/25000 [===========================&gt;..] - ETA: 0s\n24640/25000 [============================&gt;.] - ETA: 0s\n25000/25000 [==============================] - 2s 66us/step\nAverage Probability Results:\n[0.3039212052822113, 0.88328]\n()\nPredictions Results:\n[[0.35452196]\n [0.9922935 ]\n [0.8634253 ]\n ...\n [0.15708613]\n [0.24914925]\n [0.44241348]]\nMLflow Run ID: 7b41855462d143c78e9a02018f7ef132\nKeras model saved locally at /databricks/driver/keras_models/7b41855462d143c78e9a02018f7ef132\nWriting TensorFlow events locally to /tmp/tmpUqRrUr\n\nUploading TensorFlow events as a run artifact.\n(&#39;loss function use&#39;, &#39;binary_crossentropy&#39;)\n</div>"]}}],"execution_count":8},{"cell_type":"code","source":["args = Params(3, 30, 16, \"binary_crossentropy\")\nrunReviews(args, False)"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Using Experimental parameters\n(&#39;hidden_layers:&#39;, 3)\n(&#39;output:&#39;, 16)\n(&#39;epochs:&#39;, 30)\n(&#39;loss:&#39;, &#39;binary_crossentropy&#39;)\nExperiment Model:\nTrain on 15000 samples, validate on 10000 samples\nEpoch 1/30\n\n  512/15000 [&gt;.............................] - ETA: 10s - loss: 0.6937 - binary_accuracy: 0.5078\n 1024/15000 [=&gt;............................] - ETA: 6s - loss: 0.6937 - binary_accuracy: 0.5137 \n 1536/15000 [==&gt;...........................] - ETA: 5s - loss: 0.6933 - binary_accuracy: 0.5078\n 2048/15000 [===&gt;..........................] - ETA: 4s - loss: 0.6933 - binary_accuracy: 0.5024\n 2560/15000 [====&gt;.........................] - ETA: 4s - loss: 0.6932 - binary_accuracy: 0.5000\n 3072/15000 [=====&gt;........................] - ETA: 3s - loss: 0.6932 - binary_accuracy: 0.4964\n 3584/15000 [======&gt;.......................] - ETA: 3s - loss: 0.6931 - binary_accuracy: 0.4978\n 4096/15000 [=======&gt;......................] - ETA: 3s - loss: 0.6929 - binary_accuracy: 0.4971\n 4608/15000 [========&gt;.....................] - ETA: 2s - loss: 0.6927 - binary_accuracy: 0.4998\n 5120/15000 [=========&gt;....................] - ETA: 2s - loss: 0.6925 - binary_accuracy: 0.5004\n 5632/15000 [==========&gt;...................] - ETA: 2s - loss: 0.6924 - binary_accuracy: 0.5011\n 6144/15000 [===========&gt;..................] - ETA: 2s - loss: 0.6922 - binary_accuracy: 0.5010\n 6656/15000 [============&gt;.................] - ETA: 2s - loss: 0.6920 - binary_accuracy: 0.5024\n 7168/15000 [=============&gt;................] - ETA: 2s - loss: 0.6920 - binary_accuracy: 0.5008\n 7680/15000 [==============&gt;...............] - ETA: 1s - loss: 0.6920 - binary_accuracy: 0.4982\n 8192/15000 [===============&gt;..............] - ETA: 1s - loss: 0.6918 - binary_accuracy: 0.5010\n 8704/15000 [================&gt;.............] - ETA: 1s - loss: 0.6917 - binary_accuracy: 0.5009\n 9216/15000 [=================&gt;............] - ETA: 1s - loss: 0.6914 - binary_accuracy: 0.5015\n 9728/15000 [==================&gt;...........] - ETA: 1s - loss: 0.6913 - binary_accuracy: 0.5009\n10240/15000 [===================&gt;..........] - ETA: 1s - loss: 0.6912 - binary_accuracy: 0.4997\n10752/15000 [====================&gt;.........] - ETA: 1s - loss: 0.6912 - binary_accuracy: 0.4985\n11264/15000 [=====================&gt;........] - ETA: 0s - loss: 0.6912 - binary_accuracy: 0.4971\n11776/15000 [======================&gt;.......] - ETA: 0s - loss: 0.6911 - binary_accuracy: 0.4979\n12288/15000 [=======================&gt;......] - ETA: 0s - loss: 0.6910 - binary_accuracy: 0.4967\n12800/15000 [========================&gt;.....] - ETA: 0s - loss: 0.6909 - binary_accuracy: 0.4964\n13312/15000 [=========================&gt;....] - ETA: 0s - loss: 0.6909 - binary_accuracy: 0.4956\n13824/15000 [==========================&gt;...] - ETA: 0s - loss: 0.6907 - binary_accuracy: 0.4966\n14336/15000 [===========================&gt;..] - ETA: 0s - loss: 0.6904 - binary_accuracy: 0.4971\n14848/15000 [============================&gt;.] - ETA: 0s - loss: 0.6902 - binary_accuracy: 0.4985\n15000/15000 [==============================] - 6s 381us/step - loss: 0.6902 - binary_accuracy: 0.4981 - val_loss: 0.6844 - val_binary_accuracy: 0.5108\nEpoch 2/30\n\n  512/15000 [&gt;.............................] - ETA: 3s - loss: 0.6803 - binary_accuracy: 0.5508\n 1024/15000 [=&gt;............................] - ETA: 3s - loss: 0.6807 - binary_accuracy: 0.5420\n 1536/15000 [==&gt;...........................] - ETA: 3s - loss: 0.6820 - binary_accuracy: 0.5208\n 2048/15000 [===&gt;..........................] - ETA: 2s - loss: 0.6821 - binary_accuracy: 0.5142\n 2560/15000 [====&gt;.........................] - ETA: 2s - loss: 0.6821 - binary_accuracy: 0.5094\n 3072/15000 [=====&gt;........................] - ETA: 2s - loss: 0.6823 - binary_accuracy: 0.5055\n 3584/15000 [======&gt;.......................] - ETA: 2s - loss: 0.6818 - binary_accuracy: 0.5095\n 4096/15000 [=======&gt;......................] - ETA: 2s - loss: 0.6816 - binary_accuracy: 0.5083\n 4608/15000 [========&gt;.....................] - ETA: 2s - loss: 0.6813 - binary_accuracy: 0.5095\n 5120/15000 [=========&gt;....................] - ETA: 2s - loss: 0.6812 - binary_accuracy: 0.5078\n 5632/15000 [==========&gt;...................] - ETA: 2s - loss: 0.6812 - binary_accuracy: 0.5055\n 6144/15000 [===========&gt;..................] - ETA: 2s - loss: 0.6811 - binary_accuracy: 0.5060\n 6656/15000 [============&gt;.................] - ETA: 1s - loss: 0.6808 - binary_accuracy: 0.5056\n 7168/15000 [=============&gt;................] - ETA: 1s - loss: 0.6804 - binary_accuracy: 0.5061\n 7680/15000 [==============&gt;...............] - ETA: 1s - loss: 0.6802 - binary_accuracy: 0.5066\n 8192/15000 [===============&gt;..............] - ETA: 1s - loss: 0.6801 - binary_accuracy: 0.5066\n 8704/15000 [================&gt;.............] - ETA: 1s - loss: 0.6802 - binary_accuracy: 0.5047\n 9216/15000 [=================&gt;............] - ETA: 1s - loss: 0.6799 - binary_accuracy: 0.5060\n 9728/15000 [==================&gt;...........] - ETA: 1s - loss: 0.6797 - binary_accuracy: 0.5061\n10240/15000 [===================&gt;..........] - ETA: 1s - loss: 0.6795 - binary_accuracy: 0.5072\n10752/15000 [====================&gt;.........] - ETA: 0s - loss: 0.6796 - binary_accuracy: 0.5049\n11264/15000 [=====================&gt;........] - ETA: 0s - loss: 0.6793 - binary_accuracy: 0.5054\n11776/15000 [======================&gt;.......] - ETA: 0s - loss: 0.6790 - binary_accuracy: 0.5053\n12288/15000 [=======================&gt;......] - ETA: 0s - loss: 0.6785 - binary_accuracy: 0.5074\n12800/15000 [========================&gt;.....] - ETA: 0s - loss: 0.6783 - binary_accuracy: 0.5072\n13312/15000 [=========================&gt;....] - ETA: 0s - loss: 0.6779 - binary_accuracy: 0.5077\n13824/15000 [==========================&gt;...] - ETA: 0s - loss: 0.6778 - binary_accuracy: 0.5070\n14336/15000 [===========================&gt;..] - ETA: 0s - loss: 0.6776 - binary_accuracy: 0.5080\n14848/15000 [============================&gt;.] - ETA: 0s - loss: 0.6775 - binary_accuracy: 0.5077\n15000/15000 [==============================] - 5s 350us/step - loss: 0.6773 - binary_accuracy: 0.5087 - val_loss: 0.6690 - val_binary_accuracy: 0.5216\nEpoch 3/30\n\n  512/15000 [&gt;.............................] - ETA: 3s - loss: 0.6744 - binary_accuracy: 0.4766\n 1024/15000 [=&gt;............................] - ETA: 3s - loss: 0.6684 - binary_accuracy: 0.5166\n 1536/15000 [==&gt;...........................] - ETA: 3s - loss: 0.6679 - binary_accuracy: 0.5150\n 2048/15000 [===&gt;..........................] - ETA: 2s - loss: 0.6674 - binary_accuracy: 0.5161\n 2560/15000 [====&gt;.........................] - ETA: 2s - loss: 0.6657 - binary_accuracy: 0.5250\n 3072/15000 [=====&gt;........................] - ETA: 2s - loss: 0.6660 - binary_accuracy: 0.5189\n 3584/15000 [======&gt;.......................] - ETA: 2s - loss: 0.6657 - binary_accuracy: 0.5226\n 4096/15000 [=======&gt;......................] - ETA: 2s - loss: 0.6646 - binary_accuracy: 0.5239\n 4608/15000 [========&gt;.....................] - ETA: 2s - loss: 0.6650 - binary_accuracy: 0.5208\n 5120/15000 [=========&gt;....................] - ETA: 2s - loss: 0.6643 - binary_accuracy: 0.5266\n 5632/15000 [==========&gt;...................] - ETA: 2s - loss: 0.6642 - binary_accuracy: 0.5245\n 6144/15000 [===========&gt;..................] - ETA: 2s - loss: 0.6633 - binary_accuracy: 0.5295\n 6656/15000 [============&gt;.................] - ETA: 1s - loss: 0.6626 - binary_accuracy: 0.5309\n 7168/15000 [=============&gt;................] - ETA: 1s - loss: 0.6625 - binary_accuracy: 0.5310\n 7680/15000 [==============&gt;...............] - ETA: 1s - loss: 0.6626 - binary_accuracy: 0.5281\n 8192/15000 [===============&gt;..............] - ETA: 1s - loss: 0.6621 - binary_accuracy: 0.5305\n 8704/15000 [================&gt;.............] - ETA: 1s - loss: 0.6621 - binary_accuracy: 0.5300\n 9216/15000 [=================&gt;............] - ETA: 1s - loss: 0.6619 - binary_accuracy: 0.5304\n 9728/15000 [==================&gt;...........] - ETA: 1s - loss: 0.6616 - binary_accuracy: 0.5315\n10240/15000 [===================&gt;..........] - ETA: 1s - loss: 0.6614 - binary_accuracy: 0.5317\n10752/15000 [====================&gt;.........] - ETA: 0s - loss: 0.6613 - binary_accuracy: 0.5313\n11264/15000 [=====================&gt;........] - ETA: 0s - loss: 0.6608 - binary_accuracy: 0.5334\n11776/15000 [======================&gt;.......] - ETA: 0s - loss: 0.6610 - binary_accuracy: 0.5324\n12288/15000 [=======================&gt;......] - ETA: 0s - loss: 0.6603 - binary_accuracy: 0.5347\n12800/15000 [========================&gt;.....] - ETA: 0s - loss: 0.6601 - binary_accuracy: 0.5356\n13312/15000 [=========================&gt;....] - ETA: 0s - loss: 0.6598 - binary_accuracy: 0.5358\n13824/15000 [==========================&gt;...] - ETA: 0s - loss: 0.6597 - binary_accuracy: 0.5356\n14336/15000 [===========================&gt;..] - ETA: 0s - loss: 0.6596 - binary_accuracy: 0.5347\n14848/15000 [============================&gt;.] - ETA: 0s - loss: 0.6592 - binary_accuracy: 0.5369\n15000/15000 [==============================] - 5s 359us/step - loss: 0.6591 - binary_accuracy: 0.5363 - val_loss: 0.6511 - val_binary_accuracy: 0.5635\nEpoch 4/30\n\n  512/15000 [&gt;.............................] - ETA: 3s - loss: 0.6479 - binary_accuracy: 0.5566\n 1024/15000 [=&gt;............................] - ETA: 3s - loss: 0.6488 - binary_accuracy: 0.5527\n 1536/15000 [==&gt;...........................] - ETA: 3s - loss: 0.6505 - binary_accuracy: 0.5469\n 2048/15000 [===&gt;..........................] - ETA: 2s - loss: 0.6486 - binary_accuracy: 0.5576\n 2560/15000 [====&gt;.........................] - ETA: 2s - loss: 0.6470 - binary_accuracy: 0.5652\n 3072/15000 [=====&gt;........................] - ETA: 2s - loss: 0.6470 - binary_accuracy: 0.5651\n 3584/15000 [======&gt;.......................] - ETA: 2s - loss: 0.6458 - binary_accuracy: 0.5667\n 4096/15000 [=======&gt;......................] - ETA: 2s - loss: 0.6457 - binary_accuracy: 0.5674\n 4608/15000 [========&gt;.....................] - ETA: 2s - loss: 0.6463 - binary_accuracy: 0.5634\n 5120/15000 [=========&gt;....................] - ETA: 2s - loss: 0.6465 - binary_accuracy: 0.5629\n 5632/15000 [==========&gt;...................] - ETA: 2s - loss: 0.6465 - binary_accuracy: 0.5625\n 6144/15000 [===========&gt;..................] - ETA: 1s - loss: 0.6457 - binary_accuracy: 0.5633\n 6656/15000 [============&gt;.................] - ETA: 1s - loss: 0.6456 - binary_accuracy: 0.5631\n 7168/15000 [=============&gt;................] - ETA: 1s - loss: 0.6453 - binary_accuracy: 0.5625\n 7680/15000 [==============&gt;...............] - ETA: 1s - loss: 0.6453 - binary_accuracy: 0.5621\n 8192/15000 [===============&gt;..............] - ETA: 1s - loss: 0.6445 - binary_accuracy: 0.5643\n 8704/15000 [================&gt;.............] - ETA: 1s - loss: 0.6442 - binary_accuracy: 0.5634\n 9216/15000 [=================&gt;............] - ETA: 1s - loss: 0.6438 - binary_accuracy: 0.5638\n 9728/15000 [==================&gt;...........] - ETA: 1s - loss: 0.6430 - binary_accuracy: 0.5663\n10240/15000 [===================&gt;..........] - ETA: 1s - loss: 0.6423 - binary_accuracy: 0.5673\n10752/15000 [====================&gt;.........] - ETA: 0s - loss: 0.6421 - binary_accuracy: 0.5659\n11264/15000 [=====================&gt;........] - ETA: 0s - loss: 0.6413 - binary_accuracy: 0.5669\n11776/15000 [======================&gt;.......] - ETA: 0s - loss: 0.6412 - binary_accuracy: 0.5656\n12288/15000 [=======================&gt;......] - ETA: 0s - loss: 0.6407 - binary_accuracy: 0.5662\n12800/15000 [========================&gt;.....] - ETA: 0s - loss: 0.6407 - binary_accuracy: 0.5655\n13312/15000 [=========================&gt;....] - ETA: 0s - loss: 0.6411 - binary_accuracy: 0.5647\n13824/15000 [==========================&gt;...] - ETA: 0s - loss: 0.6408 - binary_accuracy: 0.5670\n14336/15000 [===========================&gt;..] - ETA: 0s - loss: 0.6400 - binary_accuracy: 0.5691\n14848/15000 [============================&gt;.] - ETA: 0s - loss: 0.6394 - binary_accuracy: 0.5706\n15000/15000 [==============================] - 5s 354us/step - loss: 0.6392 - binary_accuracy: 0.5712 - val_loss: 0.6330 - val_binary_accuracy: 0.5711\nEpoch 5/30\n\n  512/15000 [&gt;.............................] - ETA: 3s - loss: 0.6294 - binary_accuracy: 0.5723\n 1024/15000 [=&gt;............................] - ETA: 3s - loss: 0.6260 - binary_accuracy: 0.5674\n 1536/15000 [==&gt;...........................] - ETA: 3s - loss: 0.6290 - binary_accuracy: 0.5579\n 2048/15000 [===&gt;..........................] - ETA: 2s - loss: 0.6291 - binary_accuracy: 0.5674\n 2560/15000 [====&gt;.........................] - ETA: 2s - loss: 0.6267 - binary_accuracy: 0.5785\n 3072/15000 [=====&gt;........................] - ETA: 2s - loss: 0.6268 - binary_accuracy: 0.5771\n 3584/15000 [======&gt;.......................] - ETA: 2s - loss: 0.6265 - binary_accuracy: 0.5831\n 4096/15000 [=======&gt;......................] - ETA: 2s - loss: 0.6256 - binary_accuracy: 0.5847\n 4608/15000 [========&gt;.....................] - ETA: 2s - loss: 0.6249 - binary_accuracy: 0.5857\n 5120/15000 [=========&gt;....................] - ETA: 2s - loss: 0.6243 - binary_accuracy: 0.5865\n 5632/15000 [==========&gt;...................] - ETA: 2s - loss: 0.6231 - binary_accuracy: 0.5891\n 6144/15000 [===========&gt;..................] - ETA: 1s - loss: 0.6227 - binary_accuracy: 0.5884\n 6656/15000 [============&gt;.................] - ETA: 1s - loss: 0.6220 - binary_accuracy: 0.5883\n 7168/15000 [=============&gt;................] - ETA: 1s - loss: 0.6229 - binary_accuracy: 0.5855\n 7680/15000 [==============&gt;...............] - ETA: 1s - loss: 0.6219 - binary_accuracy: 0.5870\n 8192/15000 [===============&gt;..............] - ETA: 1s - loss: 0.6219 - binary_accuracy: 0.5878\n 8704/15000 [================&gt;.............] - ETA: 1s - loss: 0.6216 - binary_accuracy: 0.5881\n 9216/15000 [=================&gt;............] - ETA: 1s - loss: 0.6211 - binary_accuracy: 0.5884\n 9728/15000 [==================&gt;...........] - ETA: 1s - loss: 0.6209 - binary_accuracy: 0.5883\n10240/15000 [===================&gt;..........] - ETA: 1s - loss: 0.6211 - binary_accuracy: 0.5880\n10752/15000 [====================&gt;.........] - ETA: 0s - loss: 0.6208 - binary_accuracy: 0.5885\n11264/15000 [=====================&gt;........] - ETA: 0s - loss: 0.6210 - binary_accuracy: 0.5878\n11776/15000 [======================&gt;.......] - ETA: 0s - loss: 0.6210 - binary_accuracy: 0.5878\n12288/15000 [=======================&gt;......] - ETA: 0s - loss: 0.6206 - binary_accuracy: 0.5881\n12800/15000 [========================&gt;.....] - ETA: 0s - loss: 0.6206 - binary_accuracy: 0.5881\n13312/15000 [=========================&gt;....] - ETA: 0s - loss: 0.6205 - binary_accuracy: 0.5888\n13824/15000 [==========================&gt;...] - ETA: 0s - loss: 0.6202 - binary_accuracy: 0.5894\n14336/15000 [===========================&gt;..] - ETA: 0s - loss: 0.6198 - binary_accuracy: 0.5919\n14848/15000 [============================&gt;.] - ETA: 0s - loss: 0.6196 - binary_accuracy: 0.5915\n15000/15000 [==============================] - 5s 354us/step - loss: 0.6197 - binary_accuracy: 0.5909 - val_loss: 0.6162 - val_binary_accuracy: 0.6232\nEpoch 6/30\n\n  512/15000 [&gt;.............................] - ETA: 3s - loss: 0.6056 - binary_accuracy: 0.6230\n 1024/15000 [=&gt;............................] - ETA: 2s - loss: 0.6058 - binary_accuracy: 0.6221\n 1536/15000 [==&gt;...........................] - ETA: 2s - loss: 0.6083 - binary_accuracy: 0.6172\n 2048/15000 [===&gt;..........................] - ETA: 2s - loss: 0.6066 - binary_accuracy: 0.6250\n 2560/15000 [====&gt;.........................] - ETA: 2s - loss: 0.6050 - binary_accuracy: 0.6207\n 3072/15000 [=====&gt;........................] - ETA: 2s - loss: 0.6031 - binary_accuracy: 0.6240\n 3584/15000 [======&gt;.......................] - ETA: 2s - loss: 0.6016 - binary_accuracy: 0.6264\n 4096/15000 [=======&gt;......................] - ETA: 2s - loss: 0.6008 - binary_accuracy: 0.6230\n 4608/15000 [========&gt;.....................] - ETA: 2s - loss: 0.6022 - binary_accuracy: 0.6200\n 5120/15000 [=========&gt;....................] - ETA: 2s - loss: 0.6038 - binary_accuracy: 0.6162\n 5632/15000 [==========&gt;...................] - ETA: 2s - loss: 0.6037 - binary_accuracy: 0.6159\n 6144/15000 [===========&gt;..................] - ETA: 1s - loss: 0.6034 - binary_accuracy: 0.6177\n 6656/15000 [============&gt;.................] - ETA: 1s - loss: 0.6038 - binary_accuracy: 0.6178\n 7168/15000 [=============&gt;................] - ETA: 1s - loss: 0.6037 - binary_accuracy: 0.6193\n 7680/15000 [==============&gt;...............] - ETA: 1s - loss: 0.6037 - binary_accuracy: 0.6173\n 8192/15000 [===============&gt;..............] - ETA: 1s - loss: 0.6037 - binary_accuracy: 0.6185\n 8704/15000 [================&gt;.............] - ETA: 1s - loss: 0.6040 - binary_accuracy: 0.6156\n 9216/15000 [=================&gt;............] - ETA: 1s - loss: 0.6036 - binary_accuracy: 0.6166\n 9728/15000 [==================&gt;...........] - ETA: 1s - loss: 0.6035 - binary_accuracy: 0.6172\n10240/15000 [===================&gt;..........] - ETA: 1s - loss: 0.6029 - binary_accuracy: 0.6188\n10752/15000 [====================&gt;.........] - ETA: 0s - loss: 0.6034 - binary_accuracy: 0.6176\n11264/15000 [=====================&gt;........] - ETA: 0s - loss: 0.6030 - binary_accuracy: 0.6187\n11776/15000 [======================&gt;.......] - ETA: 0s - loss: 0.6024 - binary_accuracy: 0.6210\n12288/15000 [=======================&gt;......] - ETA: 0s - loss: 0.6029 - binary_accuracy: 0.6195\n12800/15000 [========================&gt;.....] - ETA: 0s - loss: 0.6023 - binary_accuracy: 0.6205\n13312/15000 [=========================&gt;....] - ETA: 0s - loss: 0.6020 - binary_accuracy: 0.6213\n13824/15000 [==========================&gt;...] - ETA: 0s - loss: 0.6017 - binary_accuracy: 0.6221\n14336/15000 [===========================&gt;..] - ETA: 0s - loss: 0.6015 - binary_accuracy: 0.6231\n14848/15000 [============================&gt;.] - ETA: 0s - loss: 0.6009 - binary_accuracy: 0.6237\n15000/15000 [==============================] - 5s 354us/step - loss: 0.6006 - binary_accuracy: 0.6241 - val_loss: 0.5998 - val_binary_accuracy: 0.6283\nEpoch 7/30\n\n  512/15000 [&gt;.............................] - ETA: 3s - loss: 0.5838 - binary_accuracy: 0.6328\n 1024/15000 [=&gt;............................] - ETA: 2s - loss: 0.5875 - binary_accuracy: 0.6416\n 1536/15000 [==&gt;...........................] - ETA: 2s - loss: 0.5886 - binary_accuracy: 0.6419\n 2048/15000 [===&gt;..........................] - ETA: 2s - loss: 0.5888 - binary_accuracy: 0.6475\n 2560/15000 [====&gt;.........................] - ETA: 2s - loss: 0.5906 - binary_accuracy: 0.6453\n 3072/15000 [=====&gt;........................] - ETA: 2s - loss: 0.5925 - binary_accuracy: 0.6351\n 3584/15000 [======&gt;.......................] - ETA: 2s - loss: 0.5922 - binary_accuracy: 0.6373\n 4096/15000 [=======&gt;......................] - ETA: 2s - loss: 0.5910 - binary_accuracy: 0.6423\n 4608/15000 [========&gt;.....................] - ETA: 2s - loss: 0.5906 - binary_accuracy: 0.6456\n 5120/15000 [=========&gt;....................] - ETA: 2s - loss: 0.5887 - binary_accuracy: 0.6488\n 5632/15000 [==========&gt;...................] - ETA: 2s - loss: 0.5874 - binary_accuracy: 0.6493\n 6144/15000 [===========&gt;..................] - ETA: 1s - loss: 0.5871 - binary_accuracy: 0.6484\n 6656/15000 [============&gt;.................] - ETA: 1s - loss: 0.5859 - binary_accuracy: 0.6490\n 7168/15000 [=============&gt;................] - ETA: 1s - loss: 0.5858 - binary_accuracy: 0.6487\n 7680/15000 [==============&gt;...............] - ETA: 1s - loss: 0.5856 - binary_accuracy: 0.6490\n 8192/15000 [===============&gt;..............] - ETA: 1s - loss: 0.5852 - binary_accuracy: 0.6481\n 8704/15000 [================&gt;.............] - ETA: 1s - loss: 0.5840 - binary_accuracy: 0.6495\n 9216/15000 [=================&gt;............] - ETA: 1s - loss: 0.5836 - binary_accuracy: 0.6504\n 9728/15000 [==================&gt;...........] - ETA: 1s - loss: 0.5828 - binary_accuracy: 0.6521\n10240/15000 [===================&gt;..........] - ETA: 1s - loss: 0.5830 - binary_accuracy: 0.6520\n10752/15000 [====================&gt;.........] - ETA: 0s - loss: 0.5835 - binary_accuracy: 0.6509\n11264/15000 [=====================&gt;........] - ETA: 0s - loss: 0.5836 - binary_accuracy: 0.6520\n11776/15000 [======================&gt;.......] - ETA: 0s - loss: 0.5835 - binary_accuracy: 0.6525\n12288/15000 [=======================&gt;......] - ETA: 0s - loss: 0.5837 - binary_accuracy: 0.6527\n12800/15000 [========================&gt;.....] - ETA: 0s - loss: 0.5840 - binary_accuracy: 0.6532\n13312/15000 [=========================&gt;....] - ETA: 0s - loss: 0.5836 - binary_accuracy: 0.6545\n13824/15000 [==========================&gt;...] - ETA: 0s - loss: 0.5830 - binary_accuracy: 0.6554\n14336/15000 [===========================&gt;..] - ETA: 0s - loss: 0.5827 - binary_accuracy: 0.6562\n14848/15000 [============================&gt;.] - ETA: 0s - loss: 0.5820 - binary_accuracy: 0.6576\n15000/15000 [==============================] - 5s 354us/step - loss: 0.5821 - binary_accuracy: 0.6574 - val_loss: 0.5839 - val_binary_accuracy: 0.6764\nEpoch 8/30\n\n  512/15000 [&gt;.............................] - ETA: 3s - loss: 0.5842 - binary_accuracy: 0.6836\n 1024/15000 [=&gt;............................] - ETA: 2s - loss: 0.5739 - binary_accuracy: 0.6904\n 1536/15000 [==&gt;...........................] - ETA: 2s - loss: 0.5761 - binary_accuracy: 0.6849\n 2048/15000 [===&gt;..........................] - ETA: 2s - loss: 0.5756 - binary_accuracy: 0.6826\n 2560/15000 [====&gt;.........................] - ETA: 2s - loss: 0.5778 - binary_accuracy: 0.6832\n 3072/15000 [=====&gt;........................] - ETA: 2s - loss: 0.5789 - binary_accuracy: 0.6849\n 3584/15000 [======&gt;.......................] - ETA: 2s - loss: 0.5787 - binary_accuracy: 0.6842\n 4096/15000 [=======&gt;......................] - ETA: 2s - loss: 0.5768 - binary_accuracy: 0.6892\n 4608/15000 [========&gt;.....................] - ETA: 2s - loss: 0.5754 - binary_accuracy: 0.6905\n 5120/15000 [=========&gt;....................] - ETA: 2s - loss: 0.5765 - binary_accuracy: 0.6873\n 5632/15000 [==========&gt;...................] - ETA: 2s - loss: 0.5761 - binary_accuracy: 0.6884\n 6144/15000 [===========&gt;..................] - ETA: 1s - loss: 0.5751 - binary_accuracy: 0.6925\n 6656/15000 [============&gt;.................] - ETA: 1s - loss: 0.5743 - binary_accuracy: 0.6917\n 7168/15000 [=============&gt;................] - ETA: 1s - loss: 0.5731 - binary_accuracy: 0.6931\n 7680/15000 [==============&gt;...............] - ETA: 1s - loss: 0.5720 - binary_accuracy: 0.6934\n 8192/15000 [===============&gt;..............] - ETA: 1s - loss: 0.5709 - binary_accuracy: 0.6954\n 8704/15000 [================&gt;.............] - ETA: 1s - loss: 0.5700 - binary_accuracy: 0.6946\n 9216/15000 [=================&gt;............] - ETA: 1s - loss: 0.5695 - binary_accuracy: 0.6942\n 9728/15000 [==================&gt;...........] - ETA: 1s - loss: 0.5689 - binary_accuracy: 0.6938\n10240/15000 [===================&gt;..........] - ETA: 1s - loss: 0.5679 - binary_accuracy: 0.6943\n10752/15000 [====================&gt;.........] - ETA: 0s - loss: 0.5676 - binary_accuracy: 0.6940\n11264/15000 [=====================&gt;........] - ETA: 0s - loss: 0.5675 - binary_accuracy: 0.6926\n11776/15000 [======================&gt;.......] - ETA: 0s - loss: 0.5682 - binary_accuracy: 0.6910\n12288/15000 [=======================&gt;......] - ETA: 0s - loss: 0.5675 - binary_accuracy: 0.6934\n12800/15000 [========================&gt;.....] - ETA: 0s - loss: 0.5677 - binary_accuracy: 0.6939\n13312/15000 [=========================&gt;....] - ETA: 0s - loss: 0.5667 - binary_accuracy: 0.6955\n13824/15000 [==========================&gt;...] - ETA: 0s - loss: 0.5655 - binary_accuracy: 0.6971\n14336/15000 [===========================&gt;..] - ETA: 0s - loss: 0.5649 - binary_accuracy: 0.6961\n14848/15000 [============================&gt;.] - ETA: 0s - loss: 0.5646 - binary_accuracy: 0.6961\n15000/15000 [==============================] - 5s 355us/step - loss: 0.5644 - binary_accuracy: 0.6961 - val_loss: 0.5701 - val_binary_accuracy: 0.6925\nEpoch 9/30\n\n  512/15000 [&gt;.............................] - ETA: 3s - loss: 0.5791 - binary_accuracy: 0.6621\n 1024/15000 [=&gt;............................] - ETA: 2s - loss: 0.5663 - binary_accuracy: 0.7012\n 1536/15000 [==&gt;...........................] - ETA: 2s - loss: 0.5599 - binary_accuracy: 0.7116\n 2048/15000 [===&gt;..........................] - ETA: 2s - loss: 0.5538 - binary_accuracy: 0.7241\n 2560/15000 [====&gt;.........................] - ETA: 2s - loss: 0.5499 - binary_accuracy: 0.7270\n 3072/15000 [=====&gt;........................] - ETA: 2s - loss: 0.5486 - binary_accuracy: 0.7204\n 3584/15000 [======&gt;.......................] - ETA: 2s - loss: 0.5513 - binary_accuracy: 0.7179\n 4096/15000 [=======&gt;......................] - ETA: 2s - loss: 0.5517 - binary_accuracy: 0.7214\n 4608/15000 [========&gt;.....................] - ETA: 2s - loss: 0.5481 - binary_accuracy: 0.7276\n 5120/15000 [=========&gt;....................] - ETA: 2s - loss: 0.5505 - binary_accuracy: 0.7258\n 5632/15000 [==========&gt;...................] - ETA: 2s - loss: 0.5513 - binary_accuracy: 0.7248\n 6144/15000 [===========&gt;..................] - ETA: 1s - loss: 0.5498 - binary_accuracy: 0.7274\n 6656/15000 [============&gt;.................] - ETA: 1s - loss: 0.5507 - binary_accuracy: 0.7272\n\n*** WARNING: skipped 42232 bytes of output ***\n\n12288/15000 [=======================&gt;......] - ETA: 0s - loss: 0.3017 - binary_accuracy: 0.9425\n12800/15000 [========================&gt;.....] - ETA: 0s - loss: 0.3011 - binary_accuracy: 0.9428\n13312/15000 [=========================&gt;....] - ETA: 0s - loss: 0.3014 - binary_accuracy: 0.9433\n13824/15000 [==========================&gt;...] - ETA: 0s - loss: 0.3008 - binary_accuracy: 0.9437\n14336/15000 [===========================&gt;..] - ETA: 0s - loss: 0.3004 - binary_accuracy: 0.9441\n14848/15000 [============================&gt;.] - ETA: 0s - loss: 0.3005 - binary_accuracy: 0.9439\n15000/15000 [==============================] - 2s 159us/step - loss: 0.3008 - binary_accuracy: 0.9437 - val_loss: 0.3718 - val_binary_accuracy: 0.8820\nEpoch 24/30\n\n  512/15000 [&gt;.............................] - ETA: 1s - loss: 0.2874 - binary_accuracy: 0.9531\n 1024/15000 [=&gt;............................] - ETA: 1s - loss: 0.2909 - binary_accuracy: 0.9521\n 1536/15000 [==&gt;...........................] - ETA: 1s - loss: 0.2886 - binary_accuracy: 0.9531\n 2048/15000 [===&gt;..........................] - ETA: 1s - loss: 0.2886 - binary_accuracy: 0.9473\n 2560/15000 [====&gt;.........................] - ETA: 1s - loss: 0.2866 - binary_accuracy: 0.9492\n 3072/15000 [=====&gt;........................] - ETA: 1s - loss: 0.2863 - binary_accuracy: 0.9502\n 3584/15000 [======&gt;.......................] - ETA: 1s - loss: 0.2850 - binary_accuracy: 0.9506\n 4096/15000 [=======&gt;......................] - ETA: 1s - loss: 0.2857 - binary_accuracy: 0.9497\n 4608/15000 [========&gt;.....................] - ETA: 1s - loss: 0.2853 - binary_accuracy: 0.9477\n 5120/15000 [=========&gt;....................] - ETA: 1s - loss: 0.2848 - binary_accuracy: 0.9488\n 5632/15000 [==========&gt;...................] - ETA: 1s - loss: 0.2827 - binary_accuracy: 0.9498\n 6144/15000 [===========&gt;..................] - ETA: 0s - loss: 0.2823 - binary_accuracy: 0.9510\n 6656/15000 [============&gt;.................] - ETA: 0s - loss: 0.2833 - binary_accuracy: 0.9491\n 7168/15000 [=============&gt;................] - ETA: 0s - loss: 0.2827 - binary_accuracy: 0.9487\n 7680/15000 [==============&gt;...............] - ETA: 0s - loss: 0.2822 - binary_accuracy: 0.9490\n 8192/15000 [===============&gt;..............] - ETA: 0s - loss: 0.2824 - binary_accuracy: 0.9489\n 8704/15000 [================&gt;.............] - ETA: 0s - loss: 0.2829 - binary_accuracy: 0.9484\n 9216/15000 [=================&gt;............] - ETA: 0s - loss: 0.2826 - binary_accuracy: 0.9484\n 9728/15000 [==================&gt;...........] - ETA: 0s - loss: 0.2824 - binary_accuracy: 0.9490\n10240/15000 [===================&gt;..........] - ETA: 0s - loss: 0.2819 - binary_accuracy: 0.9487\n10752/15000 [====================&gt;.........] - ETA: 0s - loss: 0.2819 - binary_accuracy: 0.9490\n11264/15000 [=====================&gt;........] - ETA: 0s - loss: 0.2812 - binary_accuracy: 0.9494\n11776/15000 [======================&gt;.......] - ETA: 0s - loss: 0.2812 - binary_accuracy: 0.9490\n12288/15000 [=======================&gt;......] - ETA: 0s - loss: 0.2809 - binary_accuracy: 0.9487\n12800/15000 [========================&gt;.....] - ETA: 0s - loss: 0.2815 - binary_accuracy: 0.9484\n13312/15000 [=========================&gt;....] - ETA: 0s - loss: 0.2824 - binary_accuracy: 0.9478\n13824/15000 [==========================&gt;...] - ETA: 0s - loss: 0.2820 - binary_accuracy: 0.9476\n14336/15000 [===========================&gt;..] - ETA: 0s - loss: 0.2816 - binary_accuracy: 0.9478\n14848/15000 [============================&gt;.] - ETA: 0s - loss: 0.2815 - binary_accuracy: 0.9478\n15000/15000 [==============================] - 2s 160us/step - loss: 0.2811 - binary_accuracy: 0.9479 - val_loss: 0.3640 - val_binary_accuracy: 0.8790\nEpoch 25/30\n\n  512/15000 [&gt;.............................] - ETA: 1s - loss: 0.2737 - binary_accuracy: 0.9453\n 1024/15000 [=&gt;............................] - ETA: 1s - loss: 0.2751 - binary_accuracy: 0.9502\n 1536/15000 [==&gt;...........................] - ETA: 1s - loss: 0.2776 - binary_accuracy: 0.9486\n 2048/15000 [===&gt;..........................] - ETA: 1s - loss: 0.2715 - binary_accuracy: 0.9526\n 2560/15000 [====&gt;.........................] - ETA: 1s - loss: 0.2726 - binary_accuracy: 0.9500\n 3072/15000 [=====&gt;........................] - ETA: 1s - loss: 0.2715 - binary_accuracy: 0.9508\n 3584/15000 [======&gt;.......................] - ETA: 1s - loss: 0.2714 - binary_accuracy: 0.9509\n 4096/15000 [=======&gt;......................] - ETA: 1s - loss: 0.2716 - binary_accuracy: 0.9490\n 4608/15000 [========&gt;.....................] - ETA: 1s - loss: 0.2716 - binary_accuracy: 0.9481\n 5120/15000 [=========&gt;....................] - ETA: 1s - loss: 0.2734 - binary_accuracy: 0.9471\n 5632/15000 [==========&gt;...................] - ETA: 1s - loss: 0.2715 - binary_accuracy: 0.9473\n 6144/15000 [===========&gt;..................] - ETA: 0s - loss: 0.2716 - binary_accuracy: 0.9476\n 6656/15000 [============&gt;.................] - ETA: 0s - loss: 0.2709 - binary_accuracy: 0.9477\n 7168/15000 [=============&gt;................] - ETA: 0s - loss: 0.2690 - binary_accuracy: 0.9492\n 7680/15000 [==============&gt;...............] - ETA: 0s - loss: 0.2685 - binary_accuracy: 0.9491\n 8192/15000 [===============&gt;..............] - ETA: 0s - loss: 0.2671 - binary_accuracy: 0.9491\n 8704/15000 [================&gt;.............] - ETA: 0s - loss: 0.2674 - binary_accuracy: 0.9486\n 9216/15000 [=================&gt;............] - ETA: 0s - loss: 0.2676 - binary_accuracy: 0.9484\n 9728/15000 [==================&gt;...........] - ETA: 0s - loss: 0.2677 - binary_accuracy: 0.9483\n10240/15000 [===================&gt;..........] - ETA: 0s - loss: 0.2664 - binary_accuracy: 0.9487\n10752/15000 [====================&gt;.........] - ETA: 0s - loss: 0.2666 - binary_accuracy: 0.9483\n11264/15000 [=====================&gt;........] - ETA: 0s - loss: 0.2660 - binary_accuracy: 0.9487\n11776/15000 [======================&gt;.......] - ETA: 0s - loss: 0.2651 - binary_accuracy: 0.9491\n12288/15000 [=======================&gt;......] - ETA: 0s - loss: 0.2642 - binary_accuracy: 0.9495\n12800/15000 [========================&gt;.....] - ETA: 0s - loss: 0.2638 - binary_accuracy: 0.9496\n13312/15000 [=========================&gt;....] - ETA: 0s - loss: 0.2634 - binary_accuracy: 0.9495\n13824/15000 [==========================&gt;...] - ETA: 0s - loss: 0.2627 - binary_accuracy: 0.9499\n14336/15000 [===========================&gt;..] - ETA: 0s - loss: 0.2624 - binary_accuracy: 0.9503\n14848/15000 [============================&gt;.] - ETA: 0s - loss: 0.2623 - binary_accuracy: 0.9503\n15000/15000 [==============================] - 2s 161us/step - loss: 0.2617 - binary_accuracy: 0.9507 - val_loss: 0.3497 - val_binary_accuracy: 0.8827\nEpoch 26/30\n\n  512/15000 [&gt;.............................] - ETA: 1s - loss: 0.2462 - binary_accuracy: 0.9648\n 1024/15000 [=&gt;............................] - ETA: 1s - loss: 0.2413 - binary_accuracy: 0.9639\n 1536/15000 [==&gt;...........................] - ETA: 1s - loss: 0.2401 - binary_accuracy: 0.9590\n 2048/15000 [===&gt;..........................] - ETA: 1s - loss: 0.2422 - binary_accuracy: 0.9580\n 2560/15000 [====&gt;.........................] - ETA: 1s - loss: 0.2395 - binary_accuracy: 0.9574\n 3072/15000 [=====&gt;........................] - ETA: 1s - loss: 0.2422 - binary_accuracy: 0.9551\n 3584/15000 [======&gt;.......................] - ETA: 1s - loss: 0.2424 - binary_accuracy: 0.9548\n 4096/15000 [=======&gt;......................] - ETA: 1s - loss: 0.2449 - binary_accuracy: 0.9541\n 4608/15000 [========&gt;.....................] - ETA: 1s - loss: 0.2469 - binary_accuracy: 0.9527\n 5120/15000 [=========&gt;....................] - ETA: 1s - loss: 0.2488 - binary_accuracy: 0.9527\n 5632/15000 [==========&gt;...................] - ETA: 1s - loss: 0.2485 - binary_accuracy: 0.9535\n 6144/15000 [===========&gt;..................] - ETA: 0s - loss: 0.2463 - binary_accuracy: 0.9544\n 6656/15000 [============&gt;.................] - ETA: 0s - loss: 0.2478 - binary_accuracy: 0.9527\n 7168/15000 [=============&gt;................] - ETA: 0s - loss: 0.2470 - binary_accuracy: 0.9527\n 7680/15000 [==============&gt;...............] - ETA: 0s - loss: 0.2467 - binary_accuracy: 0.9531\n 8192/15000 [===============&gt;..............] - ETA: 0s - loss: 0.2467 - binary_accuracy: 0.9524\n 8704/15000 [================&gt;.............] - ETA: 0s - loss: 0.2460 - binary_accuracy: 0.9524\n 9216/15000 [=================&gt;............] - ETA: 0s - loss: 0.2465 - binary_accuracy: 0.9520\n 9728/15000 [==================&gt;...........] - ETA: 0s - loss: 0.2468 - binary_accuracy: 0.9516\n10240/15000 [===================&gt;..........] - ETA: 0s - loss: 0.2464 - binary_accuracy: 0.9517\n10752/15000 [====================&gt;.........] - ETA: 0s - loss: 0.2457 - binary_accuracy: 0.9523\n11264/15000 [=====================&gt;........] - ETA: 0s - loss: 0.2447 - binary_accuracy: 0.9529\n11776/15000 [======================&gt;.......] - ETA: 0s - loss: 0.2446 - binary_accuracy: 0.9524\n12288/15000 [=======================&gt;......] - ETA: 0s - loss: 0.2437 - binary_accuracy: 0.9525\n12800/15000 [========================&gt;.....] - ETA: 0s - loss: 0.2434 - binary_accuracy: 0.9526\n13312/15000 [=========================&gt;....] - ETA: 0s - loss: 0.2431 - binary_accuracy: 0.9528\n13824/15000 [==========================&gt;...] - ETA: 0s - loss: 0.2422 - binary_accuracy: 0.9533\n14336/15000 [===========================&gt;..] - ETA: 0s - loss: 0.2420 - binary_accuracy: 0.9533\n14848/15000 [============================&gt;.] - ETA: 0s - loss: 0.2422 - binary_accuracy: 0.9531\n15000/15000 [==============================] - 2s 159us/step - loss: 0.2423 - binary_accuracy: 0.9527 - val_loss: 0.3401 - val_binary_accuracy: 0.8834\nEpoch 27/30\n\n  512/15000 [&gt;.............................] - ETA: 1s - loss: 0.2363 - binary_accuracy: 0.9434\n 1024/15000 [=&gt;............................] - ETA: 1s - loss: 0.2364 - binary_accuracy: 0.9473\n 1536/15000 [==&gt;...........................] - ETA: 1s - loss: 0.2319 - binary_accuracy: 0.9518\n 2048/15000 [===&gt;..........................] - ETA: 1s - loss: 0.2292 - binary_accuracy: 0.9556\n 2560/15000 [====&gt;.........................] - ETA: 1s - loss: 0.2296 - binary_accuracy: 0.9543\n 3072/15000 [=====&gt;........................] - ETA: 1s - loss: 0.2302 - binary_accuracy: 0.9535\n 3584/15000 [======&gt;.......................] - ETA: 1s - loss: 0.2270 - binary_accuracy: 0.9554\n 4096/15000 [=======&gt;......................] - ETA: 1s - loss: 0.2284 - binary_accuracy: 0.9558\n 4608/15000 [========&gt;.....................] - ETA: 1s - loss: 0.2263 - binary_accuracy: 0.9568\n 5120/15000 [=========&gt;....................] - ETA: 1s - loss: 0.2250 - binary_accuracy: 0.9582\n 5632/15000 [==========&gt;...................] - ETA: 0s - loss: 0.2251 - binary_accuracy: 0.9583\n 6144/15000 [===========&gt;..................] - ETA: 0s - loss: 0.2265 - binary_accuracy: 0.9575\n 6656/15000 [============&gt;.................] - ETA: 0s - loss: 0.2264 - binary_accuracy: 0.9582\n 7168/15000 [=============&gt;................] - ETA: 0s - loss: 0.2265 - binary_accuracy: 0.9579\n 7680/15000 [==============&gt;...............] - ETA: 0s - loss: 0.2262 - binary_accuracy: 0.9573\n 8192/15000 [===============&gt;..............] - ETA: 0s - loss: 0.2264 - binary_accuracy: 0.9568\n 8704/15000 [================&gt;.............] - ETA: 0s - loss: 0.2282 - binary_accuracy: 0.9550\n 9216/15000 [=================&gt;............] - ETA: 0s - loss: 0.2274 - binary_accuracy: 0.9554\n 9728/15000 [==================&gt;...........] - ETA: 0s - loss: 0.2291 - binary_accuracy: 0.9544\n10240/15000 [===================&gt;..........] - ETA: 0s - loss: 0.2297 - binary_accuracy: 0.9537\n10752/15000 [====================&gt;.........] - ETA: 0s - loss: 0.2285 - binary_accuracy: 0.9542\n11264/15000 [=====================&gt;........] - ETA: 0s - loss: 0.2290 - binary_accuracy: 0.9539\n11776/15000 [======================&gt;.......] - ETA: 0s - loss: 0.2276 - binary_accuracy: 0.9546\n12288/15000 [=======================&gt;......] - ETA: 0s - loss: 0.2263 - binary_accuracy: 0.9550\n12800/15000 [========================&gt;.....] - ETA: 0s - loss: 0.2258 - binary_accuracy: 0.9552\n13312/15000 [=========================&gt;....] - ETA: 0s - loss: 0.2252 - binary_accuracy: 0.9552\n13824/15000 [==========================&gt;...] - ETA: 0s - loss: 0.2249 - binary_accuracy: 0.9552\n14336/15000 [===========================&gt;..] - ETA: 0s - loss: 0.2240 - binary_accuracy: 0.9555\n14848/15000 [============================&gt;.] - ETA: 0s - loss: 0.2240 - binary_accuracy: 0.9554\n15000/15000 [==============================] - 2s 159us/step - loss: 0.2239 - binary_accuracy: 0.9555 - val_loss: 0.3308 - val_binary_accuracy: 0.8850\nEpoch 28/30\n\n  512/15000 [&gt;.............................] - ETA: 1s - loss: 0.2224 - binary_accuracy: 0.9512\n 1024/15000 [=&gt;............................] - ETA: 1s - loss: 0.2219 - binary_accuracy: 0.9521\n 1536/15000 [==&gt;...........................] - ETA: 1s - loss: 0.2156 - binary_accuracy: 0.9544\n 2048/15000 [===&gt;..........................] - ETA: 1s - loss: 0.2153 - binary_accuracy: 0.9517\n 2560/15000 [====&gt;.........................] - ETA: 1s - loss: 0.2152 - binary_accuracy: 0.9520\n 3072/15000 [=====&gt;........................] - ETA: 1s - loss: 0.2132 - binary_accuracy: 0.9548\n 3584/15000 [======&gt;.......................] - ETA: 1s - loss: 0.2114 - binary_accuracy: 0.9573\n 4096/15000 [=======&gt;......................] - ETA: 1s - loss: 0.2114 - binary_accuracy: 0.9575\n 4608/15000 [========&gt;.....................] - ETA: 1s - loss: 0.2101 - binary_accuracy: 0.9586\n 5120/15000 [=========&gt;....................] - ETA: 1s - loss: 0.2098 - binary_accuracy: 0.9590\n 5632/15000 [==========&gt;...................] - ETA: 1s - loss: 0.2101 - binary_accuracy: 0.9581\n 6144/15000 [===========&gt;..................] - ETA: 0s - loss: 0.2095 - binary_accuracy: 0.9582\n 6656/15000 [============&gt;.................] - ETA: 0s - loss: 0.2090 - binary_accuracy: 0.9579\n 7168/15000 [=============&gt;................] - ETA: 0s - loss: 0.2098 - binary_accuracy: 0.9577\n 7680/15000 [==============&gt;...............] - ETA: 0s - loss: 0.2104 - binary_accuracy: 0.9572\n 8192/15000 [===============&gt;..............] - ETA: 0s - loss: 0.2100 - binary_accuracy: 0.9578\n 8704/15000 [================&gt;.............] - ETA: 0s - loss: 0.2100 - binary_accuracy: 0.9581\n 9216/15000 [=================&gt;............] - ETA: 0s - loss: 0.2093 - binary_accuracy: 0.9587\n 9728/15000 [==================&gt;...........] - ETA: 0s - loss: 0.2093 - binary_accuracy: 0.9584\n10240/15000 [===================&gt;..........] - ETA: 0s - loss: 0.2089 - binary_accuracy: 0.9585\n10752/15000 [====================&gt;.........] - ETA: 0s - loss: 0.2093 - binary_accuracy: 0.9581\n11264/15000 [=====================&gt;........] - ETA: 0s - loss: 0.2095 - binary_accuracy: 0.9581\n11776/15000 [======================&gt;.......] - ETA: 0s - loss: 0.2088 - binary_accuracy: 0.9581\n12288/15000 [=======================&gt;......] - ETA: 0s - loss: 0.2075 - binary_accuracy: 0.9586\n12800/15000 [========================&gt;.....] - ETA: 0s - loss: 0.2071 - binary_accuracy: 0.9587\n13312/15000 [=========================&gt;....] - ETA: 0s - loss: 0.2076 - binary_accuracy: 0.9584\n13824/15000 [==========================&gt;...] - ETA: 0s - loss: 0.2070 - binary_accuracy: 0.9584\n14336/15000 [===========================&gt;..] - ETA: 0s - loss: 0.2067 - binary_accuracy: 0.9585\n14848/15000 [============================&gt;.] - ETA: 0s - loss: 0.2069 - binary_accuracy: 0.9581\n15000/15000 [==============================] - 2s 159us/step - loss: 0.2066 - binary_accuracy: 0.9583 - val_loss: 0.3209 - val_binary_accuracy: 0.8871\nEpoch 29/30\n\n  512/15000 [&gt;.............................] - ETA: 1s - loss: 0.1930 - binary_accuracy: 0.9648\n 1024/15000 [=&gt;............................] - ETA: 1s - loss: 0.1974 - binary_accuracy: 0.9561\n 1536/15000 [==&gt;...........................] - ETA: 1s - loss: 0.1955 - binary_accuracy: 0.9590\n 2048/15000 [===&gt;..........................] - ETA: 1s - loss: 0.1963 - binary_accuracy: 0.9600\n 2560/15000 [====&gt;.........................] - ETA: 1s - loss: 0.1974 - binary_accuracy: 0.9574\n 3072/15000 [=====&gt;........................] - ETA: 1s - loss: 0.1937 - binary_accuracy: 0.9587\n 3584/15000 [======&gt;.......................] - ETA: 1s - loss: 0.1950 - binary_accuracy: 0.9595\n 4096/15000 [=======&gt;......................] - ETA: 1s - loss: 0.1935 - binary_accuracy: 0.9602\n 4608/15000 [========&gt;.....................] - ETA: 1s - loss: 0.1925 - binary_accuracy: 0.9599\n 5120/15000 [=========&gt;....................] - ETA: 1s - loss: 0.1936 - binary_accuracy: 0.9594\n 5632/15000 [==========&gt;...................] - ETA: 0s - loss: 0.1949 - binary_accuracy: 0.9585\n 6144/15000 [===========&gt;..................] - ETA: 0s - loss: 0.1957 - binary_accuracy: 0.9578\n 6656/15000 [============&gt;.................] - ETA: 0s - loss: 0.1953 - binary_accuracy: 0.9587\n 7168/15000 [=============&gt;................] - ETA: 0s - loss: 0.1947 - binary_accuracy: 0.9588\n 7680/15000 [==============&gt;...............] - ETA: 0s - loss: 0.1929 - binary_accuracy: 0.9600\n 8192/15000 [===============&gt;..............] - ETA: 0s - loss: 0.1915 - binary_accuracy: 0.9608\n 8704/15000 [================&gt;.............] - ETA: 0s - loss: 0.1921 - binary_accuracy: 0.9601\n 9216/15000 [=================&gt;............] - ETA: 0s - loss: 0.1921 - binary_accuracy: 0.9604\n 9728/15000 [==================&gt;...........] - ETA: 0s - loss: 0.1928 - binary_accuracy: 0.9598\n10240/15000 [===================&gt;..........] - ETA: 0s - loss: 0.1929 - binary_accuracy: 0.9599\n10752/15000 [====================&gt;.........] - ETA: 0s - loss: 0.1926 - binary_accuracy: 0.9601\n11264/15000 [=====================&gt;........] - ETA: 0s - loss: 0.1926 - binary_accuracy: 0.9603\n11776/15000 [======================&gt;.......] - ETA: 0s - loss: 0.1926 - binary_accuracy: 0.9605\n12288/15000 [=======================&gt;......] - ETA: 0s - loss: 0.1924 - binary_accuracy: 0.9609\n12800/15000 [========================&gt;.....] - ETA: 0s - loss: 0.1923 - binary_accuracy: 0.9610\n13312/15000 [=========================&gt;....] - ETA: 0s - loss: 0.1923 - binary_accuracy: 0.9609\n13824/15000 [==========================&gt;...] - ETA: 0s - loss: 0.1917 - binary_accuracy: 0.9610\n14336/15000 [===========================&gt;..] - ETA: 0s - loss: 0.1915 - binary_accuracy: 0.9614\n14848/15000 [============================&gt;.] - ETA: 0s - loss: 0.1903 - binary_accuracy: 0.9617\n15000/15000 [==============================] - 2s 159us/step - loss: 0.1906 - binary_accuracy: 0.9614 - val_loss: 0.3221 - val_binary_accuracy: 0.8840\nEpoch 30/30\n\n  512/15000 [&gt;.............................] - ETA: 1s - loss: 0.1855 - binary_accuracy: 0.9629\n 1024/15000 [=&gt;............................] - ETA: 1s - loss: 0.1801 - binary_accuracy: 0.9639\n 1536/15000 [==&gt;...........................] - ETA: 1s - loss: 0.1842 - binary_accuracy: 0.9603\n 2048/15000 [===&gt;..........................] - ETA: 1s - loss: 0.1872 - binary_accuracy: 0.9609\n 2560/15000 [====&gt;.........................] - ETA: 1s - loss: 0.1828 - binary_accuracy: 0.9645\n 3072/15000 [=====&gt;........................] - ETA: 1s - loss: 0.1833 - binary_accuracy: 0.9629\n 3584/15000 [======&gt;.......................] - ETA: 1s - loss: 0.1800 - binary_accuracy: 0.9634\n 4096/15000 [=======&gt;......................] - ETA: 1s - loss: 0.1793 - binary_accuracy: 0.9636\n 4608/15000 [========&gt;.....................] - ETA: 1s - loss: 0.1794 - binary_accuracy: 0.9640\n 5120/15000 [=========&gt;....................] - ETA: 1s - loss: 0.1786 - binary_accuracy: 0.9643\n 5632/15000 [==========&gt;...................] - ETA: 0s - loss: 0.1779 - binary_accuracy: 0.9645\n 6144/15000 [===========&gt;..................] - ETA: 0s - loss: 0.1770 - binary_accuracy: 0.9648\n 6656/15000 [============&gt;.................] - ETA: 0s - loss: 0.1759 - binary_accuracy: 0.9654\n 7168/15000 [=============&gt;................] - ETA: 0s - loss: 0.1764 - binary_accuracy: 0.9648\n 7680/15000 [==============&gt;...............] - ETA: 0s - loss: 0.1768 - binary_accuracy: 0.9645\n 8192/15000 [===============&gt;..............] - ETA: 0s - loss: 0.1762 - binary_accuracy: 0.9648\n 8704/15000 [================&gt;.............] - ETA: 0s - loss: 0.1766 - binary_accuracy: 0.9646\n 9216/15000 [=================&gt;............] - ETA: 0s - loss: 0.1773 - binary_accuracy: 0.9647\n 9728/15000 [==================&gt;...........] - ETA: 0s - loss: 0.1762 - binary_accuracy: 0.9654\n10240/15000 [===================&gt;..........] - ETA: 0s - loss: 0.1759 - binary_accuracy: 0.9655\n10752/15000 [====================&gt;.........] - ETA: 0s - loss: 0.1764 - binary_accuracy: 0.9645\n11264/15000 [=====================&gt;........] - ETA: 0s - loss: 0.1763 - binary_accuracy: 0.9645\n11776/15000 [======================&gt;.......] - ETA: 0s - loss: 0.1765 - binary_accuracy: 0.9646\n12288/15000 [=======================&gt;......] - ETA: 0s - loss: 0.1762 - binary_accuracy: 0.9647\n12800/15000 [========================&gt;.....] - ETA: 0s - loss: 0.1761 - binary_accuracy: 0.9645\n13312/15000 [=========================&gt;....] - ETA: 0s - loss: 0.1765 - binary_accuracy: 0.9641\n13824/15000 [==========================&gt;...] - ETA: 0s - loss: 0.1758 - binary_accuracy: 0.9640\n14336/15000 [===========================&gt;..] - ETA: 0s - loss: 0.1764 - binary_accuracy: 0.9634\n14848/15000 [============================&gt;.] - ETA: 0s - loss: 0.1764 - binary_accuracy: 0.9634\n15000/15000 [==============================] - 2s 164us/step - loss: 0.1762 - binary_accuracy: 0.9635 - val_loss: 0.3103 - val_binary_accuracy: 0.8866\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\ndense_23 (Dense)             (None, 16)                160016    \n_________________________________________________________________\ndense_24 (Dense)             (None, 16)                272       \n_________________________________________________________________\ndense_25 (Dense)             (None, 16)                272       \n_________________________________________________________________\ndense_26 (Dense)             (None, 16)                272       \n_________________________________________________________________\ndense_27 (Dense)             (None, 1)                 17        \n=================================================================\nTotal params: 160,849\nTrainable params: 160,849\nNon-trainable params: 0\n_________________________________________________________________\nFinal metrics: binary_loss:0.1762\nFinal metrics: binary_accuracy=0.9635\nFinal metrics: validation_binary_loss:0.3103\nFinal metrics: validation_binary_accuracy:0.8866\n\n   32/25000 [..............................] - ETA: 3s\n  768/25000 [..............................] - ETA: 1s\n 1536/25000 [&gt;.............................] - ETA: 1s\n 2304/25000 [=&gt;............................] - ETA: 1s\n 3072/25000 [==&gt;...........................] - ETA: 1s\n 3840/25000 [===&gt;..........................] - ETA: 1s\n 4608/25000 [====&gt;.........................] - ETA: 1s\n 5376/25000 [=====&gt;........................] - ETA: 1s\n 6144/25000 [======&gt;.......................] - ETA: 1s\n 6912/25000 [=======&gt;......................] - ETA: 1s\n 7680/25000 [========&gt;.....................] - ETA: 1s\n 8416/25000 [=========&gt;....................] - ETA: 1s\n 9184/25000 [==========&gt;...................] - ETA: 1s\n 9952/25000 [==========&gt;...................] - ETA: 1s\n10720/25000 [===========&gt;..................] - ETA: 0s\n11488/25000 [============&gt;.................] - ETA: 0s\n12256/25000 [=============&gt;................] - ETA: 0s\n13024/25000 [==============&gt;...............] - ETA: 0s\n13792/25000 [===============&gt;..............] - ETA: 0s\n14560/25000 [================&gt;.............] - ETA: 0s\n15296/25000 [=================&gt;............] - ETA: 0s\n16032/25000 [==================&gt;...........] - ETA: 0s\n16768/25000 [===================&gt;..........] - ETA: 0s\n17504/25000 [====================&gt;.........] - ETA: 0s\n18240/25000 [====================&gt;.........] - ETA: 0s\n18976/25000 [=====================&gt;........] - ETA: 0s\n19712/25000 [======================&gt;.......] - ETA: 0s\n20448/25000 [=======================&gt;......] - ETA: 0s\n21184/25000 [========================&gt;.....] - ETA: 0s\n21920/25000 [=========================&gt;....] - ETA: 0s\n22624/25000 [==========================&gt;...] - ETA: 0s\n23264/25000 [==========================&gt;...] - ETA: 0s\n24000/25000 [===========================&gt;..] - ETA: 0s\n24736/25000 [============================&gt;.] - ETA: 0s\n25000/25000 [==============================] - 2s 69us/step\nAverage Probability Results:\n[0.3252059131240845, 0.87924]\n()\nPredictions Results:\n[[0.3202772 ]\n [0.99991333]\n [0.9848704 ]\n ...\n [0.23091322]\n [0.22873023]\n [0.6714753 ]]\nMLflow Run ID: 12e923c8bbfb40ddbcac6308cc187811\nKeras model saved locally at /databricks/driver/keras_models/12e923c8bbfb40ddbcac6308cc187811\nWriting TensorFlow events locally to /tmp/tmp375Saj\n\nUploading TensorFlow events as a run artifact.\n(&#39;loss function use&#39;, &#39;binary_crossentropy&#39;)\n</div>"]}}],"execution_count":9},{"cell_type":"code","source":["args = Params(3, 30, 32, \"mse\")\nrunReviews(args, True)"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Using Default Baseline parameters\n(&#39;hidden_layers:&#39;, 3)\n(&#39;output:&#39;, 32)\n(&#39;epochs:&#39;, 30)\n(&#39;loss:&#39;, &#39;mse&#39;)\nBaseline Model:\nTrain on 15000 samples, validate on 10000 samples\nEpoch 1/30\n\n  512/15000 [&gt;.............................] - ETA: 11s - loss: 0.2504 - binary_accuracy: 0.5020\n 1024/15000 [=&gt;............................] - ETA: 7s - loss: 0.2499 - binary_accuracy: 0.5107 \n 1536/15000 [==&gt;...........................] - ETA: 5s - loss: 0.2501 - binary_accuracy: 0.5046\n 2048/15000 [===&gt;..........................] - ETA: 4s - loss: 0.2502 - binary_accuracy: 0.4956\n 2560/15000 [====&gt;.........................] - ETA: 3s - loss: 0.2498 - binary_accuracy: 0.5043\n 3072/15000 [=====&gt;........................] - ETA: 3s - loss: 0.2498 - binary_accuracy: 0.5078\n 3584/15000 [======&gt;.......................] - ETA: 3s - loss: 0.2497 - binary_accuracy: 0.5103\n 4096/15000 [=======&gt;......................] - ETA: 3s - loss: 0.2496 - binary_accuracy: 0.5125\n 4608/15000 [========&gt;.....................] - ETA: 2s - loss: 0.2494 - binary_accuracy: 0.5187\n 5120/15000 [=========&gt;....................] - ETA: 2s - loss: 0.2492 - binary_accuracy: 0.5271\n 5632/15000 [==========&gt;...................] - ETA: 2s - loss: 0.2490 - binary_accuracy: 0.5291\n 6144/15000 [===========&gt;..................] - ETA: 2s - loss: 0.2490 - binary_accuracy: 0.5308\n 6656/15000 [============&gt;.................] - ETA: 2s - loss: 0.2488 - binary_accuracy: 0.5329\n 7168/15000 [=============&gt;................] - ETA: 1s - loss: 0.2485 - binary_accuracy: 0.5346\n 7680/15000 [==============&gt;...............] - ETA: 1s - loss: 0.2482 - binary_accuracy: 0.5406\n 8192/15000 [===============&gt;..............] - ETA: 1s - loss: 0.2479 - binary_accuracy: 0.5450\n 8704/15000 [================&gt;.............] - ETA: 1s - loss: 0.2477 - binary_accuracy: 0.5470\n 9216/15000 [=================&gt;............] - ETA: 1s - loss: 0.2476 - binary_accuracy: 0.5497\n 9728/15000 [==================&gt;...........] - ETA: 1s - loss: 0.2474 - binary_accuracy: 0.5522\n10240/15000 [===================&gt;..........] - ETA: 1s - loss: 0.2472 - binary_accuracy: 0.5558\n10752/15000 [====================&gt;.........] - ETA: 0s - loss: 0.2471 - binary_accuracy: 0.5579\n11264/15000 [=====================&gt;........] - ETA: 0s - loss: 0.2467 - binary_accuracy: 0.5616\n11776/15000 [======================&gt;.......] - ETA: 0s - loss: 0.2464 - binary_accuracy: 0.5643\n12288/15000 [=======================&gt;......] - ETA: 0s - loss: 0.2461 - binary_accuracy: 0.5675\n12800/15000 [========================&gt;.....] - ETA: 0s - loss: 0.2458 - binary_accuracy: 0.5700\n13312/15000 [=========================&gt;....] - ETA: 0s - loss: 0.2455 - binary_accuracy: 0.5724\n13824/15000 [==========================&gt;...] - ETA: 0s - loss: 0.2453 - binary_accuracy: 0.5737\n14336/15000 [===========================&gt;..] - ETA: 0s - loss: 0.2451 - binary_accuracy: 0.5760\n14848/15000 [============================&gt;.] - ETA: 0s - loss: 0.2449 - binary_accuracy: 0.5773\n15000/15000 [==============================] - 5s 338us/step - loss: 0.2448 - binary_accuracy: 0.5785 - val_loss: 0.2369 - val_binary_accuracy: 0.6499\nEpoch 2/30\n\n  512/15000 [&gt;.............................] - ETA: 2s - loss: 0.2338 - binary_accuracy: 0.6934\n 1024/15000 [=&gt;............................] - ETA: 2s - loss: 0.2334 - binary_accuracy: 0.6855\n 1536/15000 [==&gt;...........................] - ETA: 2s - loss: 0.2330 - binary_accuracy: 0.6875\n 2048/15000 [===&gt;..........................] - ETA: 2s - loss: 0.2328 - binary_accuracy: 0.6899\n 2560/15000 [====&gt;.........................] - ETA: 2s - loss: 0.2328 - binary_accuracy: 0.6883\n 3072/15000 [=====&gt;........................] - ETA: 2s - loss: 0.2323 - binary_accuracy: 0.6898\n 3584/15000 [======&gt;.......................] - ETA: 2s - loss: 0.2325 - binary_accuracy: 0.6858\n 4096/15000 [=======&gt;......................] - ETA: 2s - loss: 0.2321 - binary_accuracy: 0.6926\n 4608/15000 [========&gt;.....................] - ETA: 2s - loss: 0.2315 - binary_accuracy: 0.6940\n 5120/15000 [=========&gt;....................] - ETA: 2s - loss: 0.2310 - binary_accuracy: 0.6992\n 5632/15000 [==========&gt;...................] - ETA: 1s - loss: 0.2307 - binary_accuracy: 0.7024\n 6144/15000 [===========&gt;..................] - ETA: 1s - loss: 0.2302 - binary_accuracy: 0.7039\n 6656/15000 [============&gt;.................] - ETA: 1s - loss: 0.2300 - binary_accuracy: 0.7034\n 7168/15000 [=============&gt;................] - ETA: 1s - loss: 0.2298 - binary_accuracy: 0.7026\n 7680/15000 [==============&gt;...............] - ETA: 1s - loss: 0.2294 - binary_accuracy: 0.7063\n 8192/15000 [===============&gt;..............] - ETA: 1s - loss: 0.2290 - binary_accuracy: 0.7083\n 8704/15000 [================&gt;.............] - ETA: 1s - loss: 0.2286 - binary_accuracy: 0.7102\n 9216/15000 [=================&gt;............] - ETA: 1s - loss: 0.2284 - binary_accuracy: 0.7084\n 9728/15000 [==================&gt;...........] - ETA: 1s - loss: 0.2281 - binary_accuracy: 0.7089\n10240/15000 [===================&gt;..........] - ETA: 1s - loss: 0.2280 - binary_accuracy: 0.7084\n10752/15000 [====================&gt;.........] - ETA: 0s - loss: 0.2277 - binary_accuracy: 0.7094\n11264/15000 [=====================&gt;........] - ETA: 0s - loss: 0.2275 - binary_accuracy: 0.7094\n11776/15000 [======================&gt;.......] - ETA: 0s - loss: 0.2271 - binary_accuracy: 0.7111\n12288/15000 [=======================&gt;......] - ETA: 0s - loss: 0.2267 - binary_accuracy: 0.7124\n12800/15000 [========================&gt;.....] - ETA: 0s - loss: 0.2263 - binary_accuracy: 0.7149\n13312/15000 [=========================&gt;....] - ETA: 0s - loss: 0.2261 - binary_accuracy: 0.7157\n13824/15000 [==========================&gt;...] - ETA: 0s - loss: 0.2258 - binary_accuracy: 0.7182\n14336/15000 [===========================&gt;..] - ETA: 0s - loss: 0.2256 - binary_accuracy: 0.7196\n14848/15000 [============================&gt;.] - ETA: 0s - loss: 0.2253 - binary_accuracy: 0.7204\n15000/15000 [==============================] - 5s 333us/step - loss: 0.2252 - binary_accuracy: 0.7207 - val_loss: 0.2165 - val_binary_accuracy: 0.7614\nEpoch 3/30\n\n  512/15000 [&gt;.............................] - ETA: 2s - loss: 0.2099 - binary_accuracy: 0.7949\n 1024/15000 [=&gt;............................] - ETA: 2s - loss: 0.2118 - binary_accuracy: 0.7881\n 1536/15000 [==&gt;...........................] - ETA: 2s - loss: 0.2110 - binary_accuracy: 0.7923\n 2048/15000 [===&gt;..........................] - ETA: 2s - loss: 0.2106 - binary_accuracy: 0.7905\n 2560/15000 [====&gt;.........................] - ETA: 2s - loss: 0.2101 - binary_accuracy: 0.7898\n 3072/15000 [=====&gt;........................] - ETA: 2s - loss: 0.2096 - binary_accuracy: 0.7913\n 3584/15000 [======&gt;.......................] - ETA: 2s - loss: 0.2096 - binary_accuracy: 0.7902\n 4096/15000 [=======&gt;......................] - ETA: 2s - loss: 0.2095 - binary_accuracy: 0.7898\n 4608/15000 [========&gt;.....................] - ETA: 2s - loss: 0.2092 - binary_accuracy: 0.7914\n 5120/15000 [=========&gt;....................] - ETA: 2s - loss: 0.2087 - binary_accuracy: 0.7949\n 5632/15000 [==========&gt;...................] - ETA: 1s - loss: 0.2086 - binary_accuracy: 0.7939\n 6144/15000 [===========&gt;..................] - ETA: 1s - loss: 0.2082 - binary_accuracy: 0.7954\n 6656/15000 [============&gt;.................] - ETA: 1s - loss: 0.2078 - binary_accuracy: 0.7949\n 7168/15000 [=============&gt;................] - ETA: 1s - loss: 0.2077 - binary_accuracy: 0.7937\n 7680/15000 [==============&gt;...............] - ETA: 1s - loss: 0.2071 - binary_accuracy: 0.7954\n 8192/15000 [===============&gt;..............] - ETA: 1s - loss: 0.2066 - binary_accuracy: 0.7952\n 8704/15000 [================&gt;.............] - ETA: 1s - loss: 0.2066 - binary_accuracy: 0.7933\n 9216/15000 [=================&gt;............] - ETA: 1s - loss: 0.2065 - binary_accuracy: 0.7921\n 9728/15000 [==================&gt;...........] - ETA: 1s - loss: 0.2064 - binary_accuracy: 0.7919\n10240/15000 [===================&gt;..........] - ETA: 1s - loss: 0.2058 - binary_accuracy: 0.7930\n10752/15000 [====================&gt;.........] - ETA: 0s - loss: 0.2057 - binary_accuracy: 0.7934\n11264/15000 [=====================&gt;........] - ETA: 0s - loss: 0.2054 - binary_accuracy: 0.7943\n11776/15000 [======================&gt;.......] - ETA: 0s - loss: 0.2052 - binary_accuracy: 0.7951\n12288/15000 [=======================&gt;......] - ETA: 0s - loss: 0.2049 - binary_accuracy: 0.7957\n12800/15000 [========================&gt;.....] - ETA: 0s - loss: 0.2044 - binary_accuracy: 0.7970\n13312/15000 [=========================&gt;....] - ETA: 0s - loss: 0.2042 - binary_accuracy: 0.7982\n13824/15000 [==========================&gt;...] - ETA: 0s - loss: 0.2036 - binary_accuracy: 0.8011\n14336/15000 [===========================&gt;..] - ETA: 0s - loss: 0.2035 - binary_accuracy: 0.8006\n14848/15000 [============================&gt;.] - ETA: 0s - loss: 0.2033 - binary_accuracy: 0.8016\n15000/15000 [==============================] - 5s 333us/step - loss: 0.2032 - binary_accuracy: 0.8016 - val_loss: 0.1976 - val_binary_accuracy: 0.8099\nEpoch 4/30\n\n  512/15000 [&gt;.............................] - ETA: 2s - loss: 0.1894 - binary_accuracy: 0.8516\n 1024/15000 [=&gt;............................] - ETA: 2s - loss: 0.1891 - binary_accuracy: 0.8408\n 1536/15000 [==&gt;...........................] - ETA: 2s - loss: 0.1882 - binary_accuracy: 0.8431\n 2048/15000 [===&gt;..........................] - ETA: 2s - loss: 0.1894 - binary_accuracy: 0.8354\n 2560/15000 [====&gt;.........................] - ETA: 2s - loss: 0.1894 - binary_accuracy: 0.8371\n 3072/15000 [=====&gt;........................] - ETA: 2s - loss: 0.1891 - binary_accuracy: 0.8369\n 3584/15000 [======&gt;.......................] - ETA: 2s - loss: 0.1884 - binary_accuracy: 0.8365\n 4096/15000 [=======&gt;......................] - ETA: 2s - loss: 0.1885 - binary_accuracy: 0.8345\n 4608/15000 [========&gt;.....................] - ETA: 2s - loss: 0.1880 - binary_accuracy: 0.8359\n 5120/15000 [=========&gt;....................] - ETA: 2s - loss: 0.1876 - binary_accuracy: 0.8365\n 5632/15000 [==========&gt;...................] - ETA: 1s - loss: 0.1874 - binary_accuracy: 0.8358\n 6144/15000 [===========&gt;..................] - ETA: 1s - loss: 0.1876 - binary_accuracy: 0.8350\n 6656/15000 [============&gt;.................] - ETA: 1s - loss: 0.1872 - binary_accuracy: 0.8356\n 7168/15000 [=============&gt;................] - ETA: 1s - loss: 0.1871 - binary_accuracy: 0.8364\n 7680/15000 [==============&gt;...............] - ETA: 1s - loss: 0.1869 - binary_accuracy: 0.8372\n 8192/15000 [===============&gt;..............] - ETA: 1s - loss: 0.1865 - binary_accuracy: 0.8376\n 8704/15000 [================&gt;.............] - ETA: 1s - loss: 0.1865 - binary_accuracy: 0.8366\n 9216/15000 [=================&gt;............] - ETA: 1s - loss: 0.1863 - binary_accuracy: 0.8364\n 9728/15000 [==================&gt;...........] - ETA: 1s - loss: 0.1862 - binary_accuracy: 0.8359\n10240/15000 [===================&gt;..........] - ETA: 1s - loss: 0.1859 - binary_accuracy: 0.8359\n10752/15000 [====================&gt;.........] - ETA: 0s - loss: 0.1859 - binary_accuracy: 0.8352\n11264/15000 [=====================&gt;........] - ETA: 0s - loss: 0.1857 - binary_accuracy: 0.8353\n11776/15000 [======================&gt;.......] - ETA: 0s - loss: 0.1854 - binary_accuracy: 0.8361\n12288/15000 [=======================&gt;......] - ETA: 0s - loss: 0.1854 - binary_accuracy: 0.8354\n12800/15000 [========================&gt;.....] - ETA: 0s - loss: 0.1850 - binary_accuracy: 0.8353\n13312/15000 [=========================&gt;....] - ETA: 0s - loss: 0.1846 - binary_accuracy: 0.8358\n13824/15000 [==========================&gt;...] - ETA: 0s - loss: 0.1843 - binary_accuracy: 0.8364\n14336/15000 [===========================&gt;..] - ETA: 0s - loss: 0.1841 - binary_accuracy: 0.8368\n14848/15000 [============================&gt;.] - ETA: 0s - loss: 0.1836 - binary_accuracy: 0.8382\n15000/15000 [==============================] - 5s 332us/step - loss: 0.1835 - binary_accuracy: 0.8387 - val_loss: 0.1808 - val_binary_accuracy: 0.8274\nEpoch 5/30\n\n  512/15000 [&gt;.............................] - ETA: 2s - loss: 0.1756 - binary_accuracy: 0.8340\n 1024/15000 [=&gt;............................] - ETA: 2s - loss: 0.1770 - binary_accuracy: 0.8389\n 1536/15000 [==&gt;...........................] - ETA: 2s - loss: 0.1752 - binary_accuracy: 0.8392\n 2048/15000 [===&gt;..........................] - ETA: 2s - loss: 0.1738 - binary_accuracy: 0.8394\n 2560/15000 [====&gt;.........................] - ETA: 2s - loss: 0.1736 - binary_accuracy: 0.8402\n 3072/15000 [=====&gt;........................] - ETA: 2s - loss: 0.1732 - binary_accuracy: 0.8424\n 3584/15000 [======&gt;.......................] - ETA: 2s - loss: 0.1733 - binary_accuracy: 0.8421\n 4096/15000 [=======&gt;......................] - ETA: 2s - loss: 0.1728 - binary_accuracy: 0.8469\n 4608/15000 [========&gt;.....................] - ETA: 2s - loss: 0.1730 - binary_accuracy: 0.8453\n 5120/15000 [=========&gt;....................] - ETA: 2s - loss: 0.1723 - binary_accuracy: 0.8457\n 5632/15000 [==========&gt;...................] - ETA: 1s - loss: 0.1720 - binary_accuracy: 0.8459\n 6144/15000 [===========&gt;..................] - ETA: 1s - loss: 0.1712 - binary_accuracy: 0.8477\n 6656/15000 [============&gt;.................] - ETA: 1s - loss: 0.1699 - binary_accuracy: 0.8505\n 7168/15000 [=============&gt;................] - ETA: 1s - loss: 0.1699 - binary_accuracy: 0.8500\n 7680/15000 [==============&gt;...............] - ETA: 1s - loss: 0.1697 - binary_accuracy: 0.8513\n 8192/15000 [===============&gt;..............] - ETA: 1s - loss: 0.1691 - binary_accuracy: 0.8527\n 8704/15000 [================&gt;.............] - ETA: 1s - loss: 0.1686 - binary_accuracy: 0.8540\n 9216/15000 [=================&gt;............] - ETA: 1s - loss: 0.1680 - binary_accuracy: 0.8566\n 9728/15000 [==================&gt;...........] - ETA: 1s - loss: 0.1679 - binary_accuracy: 0.8562\n10240/15000 [===================&gt;..........] - ETA: 0s - loss: 0.1673 - binary_accuracy: 0.8573\n10752/15000 [====================&gt;.........] - ETA: 0s - loss: 0.1672 - binary_accuracy: 0.8574\n11264/15000 [=====================&gt;........] - ETA: 0s - loss: 0.1671 - binary_accuracy: 0.8577\n11776/15000 [======================&gt;.......] - ETA: 0s - loss: 0.1670 - binary_accuracy: 0.8577\n12288/15000 [=======================&gt;......] - ETA: 0s - loss: 0.1667 - binary_accuracy: 0.8575\n12800/15000 [========================&gt;.....] - ETA: 0s - loss: 0.1664 - binary_accuracy: 0.8579\n13312/15000 [=========================&gt;....] - ETA: 0s - loss: 0.1662 - binary_accuracy: 0.8587\n13824/15000 [==========================&gt;...] - ETA: 0s - loss: 0.1661 - binary_accuracy: 0.8584\n14336/15000 [===========================&gt;..] - ETA: 0s - loss: 0.1661 - binary_accuracy: 0.8576\n14848/15000 [============================&gt;.] - ETA: 0s - loss: 0.1658 - binary_accuracy: 0.8585\n15000/15000 [==============================] - 5s 327us/step - loss: 0.1657 - binary_accuracy: 0.8587 - val_loss: 0.1659 - val_binary_accuracy: 0.8420\nEpoch 6/30\n\n  512/15000 [&gt;.............................] - ETA: 2s - loss: 0.1569 - binary_accuracy: 0.8691\n 1024/15000 [=&gt;............................] - ETA: 2s - loss: 0.1545 - binary_accuracy: 0.8779\n 1536/15000 [==&gt;...........................] - ETA: 2s - loss: 0.1530 - binary_accuracy: 0.8757\n 2048/15000 [===&gt;..........................] - ETA: 2s - loss: 0.1538 - binary_accuracy: 0.8760\n 2560/15000 [====&gt;.........................] - ETA: 2s - loss: 0.1535 - binary_accuracy: 0.8746\n 3072/15000 [=====&gt;........................] - ETA: 2s - loss: 0.1537 - binary_accuracy: 0.8724\n 3584/15000 [======&gt;.......................] - ETA: 2s - loss: 0.1532 - binary_accuracy: 0.8733\n 4096/15000 [=======&gt;......................] - ETA: 2s - loss: 0.1533 - binary_accuracy: 0.8735\n 4608/15000 [========&gt;.....................] - ETA: 1s - loss: 0.1540 - binary_accuracy: 0.8711\n 5120/15000 [=========&gt;....................] - ETA: 1s - loss: 0.1540 - binary_accuracy: 0.8703\n 5632/15000 [==========&gt;...................] - ETA: 1s - loss: 0.1534 - binary_accuracy: 0.8702\n 6144/15000 [===========&gt;..................] - ETA: 1s - loss: 0.1534 - binary_accuracy: 0.8716\n 6656/15000 [============&gt;.................] - ETA: 1s - loss: 0.1534 - binary_accuracy: 0.8715\n 7168/15000 [=============&gt;................] - ETA: 1s - loss: 0.1538 - binary_accuracy: 0.8694\n 7680/15000 [==============&gt;...............] - ETA: 1s - loss: 0.1534 - binary_accuracy: 0.8714\n 8192/15000 [===============&gt;..............] - ETA: 1s - loss: 0.1528 - binary_accuracy: 0.8728\n 8704/15000 [================&gt;.............] - ETA: 1s - loss: 0.1528 - binary_accuracy: 0.8733\n 9216/15000 [=================&gt;............] - ETA: 1s - loss: 0.1525 - binary_accuracy: 0.8727\n 9728/15000 [==================&gt;...........] - ETA: 1s - loss: 0.1524 - binary_accuracy: 0.8722\n10240/15000 [===================&gt;..........] - ETA: 0s - loss: 0.1520 - binary_accuracy: 0.8720\n10752/15000 [====================&gt;.........] - ETA: 0s - loss: 0.1520 - binary_accuracy: 0.8714\n11264/15000 [=====================&gt;........] - ETA: 0s - loss: 0.1516 - binary_accuracy: 0.8728\n11776/15000 [======================&gt;.......] - ETA: 0s - loss: 0.1513 - binary_accuracy: 0.8735\n12288/15000 [=======================&gt;......] - ETA: 0s - loss: 0.1514 - binary_accuracy: 0.8727\n12800/15000 [========================&gt;.....] - ETA: 0s - loss: 0.1511 - binary_accuracy: 0.8732\n13312/15000 [=========================&gt;....] - ETA: 0s - loss: 0.1510 - binary_accuracy: 0.8727\n13824/15000 [==========================&gt;...] - ETA: 0s - loss: 0.1507 - binary_accuracy: 0.8733\n14336/15000 [===========================&gt;..] - ETA: 0s - loss: 0.1505 - binary_accuracy: 0.8735\n14848/15000 [============================&gt;.] - ETA: 0s - loss: 0.1502 - binary_accuracy: 0.8737\n15000/15000 [==============================] - 5s 308us/step - loss: 0.1501 - binary_accuracy: 0.8738 - val_loss: 0.1530 - val_binary_accuracy: 0.8510\nEpoch 7/30\n\n  512/15000 [&gt;.............................] - ETA: 2s - loss: 0.1391 - binary_accuracy: 0.8867\n 1024/15000 [=&gt;............................] - ETA: 2s - loss: 0.1392 - binary_accuracy: 0.8916\n 1536/15000 [==&gt;...........................] - ETA: 2s - loss: 0.1386 - binary_accuracy: 0.8874\n 2048/15000 [===&gt;..........................] - ETA: 2s - loss: 0.1391 - binary_accuracy: 0.8862\n 2560/15000 [====&gt;.........................] - ETA: 2s - loss: 0.1397 - binary_accuracy: 0.8816\n 3072/15000 [=====&gt;........................] - ETA: 2s - loss: 0.1401 - binary_accuracy: 0.8815\n 3584/15000 [======&gt;.......................] - ETA: 2s - loss: 0.1400 - binary_accuracy: 0.8797\n 4096/15000 [=======&gt;......................] - ETA: 2s - loss: 0.1397 - binary_accuracy: 0.8796\n 4608/15000 [========&gt;.....................] - ETA: 2s - loss: 0.1397 - binary_accuracy: 0.8789\n 5120/15000 [=========&gt;....................] - ETA: 1s - loss: 0.1397 - binary_accuracy: 0.8793\n 5632/15000 [==========&gt;...................] - ETA: 1s - loss: 0.1393 - binary_accuracy: 0.8812\n 6144/15000 [===========&gt;..................] - ETA: 1s - loss: 0.1390 - binary_accuracy: 0.8809\n 6656/15000 [============&gt;.................] - ETA: 1s - loss: 0.1383 - binary_accuracy: 0.8821\n 7168/15000 [=============&gt;................] - ETA: 1s - loss: 0.1383 - binary_accuracy: 0.8824\n 7680/15000 [==============&gt;...............] - ETA: 1s - loss: 0.1383 - binary_accuracy: 0.8824\n 8192/15000 [===============&gt;..............] - ETA: 1s - loss: 0.1384 - binary_accuracy: 0.8821\n 8704/15000 [================&gt;.............] - ETA: 1s - loss: 0.1383 - binary_accuracy: 0.8820\n 9216/15000 [=================&gt;............] - ETA: 1s - loss: 0.1383 - binary_accuracy: 0.8824\n 9728/15000 [==================&gt;...........] - ETA: 1s - loss: 0.1383 - binary_accuracy: 0.8825\n10240/15000 [===================&gt;..........] - ETA: 0s - loss: 0.1382 - binary_accuracy: 0.8828\n10752/15000 [====================&gt;.........] - ETA: 0s - loss: 0.1380 - binary_accuracy: 0.8828\n11264/15000 [=====================&gt;........] - ETA: 0s - loss: 0.1375 - binary_accuracy: 0.8831\n11776/15000 [======================&gt;.......] - ETA: 0s - loss: 0.1371 - binary_accuracy: 0.8842\n12288/15000 [=======================&gt;......] - ETA: 0s - loss: 0.1369 - binary_accuracy: 0.8844\n12800/15000 [========================&gt;.....] - ETA: 0s - loss: 0.1369 - binary_accuracy: 0.8838\n13312/15000 [=========================&gt;....] - ETA: 0s - loss: 0.1368 - binary_accuracy: 0.8838\n13824/15000 [==========================&gt;...] - ETA: 0s - loss: 0.1370 - binary_accuracy: 0.8829\n14336/15000 [===========================&gt;..] - ETA: 0s - loss: 0.1369 - binary_accuracy: 0.8826\n14848/15000 [============================&gt;.] - ETA: 0s - loss: 0.1365 - binary_accuracy: 0.8832\n15000/15000 [==============================] - 5s 311us/step - loss: 0.1364 - binary_accuracy: 0.8835 - val_loss: 0.1417 - val_binary_accuracy: 0.8590\nEpoch 8/30\n\n  512/15000 [&gt;.............................] - ETA: 2s - loss: 0.1305 - binary_accuracy: 0.8945\n 1024/15000 [=&gt;............................] - ETA: 2s - loss: 0.1283 - binary_accuracy: 0.8955\n 1536/15000 [==&gt;...........................] - ETA: 2s - loss: 0.1294 - binary_accuracy: 0.8880\n 2048/15000 [===&gt;..........................] - ETA: 2s - loss: 0.1283 - binary_accuracy: 0.8892\n 2560/15000 [====&gt;.........................] - ETA: 2s - loss: 0.1276 - binary_accuracy: 0.8918\n 3072/15000 [=====&gt;........................] - ETA: 2s - loss: 0.1294 - binary_accuracy: 0.8857\n 3584/15000 [======&gt;.......................] - ETA: 2s - loss: 0.1287 - binary_accuracy: 0.8873\n 4096/15000 [=======&gt;......................] - ETA: 2s - loss: 0.1279 - binary_accuracy: 0.8906\n 4608/15000 [========&gt;.....................] - ETA: 2s - loss: 0.1277 - binary_accuracy: 0.8908\n 5120/15000 [=========&gt;....................] - ETA: 1s - loss: 0.1280 - binary_accuracy: 0.8904\n 5632/15000 [==========&gt;...................] - ETA: 1s - loss: 0.1276 - binary_accuracy: 0.8906\n 6144/15000 [===========&gt;..................] - ETA: 1s - loss: 0.1277 - binary_accuracy: 0.8901\n 6656/15000 [============&gt;.................] - ETA: 1s - loss: 0.1272 - binary_accuracy: 0.8903\n 7168/15000 [=============&gt;................] - ETA: 1s - loss: 0.1269 - binary_accuracy: 0.8903\n 7680/15000 [==============&gt;...............] - ETA: 1s - loss: 0.1261 - binary_accuracy: 0.8919\n 8192/15000 [===============&gt;..............] - ETA: 1s - loss: 0.1257 - binary_accuracy: 0.8932\n 8704/15000 [================&gt;.............] - ETA: 1s - loss: 0.1257 - binary_accuracy: 0.8930\n 9216/15000 [=================&gt;............] - ETA: 1s - loss: 0.1258 - binary_accuracy: 0.8934\n 9728/15000 [==================&gt;...........] - ETA: 1s - loss: 0.1254 - binary_accuracy: 0.8938\n10240/15000 [===================&gt;..........] - ETA: 0s - loss: 0.1255 - binary_accuracy: 0.8934\n10752/15000 [====================&gt;.........] - ETA: 0s - loss: 0.1256 - binary_accuracy: 0.8934\n11264/15000 [=====================&gt;........] - ETA: 0s - loss: 0.1254 - binary_accuracy: 0.8943\n11776/15000 [======================&gt;.......] - ETA: 0s - loss: 0.1255 - binary_accuracy: 0.8930\n12288/15000 [=======================&gt;......] - ETA: 0s - loss: 0.1253 - binary_accuracy: 0.8933\n12800/15000 [========================&gt;.....] - ETA: 0s - loss: 0.1249 - binary_accuracy: 0.8930\n13312/15000 [=========================&gt;....] - ETA: 0s - loss: 0.1246 - binary_accuracy: 0.8938\n13824/15000 [==========================&gt;...] - ETA: 0s - loss: 0.1244 - binary_accuracy: 0.8939\n14336/15000 [===========================&gt;..] - ETA: 0s - loss: 0.1246 - binary_accuracy: 0.8924\n14848/15000 [============================&gt;.] - ETA: 0s - loss: 0.1244 - binary_accuracy: 0.8928\n15000/15000 [==============================] - 5s 312us/step - loss: 0.1246 - binary_accuracy: 0.8923 - val_loss: 0.1325 - val_binary_accuracy: 0.8656\nEpoch 9/30\n\n  512/15000 [&gt;.............................] - ETA: 2s - loss: 0.1166 - binary_accuracy: 0.8984\n 1024/15000 [=&gt;............................] - ETA: 2s - loss: 0.1161 - binary_accuracy: 0.9062\n 1536/15000 [==&gt;...........................] - ETA: 2s - loss: 0.1174 - binary_accuracy: 0.9023\n 2048/15000 [===&gt;..........................] - ETA: 2s - loss: 0.1190 - binary_accuracy: 0.8999\n 2560/15000 [====&gt;.........................] - ETA: 2s - loss: 0.1194 - binary_accuracy: 0.9004\n 3072/15000 [=====&gt;........................] - ETA: 2s - loss: 0.1186 - binary_accuracy: 0.9017\n 3584/15000 [======&gt;.......................] - ETA: 2s - loss: 0.1174 - binary_accuracy: 0.9049\n 4096/15000 [=======&gt;......................] - ETA: 2s - loss: 0.1186 - binary_accuracy: 0.9019\n 4608/15000 [========&gt;.....................] - ETA: 2s - loss: 0.1190 - binary_accuracy: 0.8997\n 5120/15000 [=========&gt;....................] - ETA: 1s - loss: 0.1184 - binary_accuracy: 0.9008\n 5632/15000 [==========&gt;...................] - ETA: 1s - loss: 0.1183 - binary_accuracy: 0.9022\n 6144/15000 [===========&gt;..................] - ETA: 1s - loss: 0.1176 - binary_accuracy: 0.9035\n 6656/15000 [============&gt;.................] - ETA: 1s - loss: 0.1173 - binary_accuracy: 0.9034\n\n*** WARNING: skipped 41848 bytes of output ***\n\n10240/15000 [===================&gt;..........] - ETA: 0s - loss: 0.0502 - binary_accuracy: 0.9542\n10752/15000 [====================&gt;.........] - ETA: 0s - loss: 0.0501 - binary_accuracy: 0.9545\n11264/15000 [=====================&gt;........] - ETA: 0s - loss: 0.0498 - binary_accuracy: 0.9550\n11776/15000 [======================&gt;.......] - ETA: 0s - loss: 0.0500 - binary_accuracy: 0.9547\n12288/15000 [=======================&gt;......] - ETA: 0s - loss: 0.0498 - binary_accuracy: 0.9549\n12800/15000 [========================&gt;.....] - ETA: 0s - loss: 0.0497 - binary_accuracy: 0.9552\n13312/15000 [=========================&gt;....] - ETA: 0s - loss: 0.0496 - binary_accuracy: 0.9553\n13824/15000 [==========================&gt;...] - ETA: 0s - loss: 0.0498 - binary_accuracy: 0.9552\n14336/15000 [===========================&gt;..] - ETA: 0s - loss: 0.0500 - binary_accuracy: 0.9547\n14848/15000 [============================&gt;.] - ETA: 0s - loss: 0.0500 - binary_accuracy: 0.9544\n15000/15000 [==============================] - 5s 310us/step - loss: 0.0502 - binary_accuracy: 0.9543 - val_loss: 0.0853 - val_binary_accuracy: 0.8910\nEpoch 24/30\n\n  512/15000 [&gt;.............................] - ETA: 2s - loss: 0.0431 - binary_accuracy: 0.9688\n 1024/15000 [=&gt;............................] - ETA: 2s - loss: 0.0449 - binary_accuracy: 0.9639\n 1536/15000 [==&gt;...........................] - ETA: 2s - loss: 0.0481 - binary_accuracy: 0.9538\n 2048/15000 [===&gt;..........................] - ETA: 2s - loss: 0.0478 - binary_accuracy: 0.9551\n 2560/15000 [====&gt;.........................] - ETA: 2s - loss: 0.0493 - binary_accuracy: 0.9523\n 3072/15000 [=====&gt;........................] - ETA: 2s - loss: 0.0480 - binary_accuracy: 0.9551\n 3584/15000 [======&gt;.......................] - ETA: 2s - loss: 0.0471 - binary_accuracy: 0.9559\n 4096/15000 [=======&gt;......................] - ETA: 2s - loss: 0.0481 - binary_accuracy: 0.9543\n 4608/15000 [========&gt;.....................] - ETA: 2s - loss: 0.0483 - binary_accuracy: 0.9544\n 5120/15000 [=========&gt;....................] - ETA: 1s - loss: 0.0475 - binary_accuracy: 0.9564\n 5632/15000 [==========&gt;...................] - ETA: 1s - loss: 0.0476 - binary_accuracy: 0.9563\n 6144/15000 [===========&gt;..................] - ETA: 1s - loss: 0.0478 - binary_accuracy: 0.9561\n 6656/15000 [============&gt;.................] - ETA: 1s - loss: 0.0476 - binary_accuracy: 0.9558\n 7168/15000 [=============&gt;................] - ETA: 1s - loss: 0.0479 - binary_accuracy: 0.9559\n 7680/15000 [==============&gt;...............] - ETA: 1s - loss: 0.0481 - binary_accuracy: 0.9559\n 8192/15000 [===============&gt;..............] - ETA: 1s - loss: 0.0480 - binary_accuracy: 0.9561\n 8704/15000 [================&gt;.............] - ETA: 1s - loss: 0.0479 - binary_accuracy: 0.9566\n 9216/15000 [=================&gt;............] - ETA: 1s - loss: 0.0479 - binary_accuracy: 0.9563\n 9728/15000 [==================&gt;...........] - ETA: 1s - loss: 0.0476 - binary_accuracy: 0.9563\n10240/15000 [===================&gt;..........] - ETA: 0s - loss: 0.0476 - binary_accuracy: 0.9563\n10752/15000 [====================&gt;.........] - ETA: 0s - loss: 0.0477 - binary_accuracy: 0.9560\n11264/15000 [=====================&gt;........] - ETA: 0s - loss: 0.0475 - binary_accuracy: 0.9561\n11776/15000 [======================&gt;.......] - ETA: 0s - loss: 0.0478 - binary_accuracy: 0.9560\n12288/15000 [=======================&gt;......] - ETA: 0s - loss: 0.0480 - binary_accuracy: 0.9554\n12800/15000 [========================&gt;.....] - ETA: 0s - loss: 0.0482 - binary_accuracy: 0.9551\n13312/15000 [=========================&gt;....] - ETA: 0s - loss: 0.0483 - binary_accuracy: 0.9552\n13824/15000 [==========================&gt;...] - ETA: 0s - loss: 0.0481 - binary_accuracy: 0.9551\n14336/15000 [===========================&gt;..] - ETA: 0s - loss: 0.0482 - binary_accuracy: 0.9551\n14848/15000 [============================&gt;.] - ETA: 0s - loss: 0.0480 - binary_accuracy: 0.9555\n15000/15000 [==============================] - 5s 310us/step - loss: 0.0480 - binary_accuracy: 0.9554 - val_loss: 0.0844 - val_binary_accuracy: 0.8904\nEpoch 25/30\n\n  512/15000 [&gt;.............................] - ETA: 2s - loss: 0.0431 - binary_accuracy: 0.9590\n 1024/15000 [=&gt;............................] - ETA: 2s - loss: 0.0417 - binary_accuracy: 0.9658\n 1536/15000 [==&gt;...........................] - ETA: 2s - loss: 0.0417 - binary_accuracy: 0.9648\n 2048/15000 [===&gt;..........................] - ETA: 2s - loss: 0.0407 - binary_accuracy: 0.9668\n 2560/15000 [====&gt;.........................] - ETA: 2s - loss: 0.0405 - binary_accuracy: 0.9672\n 3072/15000 [=====&gt;........................] - ETA: 2s - loss: 0.0410 - binary_accuracy: 0.9661\n 3584/15000 [======&gt;.......................] - ETA: 2s - loss: 0.0429 - binary_accuracy: 0.9646\n 4096/15000 [=======&gt;......................] - ETA: 2s - loss: 0.0448 - binary_accuracy: 0.9604\n 4608/15000 [========&gt;.....................] - ETA: 2s - loss: 0.0446 - binary_accuracy: 0.9603\n 5120/15000 [=========&gt;....................] - ETA: 1s - loss: 0.0459 - binary_accuracy: 0.9588\n 5632/15000 [==========&gt;...................] - ETA: 1s - loss: 0.0464 - binary_accuracy: 0.9585\n 6144/15000 [===========&gt;..................] - ETA: 1s - loss: 0.0462 - binary_accuracy: 0.9578\n 6656/15000 [============&gt;.................] - ETA: 1s - loss: 0.0466 - binary_accuracy: 0.9570\n 7168/15000 [=============&gt;................] - ETA: 1s - loss: 0.0466 - binary_accuracy: 0.9569\n 7680/15000 [==============&gt;...............] - ETA: 1s - loss: 0.0467 - binary_accuracy: 0.9566\n 8192/15000 [===============&gt;..............] - ETA: 1s - loss: 0.0465 - binary_accuracy: 0.9568\n 8704/15000 [================&gt;.............] - ETA: 1s - loss: 0.0468 - binary_accuracy: 0.9563\n 9216/15000 [=================&gt;............] - ETA: 1s - loss: 0.0467 - binary_accuracy: 0.9562\n 9728/15000 [==================&gt;...........] - ETA: 1s - loss: 0.0463 - binary_accuracy: 0.9567\n10240/15000 [===================&gt;..........] - ETA: 0s - loss: 0.0463 - binary_accuracy: 0.9573\n10752/15000 [====================&gt;.........] - ETA: 0s - loss: 0.0462 - binary_accuracy: 0.9577\n11264/15000 [=====================&gt;........] - ETA: 0s - loss: 0.0462 - binary_accuracy: 0.9577\n11776/15000 [======================&gt;.......] - ETA: 0s - loss: 0.0461 - binary_accuracy: 0.9582\n12288/15000 [=======================&gt;......] - ETA: 0s - loss: 0.0463 - binary_accuracy: 0.9578\n12800/15000 [========================&gt;.....] - ETA: 0s - loss: 0.0462 - binary_accuracy: 0.9577\n13312/15000 [=========================&gt;....] - ETA: 0s - loss: 0.0460 - binary_accuracy: 0.9580\n13824/15000 [==========================&gt;...] - ETA: 0s - loss: 0.0461 - binary_accuracy: 0.9575\n14336/15000 [===========================&gt;..] - ETA: 0s - loss: 0.0460 - binary_accuracy: 0.9580\n14848/15000 [============================&gt;.] - ETA: 0s - loss: 0.0460 - binary_accuracy: 0.9578\n15000/15000 [==============================] - 5s 310us/step - loss: 0.0460 - binary_accuracy: 0.9578 - val_loss: 0.0840 - val_binary_accuracy: 0.8897\nEpoch 26/30\n\n  512/15000 [&gt;.............................] - ETA: 2s - loss: 0.0467 - binary_accuracy: 0.9609\n 1024/15000 [=&gt;............................] - ETA: 2s - loss: 0.0425 - binary_accuracy: 0.9639\n 1536/15000 [==&gt;...........................] - ETA: 2s - loss: 0.0433 - binary_accuracy: 0.9596\n 2048/15000 [===&gt;..........................] - ETA: 2s - loss: 0.0453 - binary_accuracy: 0.9551\n 2560/15000 [====&gt;.........................] - ETA: 2s - loss: 0.0450 - binary_accuracy: 0.9559\n 3072/15000 [=====&gt;........................] - ETA: 2s - loss: 0.0444 - binary_accuracy: 0.9587\n 3584/15000 [======&gt;.......................] - ETA: 2s - loss: 0.0442 - binary_accuracy: 0.9604\n 4096/15000 [=======&gt;......................] - ETA: 2s - loss: 0.0438 - binary_accuracy: 0.9619\n 4608/15000 [========&gt;.....................] - ETA: 2s - loss: 0.0432 - binary_accuracy: 0.9631\n 5120/15000 [=========&gt;....................] - ETA: 1s - loss: 0.0434 - binary_accuracy: 0.9627\n 5632/15000 [==========&gt;...................] - ETA: 1s - loss: 0.0446 - binary_accuracy: 0.9604\n 6144/15000 [===========&gt;..................] - ETA: 1s - loss: 0.0446 - binary_accuracy: 0.9606\n 6656/15000 [============&gt;.................] - ETA: 1s - loss: 0.0447 - binary_accuracy: 0.9599\n 7168/15000 [=============&gt;................] - ETA: 1s - loss: 0.0450 - binary_accuracy: 0.9595\n 7680/15000 [==============&gt;...............] - ETA: 1s - loss: 0.0453 - binary_accuracy: 0.9589\n 8192/15000 [===============&gt;..............] - ETA: 1s - loss: 0.0453 - binary_accuracy: 0.9589\n 8704/15000 [================&gt;.............] - ETA: 1s - loss: 0.0448 - binary_accuracy: 0.9598\n 9216/15000 [=================&gt;............] - ETA: 1s - loss: 0.0448 - binary_accuracy: 0.9597\n 9728/15000 [==================&gt;...........] - ETA: 1s - loss: 0.0446 - binary_accuracy: 0.9597\n10240/15000 [===================&gt;..........] - ETA: 0s - loss: 0.0446 - binary_accuracy: 0.9598\n10752/15000 [====================&gt;.........] - ETA: 0s - loss: 0.0444 - binary_accuracy: 0.9601\n11264/15000 [=====================&gt;........] - ETA: 0s - loss: 0.0442 - binary_accuracy: 0.9600\n11776/15000 [======================&gt;.......] - ETA: 0s - loss: 0.0440 - binary_accuracy: 0.9604\n12288/15000 [=======================&gt;......] - ETA: 0s - loss: 0.0437 - binary_accuracy: 0.9608\n12800/15000 [========================&gt;.....] - ETA: 0s - loss: 0.0438 - binary_accuracy: 0.9607\n13312/15000 [=========================&gt;....] - ETA: 0s - loss: 0.0440 - binary_accuracy: 0.9599\n13824/15000 [==========================&gt;...] - ETA: 0s - loss: 0.0439 - binary_accuracy: 0.9599\n14336/15000 [===========================&gt;..] - ETA: 0s - loss: 0.0439 - binary_accuracy: 0.9595\n14848/15000 [============================&gt;.] - ETA: 0s - loss: 0.0440 - binary_accuracy: 0.9593\n15000/15000 [==============================] - 5s 311us/step - loss: 0.0440 - binary_accuracy: 0.9593 - val_loss: 0.0835 - val_binary_accuracy: 0.8905\nEpoch 27/30\n\n  512/15000 [&gt;.............................] - ETA: 2s - loss: 0.0414 - binary_accuracy: 0.9707\n 1024/15000 [=&gt;............................] - ETA: 2s - loss: 0.0416 - binary_accuracy: 0.9648\n 1536/15000 [==&gt;...........................] - ETA: 2s - loss: 0.0414 - binary_accuracy: 0.9648\n 2048/15000 [===&gt;..........................] - ETA: 2s - loss: 0.0423 - binary_accuracy: 0.9634\n 2560/15000 [====&gt;.........................] - ETA: 2s - loss: 0.0424 - binary_accuracy: 0.9633\n 3072/15000 [=====&gt;........................] - ETA: 2s - loss: 0.0425 - binary_accuracy: 0.9632\n 3584/15000 [======&gt;.......................] - ETA: 2s - loss: 0.0428 - binary_accuracy: 0.9615\n 4096/15000 [=======&gt;......................] - ETA: 2s - loss: 0.0431 - binary_accuracy: 0.9609\n 4608/15000 [========&gt;.....................] - ETA: 1s - loss: 0.0428 - binary_accuracy: 0.9616\n 5120/15000 [=========&gt;....................] - ETA: 1s - loss: 0.0425 - binary_accuracy: 0.9619\n 5632/15000 [==========&gt;...................] - ETA: 1s - loss: 0.0422 - binary_accuracy: 0.9624\n 6144/15000 [===========&gt;..................] - ETA: 1s - loss: 0.0424 - binary_accuracy: 0.9622\n 6656/15000 [============&gt;.................] - ETA: 1s - loss: 0.0422 - binary_accuracy: 0.9626\n 7168/15000 [=============&gt;................] - ETA: 1s - loss: 0.0423 - binary_accuracy: 0.9625\n 7680/15000 [==============&gt;...............] - ETA: 1s - loss: 0.0424 - binary_accuracy: 0.9625\n 8192/15000 [===============&gt;..............] - ETA: 1s - loss: 0.0421 - binary_accuracy: 0.9628\n 8704/15000 [================&gt;.............] - ETA: 1s - loss: 0.0421 - binary_accuracy: 0.9628\n 9216/15000 [=================&gt;............] - ETA: 1s - loss: 0.0424 - binary_accuracy: 0.9618\n 9728/15000 [==================&gt;...........] - ETA: 1s - loss: 0.0427 - binary_accuracy: 0.9615\n10240/15000 [===================&gt;..........] - ETA: 0s - loss: 0.0427 - binary_accuracy: 0.9617\n10752/15000 [====================&gt;.........] - ETA: 0s - loss: 0.0427 - binary_accuracy: 0.9619\n11264/15000 [=====================&gt;........] - ETA: 0s - loss: 0.0426 - binary_accuracy: 0.9620\n11776/15000 [======================&gt;.......] - ETA: 0s - loss: 0.0425 - binary_accuracy: 0.9620\n12288/15000 [=======================&gt;......] - ETA: 0s - loss: 0.0423 - binary_accuracy: 0.9619\n12800/15000 [========================&gt;.....] - ETA: 0s - loss: 0.0422 - binary_accuracy: 0.9619\n13312/15000 [=========================&gt;....] - ETA: 0s - loss: 0.0422 - binary_accuracy: 0.9618\n13824/15000 [==========================&gt;...] - ETA: 0s - loss: 0.0421 - binary_accuracy: 0.9619\n14336/15000 [===========================&gt;..] - ETA: 0s - loss: 0.0421 - binary_accuracy: 0.9620\n14848/15000 [============================&gt;.] - ETA: 0s - loss: 0.0423 - binary_accuracy: 0.9617\n15000/15000 [==============================] - 5s 308us/step - loss: 0.0422 - binary_accuracy: 0.9617 - val_loss: 0.0832 - val_binary_accuracy: 0.8900\nEpoch 28/30\n\n  512/15000 [&gt;.............................] - ETA: 2s - loss: 0.0366 - binary_accuracy: 0.9668\n 1024/15000 [=&gt;............................] - ETA: 2s - loss: 0.0403 - binary_accuracy: 0.9619\n 1536/15000 [==&gt;...........................] - ETA: 2s - loss: 0.0395 - binary_accuracy: 0.9622\n 2048/15000 [===&gt;..........................] - ETA: 2s - loss: 0.0376 - binary_accuracy: 0.9648\n 2560/15000 [====&gt;.........................] - ETA: 2s - loss: 0.0387 - binary_accuracy: 0.9648\n 3072/15000 [=====&gt;........................] - ETA: 2s - loss: 0.0387 - binary_accuracy: 0.9648\n 3584/15000 [======&gt;.......................] - ETA: 2s - loss: 0.0387 - binary_accuracy: 0.9648\n 4096/15000 [=======&gt;......................] - ETA: 2s - loss: 0.0397 - binary_accuracy: 0.9631\n 4608/15000 [========&gt;.....................] - ETA: 1s - loss: 0.0404 - binary_accuracy: 0.9620\n 5120/15000 [=========&gt;....................] - ETA: 1s - loss: 0.0404 - binary_accuracy: 0.9619\n 5632/15000 [==========&gt;...................] - ETA: 1s - loss: 0.0400 - binary_accuracy: 0.9629\n 6144/15000 [===========&gt;..................] - ETA: 1s - loss: 0.0401 - binary_accuracy: 0.9627\n 6656/15000 [============&gt;.................] - ETA: 1s - loss: 0.0402 - binary_accuracy: 0.9626\n 7168/15000 [=============&gt;................] - ETA: 1s - loss: 0.0405 - binary_accuracy: 0.9616\n 7680/15000 [==============&gt;...............] - ETA: 1s - loss: 0.0405 - binary_accuracy: 0.9618\n 8192/15000 [===============&gt;..............] - ETA: 1s - loss: 0.0406 - binary_accuracy: 0.9620\n 8704/15000 [================&gt;.............] - ETA: 1s - loss: 0.0408 - binary_accuracy: 0.9621\n 9216/15000 [=================&gt;............] - ETA: 1s - loss: 0.0410 - binary_accuracy: 0.9621\n 9728/15000 [==================&gt;...........] - ETA: 1s - loss: 0.0403 - binary_accuracy: 0.9633\n10240/15000 [===================&gt;..........] - ETA: 0s - loss: 0.0403 - binary_accuracy: 0.9628\n10752/15000 [====================&gt;.........] - ETA: 0s - loss: 0.0407 - binary_accuracy: 0.9621\n11264/15000 [=====================&gt;........] - ETA: 0s - loss: 0.0405 - binary_accuracy: 0.9625\n11776/15000 [======================&gt;.......] - ETA: 0s - loss: 0.0404 - binary_accuracy: 0.9622\n12288/15000 [=======================&gt;......] - ETA: 0s - loss: 0.0404 - binary_accuracy: 0.9623\n12800/15000 [========================&gt;.....] - ETA: 0s - loss: 0.0405 - binary_accuracy: 0.9625\n13312/15000 [=========================&gt;....] - ETA: 0s - loss: 0.0406 - binary_accuracy: 0.9624\n13824/15000 [==========================&gt;...] - ETA: 0s - loss: 0.0406 - binary_accuracy: 0.9622\n14336/15000 [===========================&gt;..] - ETA: 0s - loss: 0.0406 - binary_accuracy: 0.9625\n14848/15000 [============================&gt;.] - ETA: 0s - loss: 0.0406 - binary_accuracy: 0.9624\n15000/15000 [==============================] - 5s 306us/step - loss: 0.0405 - binary_accuracy: 0.9627 - val_loss: 0.0829 - val_binary_accuracy: 0.8896\nEpoch 29/30\n\n  512/15000 [&gt;.............................] - ETA: 2s - loss: 0.0430 - binary_accuracy: 0.9570\n 1024/15000 [=&gt;............................] - ETA: 2s - loss: 0.0411 - binary_accuracy: 0.9570\n 1536/15000 [==&gt;...........................] - ETA: 2s - loss: 0.0401 - binary_accuracy: 0.9616\n 2048/15000 [===&gt;..........................] - ETA: 2s - loss: 0.0403 - binary_accuracy: 0.9624\n 2560/15000 [====&gt;.........................] - ETA: 2s - loss: 0.0388 - binary_accuracy: 0.9633\n 3072/15000 [=====&gt;........................] - ETA: 2s - loss: 0.0399 - binary_accuracy: 0.9619\n 3584/15000 [======&gt;.......................] - ETA: 2s - loss: 0.0402 - binary_accuracy: 0.9618\n 4096/15000 [=======&gt;......................] - ETA: 2s - loss: 0.0402 - binary_accuracy: 0.9622\n 4608/15000 [========&gt;.....................] - ETA: 2s - loss: 0.0401 - binary_accuracy: 0.9620\n 5120/15000 [=========&gt;....................] - ETA: 1s - loss: 0.0401 - binary_accuracy: 0.9633\n 5632/15000 [==========&gt;...................] - ETA: 1s - loss: 0.0398 - binary_accuracy: 0.9632\n 6144/15000 [===========&gt;..................] - ETA: 1s - loss: 0.0393 - binary_accuracy: 0.9639\n 6656/15000 [============&gt;.................] - ETA: 1s - loss: 0.0392 - binary_accuracy: 0.9636\n 7168/15000 [=============&gt;................] - ETA: 1s - loss: 0.0391 - binary_accuracy: 0.9643\n 7680/15000 [==============&gt;...............] - ETA: 1s - loss: 0.0388 - binary_accuracy: 0.9646\n 8192/15000 [===============&gt;..............] - ETA: 1s - loss: 0.0384 - binary_accuracy: 0.9652\n 8704/15000 [================&gt;.............] - ETA: 1s - loss: 0.0387 - binary_accuracy: 0.9646\n 9216/15000 [=================&gt;............] - ETA: 1s - loss: 0.0388 - binary_accuracy: 0.9646\n 9728/15000 [==================&gt;...........] - ETA: 1s - loss: 0.0388 - binary_accuracy: 0.9647\n10240/15000 [===================&gt;..........] - ETA: 0s - loss: 0.0388 - binary_accuracy: 0.9650\n10752/15000 [====================&gt;.........] - ETA: 0s - loss: 0.0390 - binary_accuracy: 0.9648\n11264/15000 [=====================&gt;........] - ETA: 0s - loss: 0.0391 - binary_accuracy: 0.9644\n11776/15000 [======================&gt;.......] - ETA: 0s - loss: 0.0391 - binary_accuracy: 0.9643\n12288/15000 [=======================&gt;......] - ETA: 0s - loss: 0.0392 - binary_accuracy: 0.9639\n12800/15000 [========================&gt;.....] - ETA: 0s - loss: 0.0392 - binary_accuracy: 0.9638\n13312/15000 [=========================&gt;....] - ETA: 0s - loss: 0.0390 - binary_accuracy: 0.9639\n13824/15000 [==========================&gt;...] - ETA: 0s - loss: 0.0389 - binary_accuracy: 0.9639\n14336/15000 [===========================&gt;..] - ETA: 0s - loss: 0.0388 - binary_accuracy: 0.9637\n14848/15000 [============================&gt;.] - ETA: 0s - loss: 0.0388 - binary_accuracy: 0.9640\n15000/15000 [==============================] - 5s 310us/step - loss: 0.0387 - binary_accuracy: 0.9641 - val_loss: 0.0829 - val_binary_accuracy: 0.8894\nEpoch 30/30\n\n  512/15000 [&gt;.............................] - ETA: 2s - loss: 0.0339 - binary_accuracy: 0.9648\n 1024/15000 [=&gt;............................] - ETA: 2s - loss: 0.0352 - binary_accuracy: 0.9648\n 1536/15000 [==&gt;...........................] - ETA: 2s - loss: 0.0363 - binary_accuracy: 0.9635\n 2048/15000 [===&gt;..........................] - ETA: 2s - loss: 0.0338 - binary_accuracy: 0.9683\n 2560/15000 [====&gt;.........................] - ETA: 2s - loss: 0.0340 - binary_accuracy: 0.9680\n 3072/15000 [=====&gt;........................] - ETA: 2s - loss: 0.0346 - binary_accuracy: 0.9678\n 3584/15000 [======&gt;.......................] - ETA: 2s - loss: 0.0348 - binary_accuracy: 0.9674\n 4096/15000 [=======&gt;......................] - ETA: 2s - loss: 0.0350 - binary_accuracy: 0.9675\n 4608/15000 [========&gt;.....................] - ETA: 2s - loss: 0.0350 - binary_accuracy: 0.9677\n 5120/15000 [=========&gt;....................] - ETA: 1s - loss: 0.0353 - binary_accuracy: 0.9680\n 5632/15000 [==========&gt;...................] - ETA: 1s - loss: 0.0353 - binary_accuracy: 0.9677\n 6144/15000 [===========&gt;..................] - ETA: 1s - loss: 0.0360 - binary_accuracy: 0.9665\n 6656/15000 [============&gt;.................] - ETA: 1s - loss: 0.0361 - binary_accuracy: 0.9665\n 7168/15000 [=============&gt;................] - ETA: 1s - loss: 0.0363 - binary_accuracy: 0.9665\n 7680/15000 [==============&gt;...............] - ETA: 1s - loss: 0.0368 - binary_accuracy: 0.9655\n 8192/15000 [===============&gt;..............] - ETA: 1s - loss: 0.0367 - binary_accuracy: 0.9657\n 8704/15000 [================&gt;.............] - ETA: 1s - loss: 0.0365 - binary_accuracy: 0.9665\n 9216/15000 [=================&gt;............] - ETA: 1s - loss: 0.0370 - binary_accuracy: 0.9660\n 9728/15000 [==================&gt;...........] - ETA: 1s - loss: 0.0371 - binary_accuracy: 0.9659\n10240/15000 [===================&gt;..........] - ETA: 0s - loss: 0.0372 - binary_accuracy: 0.9655\n10752/15000 [====================&gt;.........] - ETA: 0s - loss: 0.0374 - binary_accuracy: 0.9651\n11264/15000 [=====================&gt;........] - ETA: 0s - loss: 0.0374 - binary_accuracy: 0.9651\n11776/15000 [======================&gt;.......] - ETA: 0s - loss: 0.0375 - binary_accuracy: 0.9649\n12288/15000 [=======================&gt;......] - ETA: 0s - loss: 0.0372 - binary_accuracy: 0.9653\n12800/15000 [========================&gt;.....] - ETA: 0s - loss: 0.0372 - binary_accuracy: 0.9654\n13312/15000 [=========================&gt;....] - ETA: 0s - loss: 0.0371 - binary_accuracy: 0.9657\n13824/15000 [==========================&gt;...] - ETA: 0s - loss: 0.0370 - binary_accuracy: 0.9659\n14336/15000 [===========================&gt;..] - ETA: 0s - loss: 0.0369 - binary_accuracy: 0.9662\n14848/15000 [============================&gt;.] - ETA: 0s - loss: 0.0371 - binary_accuracy: 0.9659\n15000/15000 [==============================] - 5s 308us/step - loss: 0.0372 - binary_accuracy: 0.9658 - val_loss: 0.0827 - val_binary_accuracy: 0.8894\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\ndense_28 (Dense)             (None, 16)                160016    \n_________________________________________________________________\ndense_29 (Dense)             (None, 16)                272       \n_________________________________________________________________\ndense_30 (Dense)             (None, 1)                 17        \n=================================================================\nTotal params: 160,305\nTrainable params: 160,305\nNon-trainable params: 0\n_________________________________________________________________\nFinal metrics: binary_loss:0.0372\nFinal metrics: binary_accuracy=0.9658\nFinal metrics: validation_binary_loss:0.0827\nFinal metrics: validation_binary_accuracy:0.8894\n\n   32/25000 [..............................] - ETA: 4s\n  800/25000 [..............................] - ETA: 1s\n 1568/25000 [&gt;.............................] - ETA: 1s\n 2336/25000 [=&gt;............................] - ETA: 1s\n 3136/25000 [==&gt;...........................] - ETA: 1s\n 3936/25000 [===&gt;..........................] - ETA: 1s\n 4736/25000 [====&gt;.........................] - ETA: 1s\n 5536/25000 [=====&gt;........................] - ETA: 1s\n 6336/25000 [======&gt;.......................] - ETA: 1s\n 7104/25000 [=======&gt;......................] - ETA: 1s\n 7904/25000 [========&gt;.....................] - ETA: 1s\n 8672/25000 [=========&gt;....................] - ETA: 1s\n 9440/25000 [==========&gt;...................] - ETA: 1s\n10240/25000 [===========&gt;..................] - ETA: 0s\n11008/25000 [============&gt;.................] - ETA: 0s\n11808/25000 [=============&gt;................] - ETA: 0s\n12608/25000 [==============&gt;...............] - ETA: 0s\n13408/25000 [===============&gt;..............] - ETA: 0s\n14208/25000 [================&gt;.............] - ETA: 0s\n14944/25000 [================&gt;.............] - ETA: 0s\n15680/25000 [=================&gt;............] - ETA: 0s\n16416/25000 [==================&gt;...........] - ETA: 0s\n17152/25000 [===================&gt;..........] - ETA: 0s\n17920/25000 [====================&gt;.........] - ETA: 0s\n18656/25000 [=====================&gt;........] - ETA: 0s\n19392/25000 [======================&gt;.......] - ETA: 0s\n20128/25000 [=======================&gt;......] - ETA: 0s\n20864/25000 [========================&gt;.....] - ETA: 0s\n21504/25000 [========================&gt;.....] - ETA: 0s\n22240/25000 [=========================&gt;....] - ETA: 0s\n22976/25000 [==========================&gt;...] - ETA: 0s\n23712/25000 [===========================&gt;..] - ETA: 0s\n24448/25000 [============================&gt;.] - ETA: 0s\n25000/25000 [==============================] - 2s 67us/step\nAverage Probability Results:\n[0.08798528782129288, 0.8826]\n()\nPredictions Results:\n[[0.28070852]\n [0.9963032 ]\n [0.8713721 ]\n ...\n [0.14664929]\n [0.18704866]\n [0.47948763]]\nMLflow Run ID: 6d46472906234576b72a604e84817d44\nKeras model saved locally at /databricks/driver/keras_models/6d46472906234576b72a604e84817d44\nWriting TensorFlow events locally to /tmp/tmpVu3Xq8\n\nUploading TensorFlow events as a run artifact.\n(&#39;loss function use&#39;, &#39;mse&#39;)\n</div>"]}}],"execution_count":10},{"cell_type":"code","source":["# Update this manually by reviewing the previous cell `Writing TensorFlow events locally to...`\noutput_dir = \"/tmp/tmp2npaqjhu\"\ndbutils.tensorboard.start(output_dir)"],"metadata":{},"outputs":[],"execution_count":11},{"cell_type":"code","source":["dbutils.tensorboard.stop()"],"metadata":{},"outputs":[],"execution_count":12},{"cell_type":"code","source":[""],"metadata":{},"outputs":[],"execution_count":13}],"metadata":{"name":"MLflow - Keras Example","notebookId":1451022},"nbformat":4,"nbformat_minor":0}
